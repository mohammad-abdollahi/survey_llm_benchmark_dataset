{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Google Scholar Results:\n",
      "{'title': 'Binary code summarization: Benchmarking chatgpt/gpt-4 and other large language models', 'author': ['X Jin', 'J Larson', 'W Yang', 'Z Lin'], 'venue': 'arXiv preprint arXiv:2312.09601', 'year': 'N/A', 'link': 'https://arxiv.org/abs/2312.09601'}\n",
      "{'title': 'Automatic semantic augmentation of language model prompts (for code summarization)', 'author': ['T Ahmed', 'KS Pai', 'P Devanbu', 'E Barr'], 'venue': 'Proceedings of the IEEE/ACM â€¦', 'year': 'N/A', 'link': 'https://dl.acm.org/doi/abs/10.1145/3597503.3639183'}\n",
      "{'title': 'Few-shot training LLMs for project-specific code-summarization', 'author': ['T Ahmed', 'P Devanbu'], 'venue': 'Proceedings of the 37th IEEE/ACM International â€¦', 'year': 'N/A', 'link': 'https://dl.acm.org/doi/abs/10.1145/3551349.3559555'}\n",
      "{'title': 'Source code summarization in the era of large language models', 'author': ['W Sun', 'Y Miao', 'Y Li', 'H Zhang', 'C Fang', 'Y Liu'], 'venue': 'arXiv preprint arXiv â€¦', 'year': 'N/A', 'link': 'https://arxiv.org/abs/2407.07959'}\n",
      "{'title': 'Analyzing the performance of large language models on code summarization', 'author': ['R Haldar', 'J Hockenmaier'], 'venue': 'arXiv preprint arXiv:2404.08018', 'year': 'N/A', 'link': 'https://arxiv.org/abs/2404.08018'}\n",
      "\n",
      "ArXiv Results:\n",
      "{'title': 'Benchmarking LLMs on the Semantic Overlap Summarization Task', 'author': 'John Salvador, Naman Bansal, Mousumi Akter, Souvika Sarkar, Anupam Das, Shubhra Kanti Karmaker', 'published': '2024-02-26T20:33:50Z', 'summary': \"Semantic Overlap Summarization (SOS) is a constrained multi-document\\nsummarization task, where the constraint is to capture the common/overlapping\\ninformation between two alternative narratives. While recent advancements in\\nLarge Language Models (LLMs) have achieved superior performance in numerous\\nsummarization tasks, a benchmarking study of the SOS task using LLMs is yet to\\nbe performed. As LLMs' responses are sensitive to slight variations in prompt\\ndesign, a major challenge in conducting such a benchmarking study is to\\nsystematically explore a variety of prompts before drawing a reliable\\nconclusion. Fortunately, very recently, the TELeR taxonomy has been proposed\\nwhich can be used to design and explore various prompts for LLMs. Using this\\nTELeR taxonomy and 15 popular LLMs, this paper comprehensively evaluates LLMs\\non the SOS Task, assessing their ability to summarize overlapping information\\nfrom multiple alternative narratives. For evaluation, we report\\nwell-established metrics like ROUGE, BERTscore, and SEM-F1$ on two different\\ndatasets of alternative narratives. We conclude the paper by analyzing the\\nstrengths and limitations of various LLMs in terms of their capabilities in\\ncapturing overlapping information The code and datasets used to conduct this\\nstudy are available at https://anonymous.4open.science/r/llm_eval-E16D.\", 'link': 'http://arxiv.org/abs/2402.17008v1'}\n",
      "{'title': 'TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models', 'author': 'Hang Zou, Qiyang Zhao, Yu Tian, Lina Bariah, Faouzi Bader, Thierry Lestable, Merouane Debbah', 'published': '2024-07-12T16:51:02Z', 'summary': 'Large Language Models (LLMs) have the potential to revolutionize the Sixth\\nGeneration (6G) communication networks. However, current mainstream LLMs\\ngenerally lack the specialized knowledge in telecom domain. In this paper, for\\nthe first time, we propose a pipeline to adapt any general purpose LLMs to a\\ntelecom-specific LLMs. We collect and build telecom-specific pre-train dataset,\\ninstruction dataset, preference dataset to perform continual pre-training,\\ninstruct tuning and alignment tuning respectively. Besides, due to the lack of\\nwidely accepted evaluation benchmarks in telecom domain, we extend existing\\nevaluation benchmarks and proposed three new benchmarks, namely, Telecom Math\\nModeling, Telecom Open QnA and Telecom Code Tasks. These new benchmarks provide\\na holistic evaluation of the capabilities of LLMs including math modeling,\\nOpen-Ended question answering, code generation, infilling, summarization and\\nanalysis in telecom domain. Our fine-tuned LLM TelecomGPT outperforms state of\\nthe art (SOTA) LLMs including GPT-4, Llama-3 and Mistral in Telecom Math\\nModeling benchmark significantly and achieve comparable performance in various\\nevaluation benchmarks such as TeleQnA, 3GPP technical documents classification,\\ntelecom code summary and generation and infilling.', 'link': 'http://arxiv.org/abs/2407.09424v1'}\n",
      "{'title': 'Binary Code Summarization: Benchmarking ChatGPT/GPT-4 and Other Large\\n  Language Models', 'author': 'Xin Jin, Jonathan Larson, Weiwei Yang, Zhiqiang Lin', 'published': '2023-12-15T08:32:28Z', 'summary': 'Binary code summarization, while invaluable for understanding code semantics,\\nis challenging due to its labor-intensive nature. This study delves into the\\npotential of large language models (LLMs) for binary code comprehension. To\\nthis end, we present BinSum, a comprehensive benchmark and dataset of over 557K\\nbinary functions and introduce a novel method for prompt synthesis and\\noptimization. To more accurately gauge LLM performance, we also propose a new\\nsemantic similarity metric that surpasses traditional exact-match approaches.\\nOur extensive evaluation of prominent LLMs, including ChatGPT, GPT-4, Llama 2,\\nand Code Llama, reveals 10 pivotal insights. This evaluation generates 4\\nbillion inference tokens, incurred a total expense of 11,418 US dollars and 873\\nNVIDIA A100 GPU hours. Our findings highlight both the transformative potential\\nof LLMs in this field and the challenges yet to be overcome.', 'link': 'http://arxiv.org/abs/2312.09601v1'}\n",
      "{'title': 'A Survey on LLM-based Code Generation for Low-Resource and\\n  Domain-Specific Programming Languages', 'author': 'Sathvik Joel, Jie JW Wu, Fatemeh H. Fard', 'published': '2024-10-04T23:45:17Z', 'summary': 'Large Language Models (LLMs) have shown impressive capabilities in code\\ngeneration for popular programming languages. However, their performance on\\nLow-Resource Programming Languages (LRPLs) and Domain-Specific Languages (DSLs)\\nremains a significant challenge, affecting millions of developers-3.5 million\\nusers in Rust alone-who cannot fully utilize LLM capabilities. LRPLs and DSLs\\nencounter unique obstacles, including data scarcity and, for DSLs, specialized\\nsyntax that is poorly represented in general-purpose datasets.\\n  Addressing these challenges is crucial, as LRPLs and DSLs enhance development\\nefficiency in specialized domains, such as finance and science. While several\\nsurveys discuss LLMs in software engineering, none focus specifically on the\\nchallenges and opportunities associated with LRPLs and DSLs. Our survey fills\\nthis gap by systematically reviewing the current state, methodologies, and\\nchallenges in leveraging LLMs for code generation in these languages. We\\nfiltered 111 papers from over 27,000 published studies between 2020 and 2024 to\\nevaluate the capabilities and limitations of LLMs in LRPLs and DSLs. We report\\nthe LLMs used, benchmarks, and metrics for evaluation, strategies for enhancing\\nperformance, and methods for dataset collection and curation.\\n  We identified four main evaluation techniques and several metrics for\\nassessing code generation in LRPLs and DSLs. Our analysis categorizes\\nimprovement methods into six groups and summarizes novel architectures proposed\\nby researchers. Despite various techniques and metrics, a standard approach and\\nbenchmark dataset for evaluating code generation in LRPLs and DSLs are lacking.\\nThis survey serves as a resource for researchers and practitioners at the\\nintersection of LLMs, software engineering, and specialized programming\\nlanguages, laying the groundwork for future advancements in code generation for\\nLRPLs and DSLs.', 'link': 'http://arxiv.org/abs/2410.03981v2'}\n",
      "{'title': 'PersonalSum: A User-Subjective Guided Personalized Summarization Dataset\\n  for Large Language Models', 'author': 'Lemei Zhang, Peng Liu, Marcus Tiedemann Oekland Henriksboe, Even W. Lauvrak, Jon Atle Gulla, Heri Ramampiaro', 'published': '2024-10-04T20:12:39Z', 'summary': \"With the rapid advancement of Natural Language Processing in recent years,\\nnumerous studies have shown that generic summaries generated by Large Language\\nModels (LLMs) can sometimes surpass those annotated by experts, such as\\njournalists, according to human evaluations. However, there is limited research\\non whether these generic summaries meet the individual needs of ordinary\\npeople. The biggest obstacle is the lack of human-annotated datasets from the\\ngeneral public. Existing work on personalized summarization often relies on\\npseudo datasets created from generic summarization datasets or controllable\\ntasks that focus on specific named entities or other aspects, such as the\\nlength and specificity of generated summaries, collected from hypothetical\\ntasks without the annotators' initiative. To bridge this gap, we propose a\\nhigh-quality, personalized, manually annotated abstractive summarization\\ndataset called PersonalSum. This dataset is the first to investigate whether\\nthe focus of public readers differs from the generic summaries generated by\\nLLMs. It includes user profiles, personalized summaries accompanied by source\\nsentences from given articles, and machine-generated generic summaries along\\nwith their sources. We investigate several personal signals - entities/topics,\\nplot, and structure of articles - that may affect the generation of\\npersonalized summaries using LLMs in a few-shot in-context learning scenario.\\nOur preliminary results and analysis indicate that entities/topics are merely\\none of the key factors that impact the diverse preferences of users, and\\npersonalized summarization remains a significant challenge for existing LLMs.\", 'link': 'http://arxiv.org/abs/2410.03905v1'}\n",
      "\n",
      "IEEE Xplore Results:\n",
      "\n",
      "ACM Digital Library Results:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from scholarly import scholarly\n",
    "\n",
    "def search_google_scholar(query, num_results=5):\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    results = []\n",
    "    for i in range(num_results):\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            results.append({\n",
    "                'title': paper['bib']['title'],\n",
    "                'author': paper['bib'].get('author', 'N/A'),\n",
    "                'venue': paper['bib'].get('venue', 'N/A'),\n",
    "                'year': paper['bib'].get('year', 'N/A'),\n",
    "                'link': paper.get('pub_url', 'N/A')\n",
    "            })\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "def search_arxiv(query, num_results=5):\n",
    "    base_url = \"http://export.arxiv.org/api/query?search_query=\"\n",
    "    response = requests.get(f\"{base_url}{query.replace(' ', '+')}&max_results={num_results}\")\n",
    "    feed = feedparser.parse(response.text)\n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        results.append({\n",
    "            'title': entry.title,\n",
    "            'author': ', '.join(author.name for author in entry.authors),\n",
    "            'published': entry.published,\n",
    "            'summary': entry.summary,\n",
    "            'link': entry.link\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def search_ieee(query, num_results=5):\n",
    "    search_url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={query.replace(' ', '%20')}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    results = []\n",
    "    for div in soup.find_all('div', class_='List-results-items')[:num_results]:\n",
    "        title_tag = div.find('h2', class_='title')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            link = \"https://ieeexplore.ieee.org\" + title_tag.find('a')['href']\n",
    "            results.append({'title': title, 'link': link})\n",
    "    return results\n",
    "\n",
    "def search_acm(query, num_results=5):\n",
    "    search_url = f\"https://dl.acm.org/action/doSearch?AllField={query.replace(' ', '+')}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    results = []\n",
    "    for div in soup.find_all('div', class_='issue-item')[:num_results]:\n",
    "        title_tag = div.find('h5', class_='issue-item__title')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            link = \"https://dl.acm.org\" + title_tag.find('a')['href']\n",
    "            results.append({'title': title, 'link': link})\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    query = input(\"Enter search query: \")\n",
    "\n",
    "    print(\"\\nGoogle Scholar Results:\")\n",
    "    for paper in search_google_scholar(query):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nArXiv Results:\")\n",
    "    for paper in search_arxiv(query):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nIEEE Xplore Results:\")\n",
    "    for paper in search_ieee(query):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nACM Digital Library Results:\")\n",
    "    for paper in search_acm(query):\n",
    "        print(paper)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Searching for papers with keywords: benchmark dataset code summarization, benchmark dataset code generation (OR logic for Google Scholar & arXiv, direct links for IEEE & ACM)**\n",
      "\n",
      "ðŸ“Œ Google Scholar Results:\n",
      "{'title': 'Codexglue: A machine learning benchmark dataset for code understanding and generation', 'authors': ['S Lu', 'D Guo', 'S Ren', 'J Huang', 'A Svyatkovskiy'], 'year': '2021', 'link': 'https://scholar.google.com/scholar_lookup?title=Codexglue:+A+machine+learning+benchmark+dataset+for+code+understanding+and+generation'}\n",
      "{'title': 'Aixbench: A code generation benchmark dataset', 'authors': ['Y Hao', 'G Li', 'Y Liu', 'X Miao', 'H Zong', 'S Jiang'], 'year': '2022', 'link': 'https://scholar.google.com/scholar_lookup?title=Aixbench:+A+code+generation+benchmark+dataset'}\n",
      "{'title': 'Codereval: A benchmark of pragmatic code generation with generative pre-trained models', 'authors': ['H Yu', 'B Shen', 'D Ran', 'J Zhang', 'Q Zhang', 'Y Ma'], 'year': '2024', 'link': 'https://scholar.google.com/scholar_lookup?title=Codereval:+A+benchmark+of+pragmatic+code+generation+with+generative+pre-trained+models'}\n",
      "{'title': 'Pythonsaga: Redefining the benchmark to evaluate code generating llms', 'authors': ['A Yadav', 'H Beniwal', 'M Singh'], 'year': '2024', 'link': 'https://scholar.google.com/scholar_lookup?title=Pythonsaga:+Redefining+the+benchmark+to+evaluate+code+generating+llms'}\n",
      "{'title': 'Retrieval augmented code generation and summarization', 'authors': ['MR Parvez', 'WU Ahmad', 'S Chakraborty', 'B Ray'], 'year': '2021', 'link': 'https://scholar.google.com/scholar_lookup?title=Retrieval+augmented+code+generation+and+summarization'}\n",
      "\n",
      "ðŸ“Œ arXiv Results:\n",
      "{'title': 'Are We Building on the Rock? On the Importance of Data Preprocessing for\\n  Code Summarization', 'authors': ['Lin Shi', 'Fangwen Mu', 'Xiao Chen', 'Song Wang', 'Junjie Wang', 'Ye Yang', 'Ge Li', 'Xin Xia', 'Qing Wang'], 'published': '2022-07-12T15:02:16Z', 'link': 'http://arxiv.org/abs/2207.05579v2'}\n",
      "{'title': 'IndoSum: A New Benchmark Dataset for Indonesian Text Summarization', 'authors': ['Kemal Kurniawan', 'Samuel Louvan'], 'published': '2018-10-12T03:07:21Z', 'link': 'http://arxiv.org/abs/1810.05334v5'}\n",
      "{'title': 'CroCoSum: A Benchmark Dataset for Cross-Lingual Code-Switched\\n  Summarization', 'authors': ['Ruochen Zhang', 'Carsten Eickhoff'], 'published': '2023-03-07T17:52:51Z', 'link': 'http://arxiv.org/abs/2303.04092v2'}\n",
      "{'title': 'TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models', 'authors': ['Hang Zou', 'Qiyang Zhao', 'Yu Tian', 'Lina Bariah', 'Faouzi Bader', 'Thierry Lestable', 'Merouane Debbah'], 'published': '2024-07-12T16:51:02Z', 'link': 'http://arxiv.org/abs/2407.09424v1'}\n",
      "{'title': 'CNTLS: A Benchmark Dataset for Abstractive or Extractive Chinese\\n  Timeline Summarization', 'authors': ['Qianren Mao', 'Jiazheng Wang', 'Zheng Wang', 'Xi Li', 'Bo Li', 'Jianxin Li'], 'published': '2021-05-29T03:47:10Z', 'link': 'http://arxiv.org/abs/2105.14201v2'}\n",
      "\n",
      "ðŸ“Œ IEEE Xplore Search Links:\n",
      "{'IEEE Search': 'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText=benchmark+dataset+code+summarization'}\n",
      "{'IEEE Search': 'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText=benchmark+dataset+code+generation'}\n",
      "\n",
      "ðŸ“Œ ACM Digital Library Search Links:\n",
      "{'ACM Search': 'https://dl.acm.org/action/doSearch?AllField=benchmark+dataset+code+summarization'}\n",
      "{'ACM Search': 'https://dl.acm.org/action/doSearch?AllField=benchmark+dataset+code+generation'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "from scholarly import scholarly\n",
    "\n",
    "# --- Google Scholar Search ---\n",
    "def search_google_scholar(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Combine keywords with OR\n",
    "    search_query = scholarly.search_pubs(combined_query)\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_results):\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            results.append({\n",
    "                \"title\": paper.get(\"bib\", {}).get(\"title\", \"N/A\"),\n",
    "                \"authors\": paper.get(\"bib\", {}).get(\"author\", \"N/A\"),\n",
    "                \"year\": paper.get(\"bib\", {}).get(\"pub_year\", \"N/A\"),\n",
    "                \"link\": f'https://scholar.google.com/scholar_lookup?title={paper.get(\"bib\", {}).get(\"title\", \"\").replace(\" \", \"+\")}'\n",
    "            })\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# --- arXiv API Search ---\n",
    "def search_arxiv(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Use OR between keywords\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\"search_query\": f\"all:{combined_query}\", \"start\": 0, \"max_results\": num_results}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    feed = feedparser.parse(response.text)\n",
    "\n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        results.append({\n",
    "            \"title\": entry.title,\n",
    "            \"authors\": [author.name for author in entry.authors],\n",
    "            \"published\": entry.published,\n",
    "            \"link\": entry.link\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --- Reverted IEEE Xplore Search (Direct Search Links) ---\n",
    "def search_ieee_explore(keywords):\n",
    "    results = []\n",
    "    for keyword in keywords:  # Search each keyword separately\n",
    "        search_url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword.replace(' ', '+')}\"\n",
    "        results.append({\"IEEE Search\": search_url})\n",
    "    return results\n",
    "\n",
    "# --- Reverted ACM Digital Library Search (Direct Search Links) ---\n",
    "def search_acm_digital_library(keywords):\n",
    "    results = []\n",
    "    for keyword in keywords:  # Search each keyword separately\n",
    "        search_url = f\"https://dl.acm.org/action/doSearch?AllField={keyword.replace(' ', '+')}\"\n",
    "        results.append({\"ACM Search\": search_url})\n",
    "    return results\n",
    "\n",
    "# --- ðŸ”¥ Perform the Search ---\n",
    "def search_papers_with_or_logic(keywords):\n",
    "    print(f\"\\nðŸ”¹ **Searching for papers with keywords: {', '.join(keywords)} (OR logic for Google Scholar & arXiv, direct links for IEEE & ACM)**\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ Google Scholar Results:\")\n",
    "    for paper in search_google_scholar(keywords):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nðŸ“Œ arXiv Results:\")\n",
    "    for paper in search_arxiv(keywords):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nðŸ“Œ IEEE Xplore Search Links:\")\n",
    "    for paper in search_ieee_explore(keywords):\n",
    "        print(paper)\n",
    "\n",
    "    print(\"\\nðŸ“Œ ACM Digital Library Search Links:\")\n",
    "    for paper in search_acm_digital_library(keywords):\n",
    "        print(paper)\n",
    "\n",
    "\n",
    "# --- Run the Search ---\n",
    "keywords = [\"benchmark dataset code summarization\", \"benchmark dataset code generation\"]\n",
    "search_papers_with_or_logic(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Searching for papers with keywords: benchmark code summarization, benchmark code generation (Published after 2020)**\n",
      "\n",
      "ðŸ“Œ Google Scholar Results:\n",
      "{'title': 'Codereval: A benchmark of pragmatic code generation with generative pre-trained models', 'authors': ['H Yu', 'B Shen', 'D Ran', 'J Zhang', 'Q Zhang', 'Y Ma'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Codereval:+A+benchmark+of+pragmatic+code+generation+with+generative+pre-trained+models'}\n",
      "{'title': 'Codexglue: A machine learning benchmark dataset for code understanding and generation', 'authors': ['S Lu', 'D Guo', 'S Ren', 'J Huang', 'A Svyatkovskiy'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Codexglue:+A+machine+learning+benchmark+dataset+for+code+understanding+and+generation'}\n",
      "{'title': 'Classeval: A manually-crafted benchmark for evaluating llms on class-level code generation', 'authors': ['X Du', 'M Liu', 'K Wang', 'H Wang', 'J Liu', 'Y Chen'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Classeval:+A+manually-crafted+benchmark+for+evaluating+llms+on+class-level+code+generation'}\n",
      "{'title': 'Pythonsaga: Redefining the benchmark to evaluate code generating llms', 'authors': ['A Yadav', 'H Beniwal', 'M Singh'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Pythonsaga:+Redefining+the+benchmark+to+evaluate+code+generating+llms'}\n",
      "{'title': 'Evocodebench: An evolving code generation benchmark with domain-specific evaluations', 'authors': ['J Li', 'G Li', 'X Zhang', 'Y Zhao', 'Y Dong'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Evocodebench:+An+evolving+code+generation+benchmark+with+domain-specific+evaluations'}\n",
      "{'title': 'Mconala: a benchmark for code generation from multiple natural languages', 'authors': ['Z Wang', 'G Cuenca', 'S Zhou', 'FF Xu'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Mconala:+a+benchmark+for+code+generation+from+multiple+natural+languages'}\n",
      "{'title': 'BioCoder: a benchmark for bioinformatics code generation with large language models', 'authors': ['X Tang', 'B Qian', 'R Gao', 'J Chen', 'X Chen'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=BioCoder:+a+benchmark+for+bioinformatics+code+generation+with+large+language+models'}\n",
      "{'title': 'Aixbench: A code generation benchmark dataset', 'authors': ['Y Hao', 'G Li', 'Y Liu', 'X Miao', 'H Zong', 'S Jiang'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Aixbench:+A+code+generation+benchmark+dataset'}\n",
      "{'title': 'DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories', 'authors': ['J Li', 'G Li', 'Y Zhao', 'Y Li', 'H Liu', 'H Zhu', 'L Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DevEval:+A+Manually-Annotated+Code+Generation+Benchmark+Aligned+with+Real-World+Code+Repositories'}\n",
      "{'title': 'BioCoder: a benchmark for bioinformatics code generation with contextual pragmatic knowledge', 'authors': ['X Tang', 'B Qian', 'R Gao', 'J Chen', 'X Chen'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=BioCoder:+a+benchmark+for+bioinformatics+code+generation+with+contextual+pragmatic+knowledge'}\n",
      "{'title': 'EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories', 'authors': ['J Li', 'G Li', 'X Zhang', 'Y Dong', 'Z Jin'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=EvoCodeBench:+An+Evolving+Code+Generation+Benchmark+Aligned+with+Real-World+Code+Repositories'}\n",
      "{'title': 'JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models', 'authors': ['J Cao', 'Z Chen', 'J Wu', 'SC Cheung', 'C Xu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=JavaBench:+A+Benchmark+of+Object-Oriented+Code+Generation+for+Evaluating+Large+Language+Models'}\n",
      "{'title': 'DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation', 'authors': ['Q Zhu', 'J Cao', 'Y Lu', 'H Lin', 'X Han', 'L Sun'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DOMAINEVAL:+An+Auto-Constructed+Benchmark+for+Multi-Domain+Code+Generation'}\n",
      "{'title': 'Codescope: An execution-based multilingual multitask multidimensional benchmark for evaluating llms on code understanding and generation', 'authors': ['W Yan', 'H Liu', 'Y Wang', 'Y Li', 'Q Chen', 'W Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codescope:+An+execution-based+multilingual+multitask+multidimensional+benchmark+for+evaluating+llms+on+code+understanding+and+generation'}\n",
      "{'title': 'Codegeex: A pre-trained model for code generation with multilingual benchmarking on humaneval-x', 'authors': ['Q Zheng', 'X Xia', 'X Zou', 'Y Dong', 'S Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codegeex:+A+pre-trained+model+for+code+generation+with+multilingual+benchmarking+on+humaneval-x'}\n",
      "{'title': 'Complexcodeeval: A benchmark for evaluating large code models on more complex code', 'authors': ['J Feng', 'J Liu', 'C Gao', 'CY Chong', 'C Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Complexcodeeval:+A+benchmark+for+evaluating+large+code+models+on+more+complex+code'}\n",
      "{'title': 'DS-1000: A natural and reliable benchmark for data science code generation', 'authors': ['Y Lai', 'C Li', 'Y Wang', 'T Zhang', 'R Zhong'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=DS-1000:+A+natural+and+reliable+benchmark+for+data+science+code+generation'}\n",
      "{'title': 'The Fault in our Stars: Quality Assessment of Code Generation Benchmarks', 'authors': ['ML Siddiq', 'S Dristi', 'J Saha'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=The+Fault+in+our+Stars:+Quality+Assessment+of+Code+Generation+Benchmarks'}\n",
      "{'title': 'Binary code summarization: Benchmarking chatgpt/gpt-4 and other large language models', 'authors': ['X Jin', 'J Larson', 'W Yang', 'Z Lin'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Binary+code+summarization:+Benchmarking+chatgpt/gpt-4+and+other+large+language+models'}\n",
      "{'title': 'mHumanEval--A Multilingual Benchmark to Evaluate Large Language Models for Code Generation', 'authors': ['N Raihan', 'A Anastasopoulos', 'M Zampieri'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=mHumanEval--A+Multilingual+Benchmark+to+Evaluate+Large+Language+Models+for+Code+Generation'}\n",
      "{'title': 'MultiPL-E: a scalable and polyglot approach to benchmarking neural code generation', 'authors': ['F Cassano', 'J Gouwar', 'D Nguyen'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=MultiPL-E:+a+scalable+and+polyglot+approach+to+benchmarking+neural+code+generation'}\n",
      "{'title': 'Xcodeeval: An execution-based large scale multilingual multitask benchmark for code understanding, generation, translation and retrieval', 'authors': ['MAM Khan', 'MS Bari', 'D Long', 'W Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Xcodeeval:+An+execution-based+large+scale+multilingual+multitask+benchmark+for+code+understanding,+generation,+translation+and+retrieval'}\n",
      "{'title': 'Code generation from flowcharts with texts: A benchmark dataset and an approach', 'authors': ['Z Liu', 'X Hu', 'D Zhou', 'L Li', 'X Zhang'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Code+generation+from+flowcharts+with+texts:+A+benchmark+dataset+and+an+approach'}\n",
      "{'title': 'HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization', 'authors': ['Q Peng', 'Y Chai', 'X Li'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=HumanEval-XL:+A+Multilingual+Code+Generation+Benchmark+for+Cross-lingual+Natural+Language+Generalization'}\n",
      "{'title': 'Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions', 'authors': ['TY Zhuo', 'MC Vu', 'J Chim', 'H Hu', 'W Yu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Bigcodebench:+Benchmarking+code+generation+with+diverse+function+calls+and+complex+instructions'}\n",
      "{'title': 'Cruxeval: A benchmark for code reasoning, understanding and execution', 'authors': ['A Gu', 'B RoziÃ¨re', 'H Leather', 'A Solar-Lezama'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Cruxeval:+A+benchmark+for+code+reasoning,+understanding+and+execution'}\n",
      "{'title': 'PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models', 'authors': ['S Chen', 'X Feng', 'X Han', 'C Liu', 'W Yang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=PPM:+Automated+Generation+of+Diverse+Programming+Problems+for+Benchmarking+Code+Generation+Models'}\n",
      "{'title': 'Testgeneval: A real world unit test generation and test completion benchmark', 'authors': ['K Jain', 'G Synnaeve', 'B RoziÃ¨re'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Testgeneval:+A+real+world+unit+test+generation+and+test+completion+benchmark'}\n",
      "{'title': 'COFFE: A Code Efficiency Benchmark for Code Generation', 'authors': ['Y Peng', 'J Wan', 'Y Li', 'X Ren'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=COFFE:+A+Code+Efficiency+Benchmark+for+Code+Generation'}\n",
      "{'title': 'A Preliminary Study of Multilingual Code Language Models for Code Generation Task Using Translated Benchmarks', 'authors': ['R Dandamudi', 'G RodrÃ­guez-PÃ©rez'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=A+Preliminary+Study+of+Multilingual+Code+Language+Models+for+Code+Generation+Task+Using+Translated+Benchmarks'}\n",
      "{'title': 'Mercury: A code efficiency benchmark for code large language models', 'authors': ['M Du', 'AT Luu', 'B Ji', 'Q Liu', 'SK Ng'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Mercury:+A+code+efficiency+benchmark+for+code+large+language+models'}\n",
      "{'title': 'Coderujb: An executable and unified java benchmark for practical programming scenarios', 'authors': ['Z Zeng', 'Y Wang', 'R Xie', 'W Ye', 'S Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Coderujb:+An+executable+and+unified+java+benchmark+for+practical+programming+scenarios'}\n",
      "{'title': 'Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots', 'authors': ['C Wu', 'Y Ge', 'Q Guo', 'J Wang', 'Z Liang', 'Z Lu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Plot2Code:+A+Comprehensive+Benchmark+for+Evaluating+Multi-modal+Large+Language+Models+in+Code+Generation+from+Scientific+Plots'}\n",
      "{'title': 'Effibench: Benchmarking the efficiency of automatically generated code', 'authors': ['D Huang', 'Y Qing', 'W Shang', 'H Cui'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Effibench:+Benchmarking+the+efficiency+of+automatically+generated+code'}\n",
      "{'title': 'xcodeeval: A large scale multilingual multitask benchmark for code understanding, generation, translation and retrieval', 'authors': ['MAM Khan', 'MS Bari', 'XL Do', 'W Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=xcodeeval:+A+large+scale+multilingual+multitask+benchmark+for+code+understanding,+generation,+translation+and+retrieval'}\n",
      "{'title': 'Lyra: A benchmark for turducken-style code generation', 'authors': ['Q Liang', 'Z Sun', 'Q Zhu', 'W Zhang', 'L Yu', 'Y Xiong'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Lyra:+A+benchmark+for+turducken-style+code+generation'}\n",
      "{'title': 'REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark', 'authors': ['NL Hai', 'DM Nguyen', 'NDQ Bui'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=REPOEXEC:+Evaluate+Code+Generation+with+a+Repository-Level+Executable+Benchmark'}\n",
      "{'title': 'CodeBenchGen: Creating Scalable Execution-based Code Generation Benchmarks', 'authors': ['Y Xie', 'A Xie', 'D Sheth', 'P Liu', 'D Fried', 'C Rose'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CodeBenchGen:+Creating+Scalable+Execution-based+Code+Generation+Benchmarks'}\n",
      "{'title': 'ICG: A machine learning benchmark dataset and baselines for inline code comments generation task', 'authors': ['X Zhang', 'L Chen', 'W Zou', 'Y Cao', 'H Ren'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ICG:+A+machine+learning+benchmark+dataset+and+baselines+for+inline+code+comments+generation+task'}\n",
      "{'title': 'Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation', 'authors': ['J Liu', 'CS Xia', 'Y Wang', 'L Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Is+your+code+generated+by+chatgpt+really+correct?+rigorous+evaluation+of+large+language+models+for+code+generation'}\n",
      "{'title': 'IaC-Eval: A Code Generation Benchmark for Cloud Infrastructure-as-Code Programs', 'authors': ['PTJ Kon', 'J Liu', 'Y Qiu', 'W Fan', 'T He'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=IaC-Eval:+A+Code+Generation+Benchmark+for+Cloud+Infrastructure-as-Code+Programs'}\n",
      "{'title': 'CloudEval-YAML: A Practical Benchmark for Cloud Configuration Generation', 'authors': ['Y Xu', 'Y Chen', 'X Zhang', 'X Lin', 'P Hu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CloudEval-YAML:+A+Practical+Benchmark+for+Cloud+Configuration+Generation'}\n",
      "{'title': 'Boldly Going Where No Benchmark Has Gone Before: Exposing Bias and Shortcomings in Code Generation Evaluation', 'authors': ['A Yadav', 'M Singh'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Boldly+Going+Where+No+Benchmark+Has+Gone+Before:+Exposing+Bias+and+Shortcomings+in+Code+Generation+Evaluation'}\n",
      "{'title': 'Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion', 'authors': ['Y Ding', 'Z Wang', 'W Ahmad', 'H Ding'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Crosscodeeval:+A+diverse+and+multilingual+benchmark+for+cross-file+code+completion'}\n",
      "{'title': 'How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation', 'authors': ['D Zheng', 'Y Wang', 'E Shi', 'H Zhang', 'Z Zheng'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=How+Well+Do+LLMs+Generate+Code+for+Different+Application+Domains?+Benchmark+and+Evaluation'}\n",
      "{'title': 'Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit', 'authors': ['Y Wan', 'Z Bi', 'Y He', 'J Zhang', 'H Zhang', 'Y Sui'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Deep+Learning+for+Code+Intelligence:+Survey,+Benchmark+and+Toolkit'}\n",
      "{'title': 'A survey of large language models for code: Evolution, benchmarking, and future trends', 'authors': ['Z Zheng', 'K Ning', 'Y Wang', 'J Zhang', 'D Zheng'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+survey+of+large+language+models+for+code:+Evolution,+benchmarking,+and+future+trends'}\n",
      "{'title': 'Multipl-e: A scalable and extensible approach to benchmarking neural code generation', 'authors': ['F Cassano', 'J Gouwar', 'D Nguyen', 'S Nguyen'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Multipl-e:+A+scalable+and+extensible+approach+to+benchmarking+neural+code+generation'}\n",
      "{'title': 'StudentEval: a benchmark of student-written prompts for large language models of code', 'authors': ['HML Babe', 'S Nguyen', 'Y Zi', 'A Guha'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=StudentEval:+a+benchmark+of+student-written+prompts+for+large+language+models+of+code'}\n",
      "{'title': 'WebApp1K: A Practical Code-Generation Benchmark for Web App Development', 'authors': ['Y Cui'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=WebApp1K:+A+Practical+Code-Generation+Benchmark+for+Web+App+Development'}\n",
      "{'title': 'Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models', 'authors': ['J Zheng', 'B Cao', 'Z Ma', 'R Pan', 'H Lin', 'Y Lu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Beyond+Correctness:+Benchmarking+Multi-dimensional+Code+Generation+for+Large+Language+Models'}\n",
      "{'title': 'ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation', 'authors': ['DG Paul', 'H Zhu', 'I Bayley'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ScenEval:+A+Benchmark+for+Scenario-Based+Evaluation+of+Code+Generation'}\n",
      "{'title': 'CommitBench: A benchmark for commit message generation', 'authors': ['M Schall', 'T Czinczoll', 'G De Melo'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CommitBench:+A+benchmark+for+commit+message+generation'}\n",
      "{'title': 'Devbench: A comprehensive benchmark for software development', 'authors': ['B Li', 'W Wu', 'Z Tang', 'L Shi', 'J Yang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Devbench:+A+comprehensive+benchmark+for+software+development'}\n",
      "{'title': 'Beyond synthetic benchmarks: Assessing recent LLMs for code generation', 'authors': ['AR Oskooei', 'MS Babacan', 'E YaÄŸcÄ±'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Beyond+synthetic+benchmarks:+Assessing+recent+LLMs+for+code+generation'}\n",
      "{'title': 'DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models', 'authors': ['Y Huang', 'J Luo', 'Y Yu', 'Y Zhang', 'F Lei', 'Y Wei'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DA-Code:+Agent+Data+Science+Code+Generation+Benchmark+for+Large+Language+Models'}\n",
      "{'title': 'Coir: A comprehensive benchmark for code information retrieval models', 'authors': ['X Li', 'K Dong', 'YQ Lee', 'W Xia', 'Y Yin', 'H Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Coir:+A+comprehensive+benchmark+for+code+information+retrieval+models'}\n",
      "{'title': 'Pdebench: An extensive benchmark for scientific machine learning', 'authors': ['M Takamoto', 'T Praditia', 'R Leiteritz'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Pdebench:+An+extensive+benchmark+for+scientific+machine+learning'}\n",
      "{'title': 'Xlcost: A benchmark dataset for cross-lingual code intelligence', 'authors': ['M Zhu', 'A Jain', 'K Suresh', 'R Ravindran'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Xlcost:+A+benchmark+dataset+for+cross-lingual+code+intelligence'}\n",
      "{'title': 'Crocosum: A benchmark dataset for cross-lingual code-switched summarization', 'authors': ['R Zhang', 'C Eickhoff'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Crocosum:+A+benchmark+dataset+for+cross-lingual+code-switched+summarization'}\n",
      "{'title': 'Mercury: An efficiency benchmark for llm code synthesis', 'authors': ['M Du', 'AT Luu', 'B Ji', 'SK Ng'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Mercury:+An+efficiency+benchmark+for+llm+code+synthesis'}\n",
      "{'title': 'CodeLMSec Benchmark: Systematically Evaluating and Finding Security Vulnerabilities in Black-Box Code Language Models', 'authors': ['H Hajipour', 'K Hassler', 'T Holz'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CodeLMSec+Benchmark:+Systematically+Evaluating+and+Finding+Security+Vulnerabilities+in+Black-Box+Code+Language+Models'}\n",
      "{'title': 'CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution', 'authors': ['R Xu', 'J Cao', 'Y Lu', 'H Lin', 'X Han', 'B He'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CRUXEval-X:+A+Benchmark+for+Multilingual+Code+Reasoning,+Understanding+and+Execution'}\n",
      "{'title': 'Benchpress: A deep active benchmark generator', 'authors': ['F Tsimpourlas', 'P Petoumenos', 'M Xu'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchpress:+A+deep+active+benchmark+generator'}\n",
      "{'title': 'CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs', 'authors': ['DN Manh', 'TP Chau', 'NL Hai', 'TT Doan'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CodeMMLU:+A+Multi-Task+Benchmark+for+Assessing+Code+Understanding+Capabilities+of+CodeLLMs'}\n",
      "{'title': 'Codetransocean: A comprehensive multilingual benchmark for code translation', 'authors': ['W Yan', 'Y Tian', 'Y Li', 'Q Chen', 'W Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codetransocean:+A+comprehensive+multilingual+benchmark+for+code+translation'}\n",
      "{'title': 'Benchmarking and explaining large language model-based code generation: A causality-centric approach', 'authors': ['Z Ji', 'P Ma', 'Z Li', 'S Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchmarking+and+explaining+large+language+model-based+code+generation:+A+causality-centric+approach'}\n",
      "{'title': 'On the evaluation of neural code translation: Taxonomy and benchmark', 'authors': ['M Jiao', 'T Yu', 'X Li', 'G Qiu', 'X Gu'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=On+the+evaluation+of+neural+code+translation:+Taxonomy+and+benchmark'}\n",
      "{'title': 'RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation', 'authors': ['Y Wang', 'Y Wang', 'S Wang', 'D Guo', 'J Chen'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=RepoTransBench:+A+Real-World+Benchmark+for+Repository-Level+Code+Translation'}\n",
      "{'title': 'Image scene graph generation (sgg) benchmark', 'authors': ['X Han', 'J Yang', 'H Hu', 'L Zhang', 'J Gao'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Image+scene+graph+generation+(sgg)+benchmark'}\n",
      "{'title': 'Can we benchmark code review studies? a systematic mapping study of methodology, dataset, and metric', 'authors': ['D Wang', 'Y Ueda', 'RG Kula', 'T Ishio'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Can+we+benchmark+code+review+studies?+a+systematic+mapping+study+of+methodology,+dataset,+and+metric'}\n",
      "{'title': 'LibEvolutionEval: A benchmark and study for version-specific code generation', 'authors': ['S Kuhar', 'WU Ahmad', 'Z Wang', 'N Jain', 'H Qian'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=LibEvolutionEval:+A+benchmark+and+study+for+version-specific+code+generation'}\n",
      "{'title': 'Bizbench: A quantitative reasoning benchmark for business and finance', 'authors': ['R Koncel-Kedziorski', 'M Krumdick', 'V Lai'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Bizbench:+A+quantitative+reasoning+benchmark+for+business+and+finance'}\n",
      "{'title': 'Swe-bench+: Enhanced coding benchmark for llms', 'authors': ['R Aleithan', 'H Xue', 'MM Mohajer', 'E Nnorom'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Swe-bench+:+Enhanced+coding+benchmark+for+llms'}\n",
      "{'title': 'RedCode: Risky Code Execution and Generation Benchmark for Code Agents', 'authors': ['C Guo', 'X Liu', 'C Xie', 'A Zhou', 'Y Zeng', 'Z Lin'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=RedCode:+Risky+Code+Execution+and+Generation+Benchmark+for+Code+Agents'}\n",
      "{'title': 'Codeapex: A bilingual programming evaluation benchmark for large language models', 'authors': ['L Fu', 'H Chai', 'S Luo', 'K Du', 'W Zhang', 'L Fan'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codeapex:+A+bilingual+programming+evaluation+benchmark+for+large+language+models'}\n",
      "{'title': 'Qiskit HumanEval: An Evaluation Benchmark For Quantum Code Generative Models', 'authors': ['S Vishwakarma', 'F Harkins', 'S Golecha'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Qiskit+HumanEval:+An+Evaluation+Benchmark+For+Quantum+Code+Generative+Models'}\n",
      "{'title': 'CodeWMBench: An Automated Benchmark for Code Watermarking Evaluation', 'authors': ['BL Wu', 'K Chen', 'Y He', 'G Chen', 'W Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CodeWMBench:+An+Automated+Benchmark+for+Code+Watermarking+Evaluation'}\n",
      "{'title': 'Purple llama cyberseceval: A secure coding benchmark for language models', 'authors': ['M Bhatt', 'S Chennabasappa', 'C Nikolaidis'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Purple+llama+cyberseceval:+A+secure+coding+benchmark+for+language+models'}\n",
      "{'title': 'MTG: A benchmark suite for multilingual text generation', 'authors': ['Y Chen', 'Z Song', 'X Wu', 'D Wang', 'J Xu', 'J Chen'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=MTG:+A+benchmark+suite+for+multilingual+text+generation'}\n",
      "{'title': 'OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models', 'authors': ['S Wang', 'L Ding', 'L Shen', 'Y Luo', 'B Du', 'D Tao'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=OOP:+Object-Oriented+Programming+Evaluation+Benchmark+for+Large+Language+Models'}\n",
      "{'title': \"RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code\", 'authors': ['J Chen', 'Q Zhong', 'Y Wang', 'K Ning', 'Y Liu', 'Z Xu'], 'year': 2024, 'link': \"https://scholar.google.com/scholar_lookup?title=RMCBench:+Benchmarking+Large+Language+Models'+Resistance+to+Malicious+Code\"}\n",
      "{'title': 'A systematic study and comprehensive evaluation of ChatGPT on benchmark datasets', 'authors': ['MTR Laskar', 'MS Bari', 'M Rahman'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+systematic+study+and+comprehensive+evaluation+of+ChatGPT+on+benchmark+datasets'}\n",
      "{'title': 'Viseval: A benchmark for data visualization in the era of large language models', 'authors': ['N Chen', 'Y Zhang', 'J Xu', 'K Ren'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Viseval:+A+benchmark+for+data+visualization+in+the+era+of+large+language+models'}\n",
      "{'title': 'Benchmarking causal study to interpret large language models for source code', 'authors': ['D Rodriguez-Cardenas', 'DN Palacio'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchmarking+causal+study+to+interpret+large+language+models+for+source+code'}\n",
      "{'title': 'Scicode: A research coding benchmark curated by scientists', 'authors': ['M Tian', 'L Gao', 'SD Zhang', 'X Chen', 'C Fan'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Scicode:+A+research+coding+benchmark+curated+by+scientists'}\n",
      "{'title': 'Coderl: Mastering code generation through pretrained models and deep reinforcement learning', 'authors': ['H Le', 'Y Wang', 'AD Gotmare'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Coderl:+Mastering+code+generation+through+pretrained+models+and+deep+reinforcement+learning'}\n",
      "{'title': 'Analysis of rostov-II benchmark using conventional two-step code systems', 'authors': ['J Jang', 'M Hursin', 'W Lee', 'A Pautz', 'M Papadionysiou'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Analysis+of+rostov-II+benchmark+using+conventional+two-step+code+systems'}\n",
      "{'title': 'Crosscodebench: Benchmarking cross-task generalization of source code models', 'authors': ['C Niu', 'C Li', 'V Ng', 'B Luo'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Crosscodebench:+Benchmarking+cross-task+generalization+of+source+code+models'}\n",
      "{'title': 'Code as policies: Language model programs for embodied control', 'authors': ['J Liang', 'W Huang', 'F Xia', 'P Xu'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Code+as+policies:+Language+model+programs+for+embodied+control'}\n",
      "{'title': 'Lampilot: An open benchmark dataset for autonomous driving with language model programs', 'authors': ['Y Ma', 'C Cui', 'X Cao', 'W Ye', 'P Liu', 'J Lu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Lampilot:+An+open+benchmark+dataset+for+autonomous+driving+with+language+model+programs'}\n",
      "{'title': 'Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark', 'authors': ['H Phan', 'A Jannesari'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Evaluating+and+Optimizing+the+Effectiveness+of+Neural+Machine+Translation+in+Supporting+Code+Retrieval+Models:+A+Study+on+the+CAT+Benchmark'}\n",
      "{'title': 'Proving the Coding Interview: A Benchmark for Formally Verified Code Generation', 'authors': ['Q Dougherty', 'R Mehta'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Proving+the+Coding+Interview:+A+Benchmark+for+Formally+Verified+Code+Generation'}\n",
      "{'title': 'RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation', 'authors': ['V Vasilev', 'J Agafonova', 'N Gerasimenko'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=RusCode:+Russian+Cultural+Code+Benchmark+for+Text-to-Image+Generation'}\n",
      "{'title': 'Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code', 'authors': ['T Galimzyanov', 'S Titov', 'Y Golubev'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Drawing+Pandas:+A+Benchmark+for+LLMs+in+Generating+Plotting+Code'}\n",
      "{'title': 'BizBench: A Quantitative Reasoning Benchmark for Business and Finance', 'authors': ['M Krumdick', 'R Koncel-Kedziorski', 'VD Lai'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=BizBench:+A+Quantitative+Reasoning+Benchmark+for+Business+and+Finance'}\n",
      "{'title': 'miniCodeProps: a Minimal Benchmark for Proving Code Properties', 'authors': ['E Lohn', 'S Welleck'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=miniCodeProps:+a+Minimal+Benchmark+for+Proving+Code+Properties'}\n",
      "{'title': 'AL-Bench: A Benchmark for Automatic Logging', 'authors': ['B Tan', 'J Xu', 'Z Zhu', 'P He'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=AL-Bench:+A+Benchmark+for+Automatic+Logging'}\n",
      "{'title': 'Planetarium: A rigorous benchmark for translating text to structured planning languages', 'authors': ['M Zuo', 'FP Velez', 'X Li', 'ML Littman', 'SH Bach'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Planetarium:+A+rigorous+benchmark+for+translating+text+to+structured+planning+languages'}\n",
      "{'title': 'Uda: A benchmark suite for retrieval augmented generation in real-world document analysis', 'authors': ['Y Hui', 'Y Lu', 'H Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Uda:+A+benchmark+suite+for+retrieval+augmented+generation+in+real-world+document+analysis'}\n",
      "{'title': 'Rtllm: An open-source benchmark for design rtl generation with large language model', 'authors': ['Y Lu', 'S Liu', 'Q Zhang', 'Z Xie'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Rtllm:+An+open-source+benchmark+for+design+rtl+generation+with+large+language+model'}\n",
      "{'title': 'TurtleBench: A Visual Programming Benchmark in Turtle Geometry', 'authors': ['S Rismanchian', 'Y Razeghi', 'S Singh'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=TurtleBench:+A+Visual+Programming+Benchmark+in+Turtle+Geometry'}\n",
      "{'title': 'Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code', 'authors': ['N Jiang', 'Q Li', 'L Tan', 'T Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Collu-Bench:+A+Benchmark+for+Predicting+Language+Model+Hallucinations+in+Code'}\n",
      "{'title': 'MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs', 'authors': ['M Abdelatty', 'J Ma', 'S Reda'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=MetRex:+A+Benchmark+for+Verilog+Code+Metric+Reasoning+Using+LLMs'}\n",
      "{'title': 'Intercode: Standardizing and benchmarking interactive coding with execution feedback', 'authors': ['J Yang', 'A Prabhakar'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Intercode:+Standardizing+and+benchmarking+interactive+coding+with+execution+feedback'}\n",
      "{'title': 'CRQBench: A Benchmark of Code Reasoning Questions', 'authors': ['E Dinella', 'S Chandra', 'P Maniatis'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CRQBench:+A+Benchmark+of+Code+Reasoning+Questions'}\n",
      "{'title': 'BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and Multistructured Data', 'authors': ['X Wang', 'Q Cui', 'Y Tao', 'Y Wang', 'Z Chai', 'X Han'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=BabelBench:+An+Omni+Benchmark+for+Code-Driven+Analysis+of+Multimodal+and+Multistructured+Data'}\n",
      "{'title': 'Longbench: A bilingual, multitask benchmark for long context understanding', 'authors': ['Y Bai', 'X Lv', 'J Zhang', 'H Lyu', 'J Tang', 'Z Huang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Longbench:+A+bilingual,+multitask+benchmark+for+long+context+understanding'}\n",
      "{'title': 'CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification', 'authors': ['J Xu', 'B Pang', 'J Qu', 'H Hayashi', 'C Xiong'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=CLOVER:+A+Test+Case+Generation+Benchmark+with+Coverage,+Long-Context,+and+Verification'}\n",
      "{'title': 'Universal benchmark data of the three-dimensional boundary layer blockage and average friction coefficient for in silico code verification', 'authors': ['VR Sanal Kumar', 'V Sankar', 'N Chandrasekaran'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Universal+benchmark+data+of+the+three-dimensional+boundary+layer+blockage+and+average+friction+coefficient+for+in+silico+code+verification'}\n",
      "{'title': 'Repository-level Code Translation Benchmark Targeting Rust', 'authors': ['G Ou', 'M Liu', 'Y Chen', 'X Peng', 'Z Zheng'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Repository-level+Code+Translation+Benchmark+Targeting+Rust'}\n",
      "{'title': 'Towards General Loop Invariant Generation: A Benchmark of Programs with Memory Manipulation', 'authors': ['C Liu', 'X Wu', 'Y Feng', 'Q Cao', 'J Yan'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Towards+General+Loop+Invariant+Generation:+A+Benchmark+of+Programs+with+Memory+Manipulation'}\n",
      "{'title': 'Text2analysis: A benchmark of table question answering with advanced data analysis and unclear queries', 'authors': ['X He', 'M Zhou', 'X Xu', 'X Ma', 'R Ding', 'L Du'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Text2analysis:+A+benchmark+of+table+question+answering+with+advanced+data+analysis+and+unclear+queries'}\n",
      "{'title': 'Measuring coding challenge competence with apps', 'authors': ['D Hendrycks', 'S Basart', 'S Kadavath', 'M Mazeika'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Measuring+coding+challenge+competence+with+apps'}\n",
      "{'title': 'DyPyBench: A benchmark of executable python software', 'authors': ['I Bouzenia', 'BP Krishan', 'M Pradel'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DyPyBench:+A+benchmark+of+executable+python+software'}\n",
      "{'title': 'Swe-bench-java: A github issue resolving benchmark for java', 'authors': ['D Zan', 'Z Huang', 'A Yu', 'S Lin', 'Y Shi', 'W Liu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Swe-bench-java:+A+github+issue+resolving+benchmark+for+java'}\n",
      "{'title': 'CloudEval-YAML: A Realistic and Scalable Benchmark for Cloud Configuration Generation', 'authors': ['Y Xu', 'Y Chen', 'X Zhang', 'X Lin', 'P Hu', 'Y Ma', 'S Lu', 'W Du'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=CloudEval-YAML:+A+Realistic+and+Scalable+Benchmark+for+Cloud+Configuration+Generation'}\n",
      "{'title': 'Exploring and evaluating hallucinations in llm-powered code generation', 'authors': ['F Liu', 'Y Liu', 'L Shi', 'H Huang', 'R Wang', 'Z Yang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Exploring+and+evaluating+hallucinations+in+llm-powered+code+generation'}\n",
      "{'title': 'CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs', 'authors': ['H Yuan', 'J Xu', 'H Pan', 'A Bousseau'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CADTalk:+An+Algorithm+and+Benchmark+for+Semantic+Commenting+of+CAD+Programs'}\n",
      "{'title': 'A multi-scale time-series dataset with benchmark for machine learning in decarbonized energy grids', 'authors': ['X Zheng', 'N Xu', 'L Trinh', 'D Wu', 'T Huang', 'S Sivaranjani'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=A+multi-scale+time-series+dataset+with+benchmark+for+machine+learning+in+decarbonized+energy+grids'}\n",
      "{'title': 'Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving', 'authors': ['E Evstafev'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Token-by-Token+Regeneration+and+Domain+Biases:+A+Benchmark+of+LLMs+on+Advanced+Mathematical+Problem-Solving'}\n",
      "{'title': 'How Should I Build A Benchmark?', 'authors': ['J Cao', 'YK Chan', 'Z Ling', 'W Wang', 'S Li', 'M Liu'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=How+Should+I+Build+A+Benchmark?'}\n",
      "{'title': \"m &m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks\", 'authors': ['Z Ma', 'W Huang', 'J Zhang', 'T Gupta'], 'year': 2024, 'link': \"https://scholar.google.com/scholar_lookup?title=m+&m's:+A+Benchmark+to+Evaluate+Tool-Use+for+multi-step+multi-modal+Tasks\"}\n",
      "{'title': 'Supermarq: A scalable quantum benchmark suite', 'authors': ['T Tomesh', 'P Gokhale', 'V Omole', 'GS Ravi'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Supermarq:+A+scalable+quantum+benchmark+suite'}\n",
      "{'title': 'Dex-Benchmark: datasets and code to evaluate algorithms for transcriptomics data analysis', 'authors': ['Z Xie', 'C Chen', \"A Ma'ayan\"], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Dex-Benchmark:+datasets+and+code+to+evaluate+algorithms+for+transcriptomics+data+analysis'}\n",
      "{'title': 'Self-planning code generation with large language models', 'authors': ['X Jiang', 'Y Dong', 'L Wang', 'Z Fang', 'Q Shang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Self-planning+code+generation+with+large+language+models'}\n",
      "{'title': 'From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing', 'authors': ['J Wei', 'C Tan', 'Q Chen', 'G Wu', 'S Li', 'Z Gao', 'L Sun'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=From+Words+to+Structured+Visuals:+A+Benchmark+and+Framework+for+Text-to-Diagram+Generation+and+Editing'}\n",
      "{'title': 'Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models', 'authors': ['X Li', 'W Chen', 'Q Chu', 'H Li', 'Z Sun', 'R Li', 'C Qian'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Can+Large+Language+Models+Analyze+Graphs+like+Professionals?+A+Benchmark,+Datasets+and+Models'}\n",
      "{'title': 'Active Code Learning: Benchmarking Sample-Efficient Training of Code Models', 'authors': ['Q Hu', 'Y Guo', 'X Xie', 'M Cordy', 'L Ma'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Active+Code+Learning:+Benchmarking+Sample-Efficient+Training+of+Code+Models'}\n",
      "{'title': 'Enabling and scaling the HPCG benchmark on the newest generation Sunway supercomputer with 42 million heterogeneous cores', 'authors': ['Q Zhu', 'H Luo', 'C Yang', 'M Ding', 'W Yin'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Enabling+and+scaling+the+HPCG+benchmark+on+the+newest+generation+Sunway+supercomputer+with+42+million+heterogeneous+cores'}\n",
      "{'title': 'Generation of Benchmark of Software Testing Methods for Java with Realistic Introduced Errors.', 'authors': ['T Potuzak', 'R Lipka'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Generation+of+Benchmark+of+Software+Testing+Methods+for+Java+with+Realistic+Introduced+Errors.'}\n",
      "{'title': 'Self-collaboration code generation via chatgpt', 'authors': ['Y Dong', 'X Jiang', 'Z Jin', 'G Li'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Self-collaboration+code+generation+via+chatgpt'}\n",
      "{'title': 'Zero resource code-switched speech benchmark using speech utterance pairs for multiple spoken languages', 'authors': ['KP Huang', 'CK Yang', 'YK Fu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Zero+resource+code-switched+speech+benchmark+using+speech+utterance+pairs+for+multiple+spoken+languages'}\n",
      "{'title': 'A benchmark generator framework for evolving variant-rich software', 'authors': ['C Derks', 'D StrÃ¼ber', 'T Berger'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+benchmark+generator+framework+for+evolving+variant-rich+software'}\n",
      "{'title': 'Maniskill2: A unified benchmark for generalizable manipulation skills', 'authors': ['J Gu', 'F Xiang', 'X Li', 'Z Ling', 'X Liu', 'T Mu', 'Y Tang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Maniskill2:+A+unified+benchmark+for+generalizable+manipulation+skills'}\n",
      "{'title': 'Tinyml benchmark: Executing fully connected neural networks on commodity microcontrollers', 'authors': ['B Sudharsan', 'S Salerno', 'DD Nguyen'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Tinyml+benchmark:+Executing+fully+connected+neural+networks+on+commodity+microcontrollers'}\n",
      "{'title': 'Preliminary verification of multi-group cross-sections generation and locally heterogeneous transport calculation using OpenMC with CEFR start-up tests benchmark', 'authors': ['H Guo', 'Y Wu', 'X Jin', 'K Feng', 'X Huo', 'H Gu'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Preliminary+verification+of+multi-group+cross-sections+generation+and+locally+heterogeneous+transport+calculation+using+OpenMC+with+CEFR+start-up+tests+benchmark'}\n",
      "{'title': 'Scirepeval: A multi-format benchmark for scientific document representations', 'authors': ['A Singh', \"M D'Arcy\", 'A Cohan', 'D Downey'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Scirepeval:+A+multi-format+benchmark+for+scientific+document+representations'}\n",
      "{'title': \"Don't make your llm an evaluation benchmark cheater\", 'authors': ['K Zhou', 'Y Zhu', 'Z Chen', 'W Chen', 'WX Zhao'], 'year': 2023, 'link': \"https://scholar.google.com/scholar_lookup?title=Don't+make+your+llm+an+evaluation+benchmark+cheater\"}\n",
      "{'title': 'SQL to Stream with S2S: An Automatic Benchmark Generator for the Java Stream API', 'authors': ['F Schiavio', 'A RosÃ ', 'W Binder'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=SQL+to+Stream+with+S2S:+An+Automatic+Benchmark+Generator+for+the+Java+Stream+API'}\n",
      "{'title': \"SantaCoder: don't reach for the stars!\", 'authors': ['LB Allal', 'R Li', 'D Kocetkov', 'C Mou', 'C Akiki'], 'year': 2023, 'link': \"https://scholar.google.com/scholar_lookup?title=SantaCoder:+don't+reach+for+the+stars!\"}\n",
      "{'title': 'Rtlcoder: Outperforming gpt-3.5 in design rtl generation with our open-source dataset and lightweight solution', 'authors': ['S Liu', 'W Fang', 'Y Lu', 'Q Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Rtlcoder:+Outperforming+gpt-3.5+in+design+rtl+generation+with+our+open-source+dataset+and+lightweight+solution'}\n",
      "{'title': 'Turingbench: A benchmark environment for turing test in the age of neural text generation', 'authors': ['A Uchendu', 'Z Ma', 'T Le', 'R Zhang', 'D Lee'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Turingbench:+A+benchmark+environment+for+turing+test+in+the+age+of+neural+text+generation'}\n",
      "{'title': 'Codet5+: Open code large language models for code understanding and generation', 'authors': ['Y Wang', 'H Le', 'AD Gotmare', 'NDQ Bui', 'J Li'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codet5+:+Open+code+large+language+models+for+code+understanding+and+generation'}\n",
      "{'title': 'Gobench: A benchmark suite of real-world go concurrency bugs', 'authors': ['T Yuan', 'G Li', 'J Lu', 'C Liu', 'L Li'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Gobench:+A+benchmark+suite+of+real-world+go+concurrency+bugs'}\n",
      "{'title': 'Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text', 'authors': ['A Al-Lawati', 'J Lucas', 'P Mitra'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Semantic+Captioning:+Benchmark+Dataset+and+Graph-Aware+Few-Shot+In-Context+Learning+for+SQL2Text'}\n",
      "{'title': 'Applying genetic programming to PSB2: the next generation program synthesis benchmark suite', 'authors': ['T Helmuth', 'P Kelly'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Applying+genetic+programming+to+PSB2:+the+next+generation+program+synthesis+benchmark+suite'}\n",
      "{'title': 'OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation', 'authors': ['S Liu', 'Y Lu', 'W Fang', 'M Li', 'Z Xie'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=OpenLLM-RTL:+Open+Dataset+and+Benchmark+for+LLM-Aided+Design+RTL+Generation'}\n",
      "{'title': 'Analysis of C5G7-TD benchmark with a multi-group pin homogenized SP3 code SPHINCS', 'authors': ['HH Cho', 'J Kang', 'JI Yoon', 'HG Joo'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Analysis+of+C5G7-TD+benchmark+with+a+multi-group+pin+homogenized+SP3+code+SPHINCS'}\n",
      "{'title': 'SecBench. js: An executable security benchmark suite for server-side JavaScript', 'authors': ['MHM Bhuiyan', 'AS Parthasarathy'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=SecBench.+js:+An+executable+security+benchmark+suite+for+server-side+JavaScript'}\n",
      "{'title': 'GPTCloneBench: A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench', 'authors': ['AI Alam', 'PR Roy', 'F Al-Omari', 'CK Roy'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=GPTCloneBench:+A+comprehensive+benchmark+of+semantic+clones+and+cross-language+clones+using+GPT-3+model+and+SemanticCloneBench'}\n",
      "{'title': 'Verification of SARAX code system in the reactor core transient calculation based on the simplified EBR-II benchmark', 'authors': ['X Jia', 'Y Zheng', 'X Du', 'Y Wang', 'J Chen'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Verification+of+SARAX+code+system+in+the+reactor+core+transient+calculation+based+on+the+simplified+EBR-II+benchmark'}\n",
      "{'title': 'A competition, benchmark, code, and data for using artificial intelligence to detect lesions in digital breast tomosynthesis', 'authors': ['N Konz', 'M Buda', 'H Gu', 'A Saha', 'J Yang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+competition,+benchmark,+code,+and+data+for+using+artificial+intelligence+to+detect+lesions+in+digital+breast+tomosynthesis'}\n",
      "{'title': 'Can machines read coding manuals yet?â€“a benchmark for building better language models for code understanding', 'authors': ['I Abdelaziz', 'J Dolby', 'J McCusker'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Can+machines+read+coding+manuals+yet?â€“a+benchmark+for+building+better+language+models+for+code+understanding'}\n",
      "{'title': 'Robotwin: Dual-arm robot benchmark with generative digital twins (early version)', 'authors': ['Y Mu', 'T Chen', 'S Peng', 'Z Chen', 'Z Gao', 'Y Zou'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Robotwin:+Dual-arm+robot+benchmark+with+generative+digital+twins+(early+version)'}\n",
      "{'title': 'Verification of Griffin-Pronghorn-Coupled Multiphysics Code System Against CNRS Molten Salt Reactor Benchmark', 'authors': ['MK Jaradat', 'N Choi', 'A Abou-Jaoude'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Verification+of+Griffin-Pronghorn-Coupled+Multiphysics+Code+System+Against+CNRS+Molten+Salt+Reactor+Benchmark'}\n",
      "{'title': 'Large language models are poor medical codersâ€”benchmarking of medical code querying', 'authors': ['A Soroush', 'BS Glicksberg', 'E Zimlichman', 'Y Barash'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Large+language+models+are+poor+medical+codersâ€”benchmarking+of+medical+code+querying'}\n",
      "{'title': 'Two-phase gas and dust free expansion: Three-dimensional benchmark problem for CFD codes', 'authors': ['OP Stoyanovskaya', 'VV Grigoryev', 'AN Suslenkova'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Two-phase+gas+and+dust+free+expansion:+Three-dimensional+benchmark+problem+for+CFD+codes'}\n",
      "{'title': 'CSEPrompts: A Benchmark of Introductory Computer Science Prompts', 'authors': ['N Raihan', 'D Goswami', 'SSC Puspo', 'C Newman'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CSEPrompts:+A+Benchmark+of+Introductory+Computer+Science+Prompts'}\n",
      "{'title': 'A scalable and extensible approach to benchmarking nl2code for 18 programming languages', 'authors': ['F Cassano', 'J Gouwar', 'D Nguyen'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=A+scalable+and+extensible+approach+to+benchmarking+nl2code+for+18+programming+languages'}\n",
      "{'title': 'A linear benchmark between HYMAGYC, MEGA and ORB5 codes using the NLED-AUG test case to study AlfvÃ©nic modes driven by energetic particles', 'authors': ['G Vlad', 'X Wang', 'F Vannini', 'S Briguglio'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=A+linear+benchmark+between+HYMAGYC,+MEGA+and+ORB5+codes+using+the+NLED-AUG+test+case+to+study+AlfvÃ©nic+modes+driven+by+energetic+particles'}\n",
      "{'title': 'How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark', 'authors': ['R Qiu', 'WW Zeng', 'H Tong', 'J Ezick', 'C Lott'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=How+Efficient+is+LLM-Generated+Code?+A+Rigorous+&+High-Standard+Benchmark'}\n",
      "{'title': 'Oran-bench-13k: An open source benchmark for assessing llms in open radio access networks', 'authors': ['P Gajjar', 'VK Shah'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Oran-bench-13k:+An+open+source+benchmark+for+assessing+llms+in+open+radio+access+networks'}\n",
      "{'title': 'IndoNLG: Benchmark and resources for evaluating Indonesian natural language generation', 'authors': ['S Cahyawijaya', 'GI Winata', 'B Wilie', 'K Vincentio'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=IndoNLG:+Benchmark+and+resources+for+evaluating+Indonesian+natural+language+generation'}\n",
      "{'title': 'Interactive code generation via test-driven user-intent formalization', 'authors': ['SK Lahiri', 'S Fakhoury', 'A Naik', 'G Sakkas'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Interactive+code+generation+via+test-driven+user-intent+formalization'}\n",
      "{'title': 'Predicting unstable software benchmarks using static source code features', 'authors': ['C Laaber', 'M Basmaci', 'P Salza'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Predicting+unstable+software+benchmarks+using+static+source+code+features'}\n",
      "{'title': 'LasHeR: A large-scale high-diversity benchmark for RGBT tracking', 'authors': ['C Li', 'W Xue', 'Y Jia', 'Z Qu', 'B Luo'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=LasHeR:+A+large-scale+high-diversity+benchmark+for+RGBT+tracking'}\n",
      "{'title': 'RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects', 'authors': ['A Allam', 'M Shalan'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=RTL-Repo:+A+Benchmark+for+Evaluating+LLMs+on+Large-Scale+RTL+Design+Projects'}\n",
      "{'title': 'Structured chain-of-thought prompting for code generation', 'authors': ['J Li', 'G Li', 'Y Li', 'Z Jin'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Structured+chain-of-thought+prompting+for+code+generation'}\n",
      "{'title': 'Wind turbine noise code benchmark: A comparison and verification exercise', 'authors': ['F Bertagnolio', 'A Fischer', 'C Appel', 'M Herr', 'F Seel'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Wind+turbine+noise+code+benchmark:+A+comparison+and+verification+exercise'}\n",
      "{'title': 'What can large language models do in chemistry? a comprehensive benchmark on eight tasks', 'authors': ['T Guo', 'B Nan', 'Z Liang', 'Z Guo'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=What+can+large+language+models+do+in+chemistry?+a+comprehensive+benchmark+on+eight+tasks'}\n",
      "{'title': 'Rethinking benchmark and contamination for language models with rephrased samples', 'authors': ['S Yang', 'WL Chiang', 'L Zheng', 'JE Gonzalez'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Rethinking+benchmark+and+contamination+for+language+models+with+rephrased+samples'}\n",
      "{'title': 'Backdoorllm: A comprehensive benchmark for backdoor attacks on large language models', 'authors': ['Y Li', 'H Huang', 'Y Zhao', 'X Ma', 'J Sun'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Backdoorllm:+A+comprehensive+benchmark+for+backdoor+attacks+on+large+language+models'}\n",
      "{'title': \"SVGEditBench: A Benchmark Dataset for Quantitative Assessment of LLM's SVG Editing Capabilities\", 'authors': ['K Nishina', 'Y Matsui'], 'year': 2024, 'link': \"https://scholar.google.com/scholar_lookup?title=SVGEditBench:+A+Benchmark+Dataset+for+Quantitative+Assessment+of+LLM's+SVG+Editing+Capabilities\"}\n",
      "{'title': 'Nuclear data processing code FRENDY: A verification with HTTR criticality benchmark experiments', 'authors': ['N Fujimoto', 'K Tada', 'HQ Ho', 'S Hamamoto'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Nuclear+data+processing+code+FRENDY:+A+verification+with+HTTR+criticality+benchmark+experiments'}\n",
      "{'title': 'Repobench: Benchmarking repository-level code auto-completion systems', 'authors': ['T Liu', 'C Xu', 'J McAuley'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Repobench:+Benchmarking+repository-level+code+auto-completion+systems'}\n",
      "{'title': 'A systematic study and comprehensive evaluation of chatgpt on benchmark datasets', 'authors': ['M Tahmid Rahman Laskar', 'M Saiful Bari'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+systematic+study+and+comprehensive+evaluation+of+chatgpt+on+benchmark+datasets'}\n",
      "{'title': 'GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding', 'authors': ['A Diera', 'A Dahou', 'L Galke', 'F Karl', 'F Sihler'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=GenCodeSearchNet:+A+Benchmark+Test+Suite+for+Evaluating+Generalization+in+Programming+Language+Understanding'}\n",
      "{'title': 'Calculation and analysis of SFR core neutronics benchmark with Dragon/Donjon code', 'authors': ['Z Liang', 'Y Wenhua', 'S Guangming', 'S Shouhua'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Calculation+and+analysis+of+SFR+core+neutronics+benchmark+with+Dragon/Donjon+code'}\n",
      "{'title': 'RTLFixer: Automatically fixing RTL syntax errors with large language model', 'authors': ['YD Tsai', 'M Liu', 'H Ren'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=RTLFixer:+Automatically+fixing+RTL+syntax+errors+with+large+language+model'}\n",
      "{'title': 'AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation', 'authors': ['V Pulavarthi', 'D Nandal', 'S Dan', 'D Pal'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=AssertionBench:+A+Benchmark+to+Evaluate+Large-Language+Models+for+Assertion+Generation'}\n",
      "{'title': 'Kv cache compression, but what must we give in return? a comprehensive benchmark of long context capable approaches', 'authors': ['J Yuan', 'H Liu', 'S Zhong', 'YN Chuang', 'S Li'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Kv+cache+compression,+but+what+must+we+give+in+return?+a+comprehensive+benchmark+of+long+context+capable+approaches'}\n",
      "{'title': 'Seal-tools: Self-instruct tool learning dataset for agent tuning and detailed benchmark', 'authors': ['M Wu', 'T Zhu', 'H Han', 'C Tan', 'X Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Seal-tools:+Self-instruct+tool+learning+dataset+for+agent+tuning+and+detailed+benchmark'}\n",
      "{'title': 'Text2kgbench: A benchmark for ontology-driven knowledge graph generation from text', 'authors': ['N Mihindukulasooriya', 'S Tiwari', 'CF Enguix'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Text2kgbench:+A+benchmark+for+ontology-driven+knowledge+graph+generation+from+text'}\n",
      "{'title': 'MSD: A Benchmark Dataset for Floor Plan Generation of Building Complexes', 'authors': ['C Van Engelenburg', 'F Mostafavi', 'E Kuhn'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=MSD:+A+Benchmark+Dataset+for+Floor+Plan+Generation+of+Building+Complexes'}\n",
      "{'title': 'Benchmarking Large Language Models for Bio-Image Analysis Code Generation', 'authors': ['R Haase', 'C Tischer', 'JK HÃ©richÃ©', 'N Scherf'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchmarking+Large+Language+Models+for+Bio-Image+Analysis+Code+Generation'}\n",
      "{'title': 'COLA-Gen: Active learning techniques for automatic code generation of benchmarks', 'authors': ['M Berezov', 'C Ancourt', 'J Zawalska'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=COLA-Gen:+Active+learning+techniques+for+automatic+code+generation+of+benchmarks'}\n",
      "{'title': 'Livebench: A challenging, contamination-free llm benchmark', 'authors': ['C White', 'S Dooley', 'M Roberts', 'A Pal', 'B Feuer'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Livebench:+A+challenging,+contamination-free+llm+benchmark'}\n",
      "{'title': 'Wizardcoder: Empowering code large language models with evol-instruct', 'authors': ['Z Luo', 'C Xu', 'P Zhao', 'Q Sun', 'X Geng', 'W Hu'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Wizardcoder:+Empowering+code+large+language+models+with+evol-instruct'}\n",
      "{'title': 'A Real-World Benchmark for Evaluating Fine-Grained Issue Solving Capabilities of Large Language Models', 'authors': ['R Hu', 'C Peng', 'J Ren', 'B Jiang', 'X Meng', 'Q Wu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=A+Real-World+Benchmark+for+Evaluating+Fine-Grained+Issue+Solving+Capabilities+of+Large+Language+Models'}\n",
      "{'title': 'Pbmr-400 benchmark solution of exercise 1 and 2 using the moose based applications: Mammoth, pronghorn', 'authors': ['P Balestra', 'S Schunert', 'RW Carlsen'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Pbmr-400+benchmark+solution+of+exercise+1+and+2+using+the+moose+based+applications:+Mammoth,+pronghorn'}\n",
      "{'title': 'ProjectTest: A Project-level Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms', 'authors': ['Y Wang', 'C Xia', 'W Zhao', 'J Du', 'C Miao', 'Z Deng'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=ProjectTest:+A+Project-level+Unit+Test+Generation+Benchmark+and+Impact+of+Error+Fixing+Mechanisms'}\n",
      "{'title': 'Movie101: A new movie understanding benchmark', 'authors': ['Z Yue', 'Q Zhang', 'A Hu', 'L Zhang', 'Z Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Movie101:+A+new+movie+understanding+benchmark'}\n",
      "{'title': 'P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs', 'authors': ['Y Zhang', 'B Deng', 'Y Wan', 'B Yang', 'H Wei'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=P-MMEval:+A+Parallel+Multilingual+Multitask+Benchmark+for+Consistent+Evaluation+of+LLMs'}\n",
      "{'title': 'Large Language Model-Driven Structured Output: A Comprehensive Benchmark and Spatial Data Generation Framework', 'authors': ['D Li', 'Y Zhao', 'Z Wang', 'C Jung', 'Z Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Large+Language+Model-Driven+Structured+Output:+A+Comprehensive+Benchmark+and+Spatial+Data+Generation+Framework'}\n",
      "{'title': 'Omniact: A dataset and benchmark for enabling multimodal generalist autonomous agents for desktop and web', 'authors': ['R Kapoor', 'YP Butala', 'M Russak', 'JY Koh'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Omniact:+A+dataset+and+benchmark+for+enabling+multimodal+generalist+autonomous+agents+for+desktop+and+web'}\n",
      "{'title': 'Qwen2. 5-coder technical report', 'authors': ['B Hui', 'J Yang', 'Z Cui', 'J Yang', 'D Liu', 'L Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Qwen2.+5-coder+technical+report'}\n",
      "{'title': 'Verification of the direct transport code SHARK with the JRR-3M macro benchmark', 'authors': ['C Zhao', 'X Peng', 'W Zhao', 'J Feng', 'Y Zhao'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Verification+of+the+direct+transport+code+SHARK+with+the+JRR-3M+macro+benchmark'}\n",
      "{'title': 'Opv2v: An open benchmark dataset and fusion pipeline for perception with vehicle-to-vehicle communication', 'authors': ['R Xu', 'H Xiang', 'X Xia', 'X Han', 'J Li'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Opv2v:+An+open+benchmark+dataset+and+fusion+pipeline+for+perception+with+vehicle-to-vehicle+communication'}\n",
      "{'title': 'NPDP benchmark suite for the evaluation of the effectiveness of automatic optimizing compilers', 'authors': ['M Palkowski', 'W Bielecki'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=NPDP+benchmark+suite+for+the+evaluation+of+the+effectiveness+of+automatic+optimizing+compilers'}\n",
      "{'title': 'Codegen: An open large language model for code with multi-turn program synthesis', 'authors': ['E Nijkamp', 'B Pang', 'H Hayashi', 'L Tu', 'H Wang'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Codegen:+An+open+large+language+model+for+code+with+multi-turn+program+synthesis'}\n",
      "{'title': 'MMCode: Benchmarking Multimodal Large Language Models for Code Generation with Visually Rich Programming Problems', 'authors': ['K Li', 'Y Tian', 'Q Hu', 'Z Luo', 'Z Huang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=MMCode:+Benchmarking+Multimodal+Large+Language+Models+for+Code+Generation+with+Visually+Rich+Programming+Problems'}\n",
      "{'title': 'LEGOBench: Scientific Leaderboard Generation Benchmark', 'authors': ['S Singh', 'S Alam', 'H Malwat', 'M Singh'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=LEGOBench:+Scientific+Leaderboard+Generation+Benchmark'}\n",
      "{'title': 'AuthAttLyzer-V2: Unveiling Code Authorship Attribution using Enhanced Ensemble Learning Models & Generating Benchmark Dataset', 'authors': ['B Joshi', 'SHH Khani', 'A HabibiLashkari'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=AuthAttLyzer-V2:+Unveiling+Code+Authorship+Attribution+using+Enhanced+Ensemble+Learning+Models+&+Generating+Benchmark+Dataset'}\n",
      "{'title': 'DSB: A decision support benchmark for workload-driven and traditional database systems', 'authors': ['B Ding', 'S Chaudhuri', 'J Gehrke'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=DSB:+A+decision+support+benchmark+for+workload-driven+and+traditional+database+systems'}\n",
      "{'title': 'Spring: A high-resolution high-detail dataset and benchmark for scene flow, optical flow and stereo', 'authors': ['L Mehl', 'J Schmalfuss', 'A Jahedi'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Spring:+A+high-resolution+high-detail+dataset+and+benchmark+for+scene+flow,+optical+flow+and+stereo'}\n",
      "{'title': 'DMC-VB: A Benchmark for Representation Learning for Control with Visual Distractors', 'authors': ['J Ortiz', 'A Dedieu', 'W Lehrach'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=DMC-VB:+A+Benchmark+for+Representation+Learning+for+Control+with+Visual+Distractors'}\n",
      "{'title': 'TESTEVAL: Benchmarking Large Language Models for Test Case Generation', 'authors': ['W Wang', 'C Yang', 'Z Wang', 'Y Huang', 'Z Chu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=TESTEVAL:+Benchmarking+Large+Language+Models+for+Test+Case+Generation'}\n",
      "{'title': 'Wfbench: Automated generation of scientific workflow benchmarks', 'authors': ['T Coleman', 'H Casanova', 'K Maheshwari'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Wfbench:+Automated+generation+of+scientific+workflow+benchmarks'}\n",
      "{'title': 'Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change', 'authors': ['K Valmeekam', 'M Marquez', 'A Olmo'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Planbench:+An+extensible+benchmark+for+evaluating+large+language+models+on+planning+and+reasoning+about+change'}\n",
      "{'title': 'TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models', 'authors': ['X Wang', 'Y Zhang', 'T Chen', 'S Gao', 'S Jin', 'X Yang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=TRACE:+A+Comprehensive+Benchmark+for+Continual+Learning+in+Large+Language+Models'}\n",
      "{'title': 'VGBench: A Comprehensive Benchmark of Vector Graphics Understanding and Generation for Large Language Models', 'authors': ['B Zou', 'M Cai', 'J Zhang', 'YJ Lee'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=VGBench:+A+Comprehensive+Benchmark+of+Vector+Graphics+Understanding+and+Generation+for+Large+Language+Models'}\n",
      "{'title': 'A benchmark for automatic medical consultation system: frameworks, tasks and datasets', 'authors': ['W Chen', 'Z Li', 'H Fang', 'Q Yao', 'C Zhong', 'J Hao'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+benchmark+for+automatic+medical+consultation+system:+frameworks,+tasks+and+datasets'}\n",
      "{'title': 'ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation', 'authors': ['D Ghosh Paul', 'H Zhu', 'I Bayley'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ScenEval:+A+Benchmark+for+Scenario-Based+Evaluation+of+Code+Generation'}\n",
      "{'title': 'CausalBench: A Comprehensive Benchmark for Evaluating Causal Reasoning Capabilities of Large Language Models', 'authors': ['Z Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CausalBench:+A+Comprehensive+Benchmark+for+Evaluating+Causal+Reasoning+Capabilities+of+Large+Language+Models'}\n",
      "{'title': 'Wiki Entity Summarization Benchmark', 'authors': ['S Javadi', 'A Moradan', 'M Sorkhpar', 'K Zaporojets'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Wiki+Entity+Summarization+Benchmark'}\n",
      "{'title': 'Results and lessons learned from the Generation IV SCWR-FQT comprehensive Monte Carlo computational benchmark', 'authors': ['B BabcsÃ¡ny', 'V Giusti', 'A Moise', 'P MÃ©szÃ¡ros'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Results+and+lessons+learned+from+the+Generation+IV+SCWR-FQT+comprehensive+Monte+Carlo+computational+benchmark'}\n",
      "{'title': 'Are LLMs good at structured outputs? A benchmark for evaluating structured output capabilities in LLMs', 'authors': ['Y Liu', 'D Li', 'K Wang', 'Z Xiong', 'F Shi', 'J Wang', 'B Li'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Are+LLMs+good+at+structured+outputs?+A+benchmark+for+evaluating+structured+output+capabilities+in+LLMs'}\n",
      "{'title': 'Total loss of flow benchmark in CIRCE-HERO integral test facility', 'authors': ['P Lorusso', 'A Del Nevo', 'V Narcisi', 'F Giannetti'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Total+loss+of+flow+benchmark+in+CIRCE-HERO+integral+test+facility'}\n",
      "{'title': 'AI Cyber Risk Benchmark: Automated Exploitation Capabilities', 'authors': ['D Ristea', 'V Mavroudis', 'C Hicks'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=AI+Cyber+Risk+Benchmark:+Automated+Exploitation+Capabilities'}\n",
      "{'title': 'Code-aware prompting: A study of coverage-guided test generation in regression setting using llm', 'authors': ['G Ryan', 'S Jain', 'M Shang', 'S Wang', 'X Ma'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Code-aware+prompting:+A+study+of+coverage-guided+test+generation+in+regression+setting+using+llm'}\n",
      "{'title': 'Detecting offensive speech in conversational code-mixed dialogue on social media: A contextual dataset and benchmark experiments', 'authors': ['H Madhu', 'S Satapara', 'S Modha', 'T Mandl'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Detecting+offensive+speech+in+conversational+code-mixed+dialogue+on+social+media:+A+contextual+dataset+and+benchmark+experiments'}\n",
      "{'title': 'Verification of multi-group cross-section generation code ARES-MACXS with fusion neutron shielding benchmark OKTAVIAN-Fe', 'authors': ['J Hu', 'B Zhang', 'C Liu', 'N Dai', 'Y Chen'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Verification+of+multi-group+cross-section+generation+code+ARES-MACXS+with+fusion+neutron+shielding+benchmark+OKTAVIAN-Fe'}\n",
      "{'title': 'Benchmarking and defending against indirect prompt injection attacks on large language models', 'authors': ['J Yi', 'Y Xie', 'B Zhu', 'E Kiciman', 'G Sun', 'X Xie'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchmarking+and+defending+against+indirect+prompt+injection+attacks+on+large+language+models'}\n",
      "{'title': 'Crab: Cross-environment agent benchmark for multimodal language model agents', 'authors': ['T Xu', 'L Chen', 'DJ Wu', 'Y Chen', 'Z Zhang', 'X Yao'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Crab:+Cross-environment+agent+benchmark+for+multimodal+language+model+agents'}\n",
      "{'title': 'LLMatic: neural architecture search via large language models and quality diversity optimization', 'authors': ['MU Nasir', 'S Earle', 'J Togelius', 'S James'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=LLMatic:+neural+architecture+search+via+large+language+models+and+quality+diversity+optimization'}\n",
      "{'title': 'Ptsbench: A comprehensive post-training sparsity benchmark towards algorithms and models', 'authors': ['Z Wang', 'J Guo', 'R Gong', 'Y Yong', 'A Liu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Ptsbench:+A+comprehensive+post-training+sparsity+benchmark+towards+algorithms+and+models'}\n",
      "{'title': 'NPDP benchmark suite for loop tiling effectiveness evaluation', 'authors': ['M Palkowski', 'W Bielecki'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=NPDP+benchmark+suite+for+loop+tiling+effectiveness+evaluation'}\n",
      "{'title': 'Chartx & chartvlm: A versatile benchmark and foundation model for complicated chart reasoning', 'authors': ['R Xia', 'B Zhang', 'H Ye', 'X Yan', 'Q Liu', 'H Zhou'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Chartx+&+chartvlm:+A+versatile+benchmark+and+foundation+model+for+complicated+chart+reasoning'}\n",
      "{'title': 'Mojobench: Language modeling and benchmarks for mojo', 'authors': ['N Raihan', 'J Santos', 'M Zampieri'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Mojobench:+Language+modeling+and+benchmarks+for+mojo'}\n",
      "{'title': 'Responsive listening head generation: a benchmark dataset and baseline', 'authors': ['M Zhou', 'Y Bai', 'W Zhang', 'T Yao', 'T Zhao'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Responsive+listening+head+generation:+a+benchmark+dataset+and+baseline'}\n",
      "{'title': 'R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models', 'authors': ['K Deng', 'J Liu', 'H Zhu', 'C Liu', 'J Li', 'J Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=R2C2-Coder:+Enhancing+and+Benchmarking+Real-world+Repository-level+Code+Completion+Abilities+of+Code+Large+Language+Models'}\n",
      "{'title': 'Analysis of the APR1400 Benchmark Using High-Fidelity Pin-Wise Core Calculation Codes', 'authors': ['H Yu', 'H Hong', 'J Yoon'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Analysis+of+the+APR1400+Benchmark+Using+High-Fidelity+Pin-Wise+Core+Calculation+Codes'}\n",
      "{'title': 'DafnyBench: A Benchmark for Formal Software Verification', 'authors': ['C Loughridge', 'Q Sun', 'S Ahrenbach', 'F Cassano'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DafnyBench:+A+Benchmark+for+Formal+Software+Verification'}\n",
      "{'title': 'CONTEST: A unit test completion benchmark featuring context', 'authors': ['J Villmow', 'J Depoix', 'A Ulges'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=CONTEST:+A+unit+test+completion+benchmark+featuring+context'}\n",
      "{'title': 'Qasmbench: A low-level quantum benchmark suite for nisq evaluation and simulation', 'authors': ['A Li', 'S Stein', 'S Krishnamoorthy', 'J Ang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Qasmbench:+A+low-level+quantum+benchmark+suite+for+nisq+evaluation+and+simulation'}\n",
      "{'title': 'GeoQA: A geometric question answering benchmark towards multimodal numerical reasoning', 'authors': ['J Chen', 'J Tang', 'J Qin', 'X Liang', 'L Liu', 'EP Xing'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=GeoQA:+A+geometric+question+answering+benchmark+towards+multimodal+numerical+reasoning'}\n",
      "{'title': 'Tablebench: A comprehensive and complex benchmark for table question answering', 'authors': ['X Wu', 'J Yang', 'L Chai', 'G Zhang', 'J Liu', 'X Du'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Tablebench:+A+comprehensive+and+complex+benchmark+for+table+question+answering'}\n",
      "{'title': 'Hrs-bench: Holistic, reliable and scalable benchmark for text-to-image models', 'authors': ['EM Bakr', 'P Sun', 'X Shen', 'FF Khan'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Hrs-bench:+Holistic,+reliable+and+scalable+benchmark+for+text-to-image+models'}\n",
      "{'title': 'Towards a more user-friendly and easy-to-use benchmark library for recommender systems', 'authors': ['L Xu', 'Z Tian', 'G Zhang', 'J Zhang', 'L Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Towards+a+more+user-friendly+and+easy-to-use+benchmark+library+for+recommender+systems'}\n",
      "{'title': 'Vibrationâ€based monitoring of a smallâ€scale wind turbine blade under varying climate and operational conditions. Part II: A numerical benchmark', 'authors': ['K Tatsis', 'Y Ou', 'VK Dertimanis'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Vibrationâ€based+monitoring+of+a+smallâ€scale+wind+turbine+blade+under+varying+climate+and+operational+conditions.+Part+II:+A+numerical+benchmark'}\n",
      "{'title': 'The colosseum: A benchmark for evaluating generalization for robotic manipulation', 'authors': ['W Pumacay', 'I Singh', 'J Duan', 'R Krishna'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=The+colosseum:+A+benchmark+for+evaluating+generalization+for+robotic+manipulation'}\n",
      "{'title': 'Pptc benchmark: Evaluating large language models for powerpoint task completion', 'authors': ['Y Guo', 'Z Zhang', 'Y Liang', 'D Zhao', 'N Duan'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Pptc+benchmark:+Evaluating+large+language+models+for+powerpoint+task+completion'}\n",
      "{'title': 'A large-scale benchmark for few-shot program induction and synthesis', 'authors': ['F Alet', 'J Lopez-Contreras', 'J Koppel'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=A+large-scale+benchmark+for+few-shot+program+induction+and+synthesis'}\n",
      "{'title': 'ImpactX modeling of benchmark tests for space charge validation', 'authors': ['C Mitchell', 'A Huebl', 'J Qiang', 'R LehÃ©'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ImpactX+modeling+of+benchmark+tests+for+space+charge+validation'}\n",
      "{'title': 'Ceval: A benchmark for evaluating counterfactual text generation', 'authors': ['C Seifert', 'J SchlÃ¶tterer'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Ceval:+A+benchmark+for+evaluating+counterfactual+text+generation'}\n",
      "{'title': 'Using application benchmark call graphs to quantify and improve the practical relevance of microbenchmark suites', 'authors': ['M Grambow', 'C Laaber', 'P Leitner'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Using+application+benchmark+call+graphs+to+quantify+and+improve+the+practical+relevance+of+microbenchmark+suites'}\n",
      "{'title': 'Modeling of OECD/NEA P2M Benchmark Cases by Means of TRANSURANUS Code', 'authors': ['D Rozzia', 'G Bonny', 'S Billiet', 'B Boer'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Modeling+of+OECD/NEA+P2M+Benchmark+Cases+by+Means+of+TRANSURANUS+Code'}\n",
      "{'title': 'Modeling and simulation of VERA core physics benchmark using OpenMC code', 'authors': ['AO Albugami', 'AS Alomari', 'AI Almarshad'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Modeling+and+simulation+of+VERA+core+physics+benchmark+using+OpenMC+code'}\n",
      "{'title': 'Codeupdatearena: Benchmarking knowledge editing on api updates', 'authors': ['ZL Liu', 'S Pandit', 'X Ye', 'E Choi', 'G Durrett'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Codeupdatearena:+Benchmarking+knowledge+editing+on+api+updates'}\n",
      "{'title': 'Followbench: A multi-level fine-grained constraints following benchmark for large language models', 'authors': ['Y Jiang', 'Y Wang', 'X Zeng', 'W Zhong', 'L Li', 'F Mi'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Followbench:+A+multi-level+fine-grained+constraints+following+benchmark+for+large+language+models'}\n",
      "{'title': 'Unified pre-training for program understanding and generation', 'authors': ['WU Ahmad', 'S Chakraborty', 'B Ray'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Unified+pre-training+for+program+understanding+and+generation'}\n",
      "{'title': 'BinSimDB: Benchmark Dataset Construction for Fine-Grained Binary Code Similarity Analysis', 'authors': ['F Zuo', 'C Tompkins', 'Q Zeng', 'L Luo', 'YR Choe'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=BinSimDB:+Benchmark+Dataset+Construction+for+Fine-Grained+Binary+Code+Similarity+Analysis'}\n",
      "{'title': 'Multicode benchmark on simulated Ti K-edge x-ray absorption spectra of Ti-O compounds', 'authors': ['F Meng', 'B Maurer', 'F Peschel', 'S Selcuk'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Multicode+benchmark+on+simulated+Ti+K-edge+x-ray+absorption+spectra+of+Ti-O+compounds'}\n",
      "{'title': 'CyberMetric: a benchmark dataset based on retrieval-augmented generation for evaluating LLMs in cybersecurity knowledge', 'authors': ['N Tihanyi', 'MA Ferrag', 'R Jain', 'T Bisztray'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CyberMetric:+a+benchmark+dataset+based+on+retrieval-augmented+generation+for+evaluating+LLMs+in+cybersecurity+knowledge'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "from scholarly import scholarly\n",
    "\n",
    "# --- Google Scholar Search (Filter by Year) ---\n",
    "def search_google_scholar(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Combine keywords with OR\n",
    "    search_query = scholarly.search_pubs(combined_query)\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_results * 2):  # Fetch extra results to filter later\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            year = int(paper.get(\"bib\", {}).get(\"pub_year\", 0))\n",
    "            if year >= 2021:  # Only keep papers published after 2020\n",
    "                results.append({\n",
    "                    \"title\": paper.get(\"bib\", {}).get(\"title\", \"N/A\"),\n",
    "                    \"authors\": paper.get(\"bib\", {}).get(\"author\", \"N/A\"),\n",
    "                    \"year\": year,\n",
    "                    \"link\": f'https://scholar.google.com/scholar_lookup?title={paper.get(\"bib\", {}).get(\"title\", \"\").replace(\" \", \"+\")}'\n",
    "                })\n",
    "            if len(results) >= num_results:\n",
    "                break\n",
    "        except (StopIteration, ValueError):\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# --- arXiv API Search (Filter by Year) ---\n",
    "def search_arxiv(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Use OR between keywords\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\"search_query\": f\"all:{combined_query}\", \"start\": 0, \"max_results\": num_results * 2}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    feed = feedparser.parse(response.text)\n",
    "\n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        year = int(entry.published[:4])  # Extract year from published date\n",
    "        if year >= 2021:  # Only keep papers published after 2020\n",
    "            results.append({\n",
    "                \"title\": entry.title,\n",
    "                \"authors\": [author.name for author in entry.authors],\n",
    "                \"year\": year,\n",
    "                \"link\": entry.link\n",
    "            })\n",
    "        if len(results) >= num_results:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# --- ðŸ”¥ Perform the Search ---\n",
    "def search_papers_with_year_filter(keywords):\n",
    "    print(f\"\\nðŸ”¹ **Searching for papers with keywords: {', '.join(keywords)} (Published after 2020)**\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ Google Scholar Results:\")\n",
    "    for paper in search_google_scholar(keywords, 1000):\n",
    "        print(paper)\n",
    "\n",
    "    #print(\"\\nðŸ“Œ arXiv Results:\")\n",
    "    #for paper in search_arxiv(keywords):\n",
    "        #print(paper)\n",
    "\n",
    "# --- Run the Search ---\n",
    "keywords = [\"benchmark code summarization\", \"benchmark code generation\"]\n",
    "search_papers_with_year_filter(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Searching for papers with keywords: benchmark code summarization, benchmark code generation, benchmark test case generation, benchmark requirements generation, benchmark code optimization, benchmark code translation (Published after 2020)**\n",
      "\n",
      "ðŸ“Œ Google Scholar Results:\n",
      "{'title': 'Codexglue: A machine learning benchmark dataset for code understanding and generation', 'authors': ['S Lu', 'D Guo', 'S Ren', 'J Huang', 'A Svyatkovskiy'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Codexglue:+A+machine+learning+benchmark+dataset+for+code+understanding+and+generation'}\n",
      "{'title': 'A survey on evaluating large language models in code generation tasks', 'authors': ['L Chen', 'Q Guo', 'H Jia', 'Z Zeng', 'X Wang', 'Y Xu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=A+survey+on+evaluating+large+language+models+in+code+generation+tasks'}\n",
      "{'title': 'JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models', 'authors': ['J Cao', 'Z Chen', 'J Wu', 'SC Cheung', 'C Xu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=JavaBench:+A+Benchmark+of+Object-Oriented+Code+Generation+for+Evaluating+Large+Language+Models'}\n",
      "{'title': 'TESTEVAL: Benchmarking Large Language Models for Test Case Generation', 'authors': ['W Wang', 'C Yang', 'Z Wang', 'Y Huang', 'Z Chu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=TESTEVAL:+Benchmarking+Large+Language+Models+for+Test+Case+Generation'}\n",
      "{'title': 'Codetransocean: A comprehensive multilingual benchmark for code translation', 'authors': ['W Yan', 'Y Tian', 'Y Li', 'Q Chen', 'W Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codetransocean:+A+comprehensive+multilingual+benchmark+for+code+translation'}\n",
      "{'title': 'Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review', 'authors': ['DG Paul', 'H Zhu', 'I Bayley'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Benchmarks+and+Metrics+for+Evaluations+of+Code+Generation:+A+Critical+Review'}\n",
      "{'title': 'RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation', 'authors': ['Y Wang', 'Y Wang', 'S Wang', 'D Guo', 'J Chen'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=RepoTransBench:+A+Real-World+Benchmark+for+Repository-Level+Code+Translation'}\n",
      "{'title': 'Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions', 'authors': ['TY Zhuo', 'MC Vu', 'J Chim', 'H Hu', 'W Yu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Bigcodebench:+Benchmarking+code+generation+with+diverse+function+calls+and+complex+instructions'}\n",
      "{'title': 'Testgeneval: A real world unit test generation and test completion benchmark', 'authors': ['K Jain', 'G Synnaeve', 'B RoziÃ¨re'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Testgeneval:+A+real+world+unit+test+generation+and+test+completion+benchmark'}\n",
      "{'title': 'Codescope: An execution-based multilingual multitask multidimensional benchmark for evaluating llms on code understanding and generation', 'authors': ['W Yan', 'H Liu', 'Y Wang', 'Y Li', 'Q Chen', 'W Wang'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Codescope:+An+execution-based+multilingual+multitask+multidimensional+benchmark+for+evaluating+llms+on+code+understanding+and+generation'}\n",
      "{'title': 'BioCoder: a benchmark for bioinformatics code generation with large language models', 'authors': ['X Tang', 'B Qian', 'R Gao', 'J Chen', 'X Chen'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=BioCoder:+a+benchmark+for+bioinformatics+code+generation+with+large+language+models'}\n",
      "{'title': 'DS-1000: A natural and reliable benchmark for data science code generation', 'authors': ['Y Lai', 'C Li', 'Y Wang', 'T Zhang', 'R Zhong'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=DS-1000:+A+natural+and+reliable+benchmark+for+data+science+code+generation'}\n",
      "{'title': 'Coderujb: An executable and unified java benchmark for practical programming scenarios', 'authors': ['Z Zeng', 'Y Wang', 'R Xie', 'W Ye', 'S Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Coderujb:+An+executable+and+unified+java+benchmark+for+practical+programming+scenarios'}\n",
      "{'title': 'DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation', 'authors': ['Q Zhu', 'J Cao', 'Y Lu', 'H Lin', 'X Han', 'L Sun'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=DOMAINEVAL:+An+Auto-Constructed+Benchmark+for+Multi-Domain+Code+Generation'}\n",
      "{'title': 'A survey of large language models for code: Evolution, benchmarking, and future trends', 'authors': ['Z Zheng', 'K Ning', 'Y Wang', 'J Zhang', 'D Zheng'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=A+survey+of+large+language+models+for+code:+Evolution,+benchmarking,+and+future+trends'}\n",
      "{'title': 'CodeBenchGen: Creating Scalable Execution-based Code Generation Benchmarks', 'authors': ['Y Xie', 'A Xie', 'D Sheth', 'P Liu', 'D Fried', 'C Rose'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CodeBenchGen:+Creating+Scalable+Execution-based+Code+Generation+Benchmarks'}\n",
      "{'title': 'Towards Automating Benchmark Creation: An Experimental Evaluation of Developer-Written, Translated, and Generated Benchmarks', 'authors': ['Y Chen'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Towards+Automating+Benchmark+Creation:+An+Experimental+Evaluation+of+Developer-Written,+Translated,+and+Generated+Benchmarks'}\n",
      "{'title': 'HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization', 'authors': ['Q Peng', 'Y Chai', 'X Li'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=HumanEval-XL:+A+Multilingual+Code+Generation+Benchmark+for+Cross-lingual+Natural+Language+Generalization'}\n",
      "{'title': 'mHumanEval--A Multilingual Benchmark to Evaluate Large Language Models for Code Generation', 'authors': ['N Raihan', 'A Anastasopoulos', 'M Zampieri'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=mHumanEval--A+Multilingual+Benchmark+to+Evaluate+Large+Language+Models+for+Code+Generation'}\n",
      "{'title': 'PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models', 'authors': ['S Chen', 'X Feng', 'X Han', 'C Liu', 'W Yang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=PPM:+Automated+Generation+of+Diverse+Programming+Problems+for+Benchmarking+Code+Generation+Models'}\n",
      "{'title': 'On the evaluation of neural code translation: Taxonomy and benchmark', 'authors': ['M Jiao', 'T Yu', 'X Li', 'G Qiu', 'X Gu'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=On+the+evaluation+of+neural+code+translation:+Taxonomy+and+benchmark'}\n",
      "{'title': 'Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models', 'authors': ['J Zheng', 'B Cao', 'Z Ma', 'R Pan', 'H Lin', 'Y Lu'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Beyond+Correctness:+Benchmarking+Multi-dimensional+Code+Generation+for+Large+Language+Models'}\n",
      "{'title': 'Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit', 'authors': ['Y Wan', 'Z Bi', 'Y He', 'J Zhang', 'H Zhang', 'Y Sui'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Deep+Learning+for+Code+Intelligence:+Survey,+Benchmark+and+Toolkit'}\n",
      "{'title': 'Coir: A comprehensive benchmark for code information retrieval models', 'authors': ['X Li', 'K Dong', 'YQ Lee', 'W Xia', 'Y Yin', 'H Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Coir:+A+comprehensive+benchmark+for+code+information+retrieval+models'}\n",
      "{'title': 'Assessing Code Reasoning in Large Language Models: A Literature Review of Benchmarks and Future Directions', 'authors': ['S Dehghan'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Assessing+Code+Reasoning+in+Large+Language+Models:+A+Literature+Review+of+Benchmarks+and+Future+Directions'}\n",
      "{'title': 'The Fault in our Stars: Quality Assessment of Code Generation Benchmarks', 'authors': ['ML Siddiq', 'S Dristi', 'J Saha'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=The+Fault+in+our+Stars:+Quality+Assessment+of+Code+Generation+Benchmarks'}\n",
      "{'title': 'Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark', 'authors': ['H Phan', 'A Jannesari'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Evaluating+and+Optimizing+the+Effectiveness+of+Neural+Machine+Translation+in+Supporting+Code+Retrieval+Models:+A+Study+on+the+CAT+Benchmark'}\n",
      "{'title': 'Skeleton-Guided-Translation: A Benchmarking Framework for Code Repository Translation with Fine-Grained Quality Evaluation', 'authors': ['X Zhang', 'J Wen', 'F Yang', 'P Zhao', 'Y Kang'], 'year': 2025, 'link': 'https://scholar.google.com/scholar_lookup?title=Skeleton-Guided-Translation:+A+Benchmarking+Framework+for+Code+Repository+Translation+with+Fine-Grained+Quality+Evaluation'}\n",
      "{'title': 'ICG: A machine learning benchmark dataset and baselines for inline code comments generation task', 'authors': ['X Zhang', 'L Chen', 'W Zou', 'Y Cao', 'H Ren'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ICG:+A+machine+learning+benchmark+dataset+and+baselines+for+inline+code+comments+generation+task'}\n",
      "{'title': 'Mercury: A code efficiency benchmark for code large language models', 'authors': ['M Du', 'AT Luu', 'B Ji', 'Q Liu', 'SK Ng'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Mercury:+A+code+efficiency+benchmark+for+code+large+language+models'}\n",
      "{'title': 'Crosscodebench: Benchmarking cross-task generalization of source code models', 'authors': ['C Niu', 'C Li', 'V Ng', 'B Luo'], 'year': 2023, 'link': 'https://scholar.google.com/scholar_lookup?title=Crosscodebench:+Benchmarking+cross-task+generalization+of+source+code+models'}\n",
      "{'title': 'Code generation using machine learning: A systematic review', 'authors': ['E Dehaerne', 'B Dey', 'S Halder', 'S De Gendt'], 'year': 2022, 'link': 'https://scholar.google.com/scholar_lookup?title=Code+generation+using+machine+learning:+A+systematic+review'}\n",
      "{'title': 'CommitBench: A benchmark for commit message generation', 'authors': ['M Schall', 'T Czinczoll', 'G De Melo'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=CommitBench:+A+benchmark+for+commit+message+generation'}\n",
      "{'title': 'Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation', 'authors': ['J Liu', 'CS Xia', 'Y Wang', 'L Zhang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Is+your+code+generated+by+chatgpt+really+correct?+rigorous+evaluation+of+large+language+models+for+code+generation'}\n",
      "{'title': 'ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation', 'authors': ['DG Paul', 'H Zhu', 'I Bayley'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=ScenEval:+A+Benchmark+for+Scenario-Based+Evaluation+of+Code+Generation'}\n",
      "{'title': 'Intercode: Standardizing and benchmarking interactive coding with execution feedback', 'authors': ['J Yang', 'A Prabhakar'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Intercode:+Standardizing+and+benchmarking+interactive+coding+with+execution+feedback'}\n",
      "{'title': 'Complexcodeeval: A benchmark for evaluating large code models on more complex code', 'authors': ['J Feng', 'J Liu', 'C Gao', 'CY Chong', 'C Wang'], 'year': 2024, 'link': 'https://scholar.google.com/scholar_lookup?title=Complexcodeeval:+A+benchmark+for+evaluating+large+code+models+on+more+complex+code'}\n",
      "{'title': 'Lyra: A benchmark for turducken-style code generation', 'authors': ['Q Liang', 'Z Sun', 'Q Zhu', 'W Zhang', 'L Yu', 'Y Xiong'], 'year': 2021, 'link': 'https://scholar.google.com/scholar_lookup?title=Lyra:+A+benchmark+for+turducken-style+code+generation'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "from scholarly import scholarly\n",
    "\n",
    "# --- Google Scholar Search (Filter by Year) ---\n",
    "def search_google_scholar(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Combine keywords with OR\n",
    "    search_query = scholarly.search_pubs(combined_query)\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_results * 2):  # Fetch extra results to filter later\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            year = int(paper.get(\"bib\", {}).get(\"pub_year\", 0))\n",
    "            if year >= 2021:  # Only keep papers published after 2020\n",
    "                results.append({\n",
    "                    \"title\": paper.get(\"bib\", {}).get(\"title\", \"N/A\"),\n",
    "                    \"authors\": paper.get(\"bib\", {}).get(\"author\", \"N/A\"),\n",
    "                    \"year\": year,\n",
    "                    \"link\": f'https://scholar.google.com/scholar_lookup?title={paper.get(\"bib\", {}).get(\"title\", \"\").replace(\" \", \"+\")}'\n",
    "                })\n",
    "            if len(results) >= num_results:\n",
    "                break\n",
    "        except (StopIteration, ValueError):\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# --- arXiv API Search (Filter by Year) ---\n",
    "def search_arxiv(keywords, num_results=5):\n",
    "    combined_query = \" OR \".join(keywords)  # Use OR between keywords\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\"search_query\": f\"all:{combined_query}\", \"start\": 0, \"max_results\": num_results * 2}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    feed = feedparser.parse(response.text)\n",
    "\n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        year = int(entry.published[:4])  # Extract year from published date\n",
    "        if year >= 2021:  # Only keep papers published after 2020\n",
    "            results.append({\n",
    "                \"title\": entry.title,\n",
    "                \"authors\": [author.name for author in entry.authors],\n",
    "                \"year\": year,\n",
    "                \"link\": entry.link\n",
    "            })\n",
    "        if len(results) >= num_results:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# --- ðŸ”¥ Perform the Search ---\n",
    "def search_papers_with_year_filter(keywords):\n",
    "    print(f\"\\nðŸ”¹ **Searching for papers with keywords: {', '.join(keywords)} (Published after 2020)**\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ Google Scholar Results:\")\n",
    "    for paper in search_google_scholar(keywords, 1000):\n",
    "        print(paper)\n",
    "\n",
    "    #print(\"\\nðŸ“Œ arXiv Results:\")\n",
    "    #for paper in search_arxiv(keywords):\n",
    "        #print(paper)\n",
    "\n",
    "# --- Run the Search ---\n",
    "keywords = [\"benchmark code summarization\", \"benchmark code generation\", \"benchmark test case generation\", \"benchmark requirements generation\", \"benchmark code optimization\", \"benchmark code \"]\n",
    "search_papers_with_year_filter(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am analyzing this page: 100\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".main-section\"}\n  (Session info: chrome=133.0.6943.98); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n#0 0x61aaf7f14bba <unknown>\n#1 0x61aaf79b2790 <unknown>\n#2 0x61aaf7a03c80 <unknown>\n#3 0x61aaf7a03e01 <unknown>\n#4 0x61aaf7a52944 <unknown>\n#5 0x61aaf7a29a7d <unknown>\n#6 0x61aaf7a4fccc <unknown>\n#7 0x61aaf7a29823 <unknown>\n#8 0x61aaf79f5a88 <unknown>\n#9 0x61aaf79f6bf1 <unknown>\n#10 0x61aaf7ede15b <unknown>\n#11 0x61aaf7ee20e2 <unknown>\n#12 0x61aaf7ecb01c <unknown>\n#13 0x61aaf7ee2cd4 <unknown>\n#14 0x61aaf7eaf48f <unknown>\n#15 0x61aaf7f034f8 <unknown>\n#16 0x61aaf7f036c9 <unknown>\n#17 0x61aaf7f13a36 <unknown>\n#18 0x76bea0a9caa4 <unknown>\n#19 0x76bea0b29c3c <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 160\u001b[0m\n\u001b[1;32m    156\u001b[0m       parseIEEE(pager_number, init_pgsize, ieee_link, title)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 156\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# acm_url = 'https://dl.acm.org/action/doSearch?AllField='+title+'&pageSize='+str(init_pgsize)+'&startPage=1'\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# acm_url = f\"https://dl.acm.org/action/doSearch?AllField={title}&pageSize={init_pgsize}&startPage={pager_number}\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# sd_url = 'https://www.sciencedirect.com/search?qs='+title+'&date=2022-2024'\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# parse_scienceDirect(init_pgsize, pager_number, sd_url, title)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     ieee_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://ieeexplore.ieee.org/search/searchresult.jsp?queryText=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&highlight=true&returnType=SEARCH&matchPubs=true&ranges=2022_2024_Year&returnFacets=ALL&rowsPerPage=100&pageNumber=1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 156\u001b[0m     \u001b[43mparseIEEE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpager_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_pgsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mieee_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 122\u001b[0m, in \u001b[0;36mparseIEEE\u001b[0;34m(pager_number, pgsize, init_url, keyword)\u001b[0m\n\u001b[1;32m    119\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(init_url)\n\u001b[1;32m    121\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m bidy \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain-section\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m a \u001b[38;5;241m=\u001b[39m bidy\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mTAG_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxpl-results-list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    124\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/york/survey /venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:888\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/york/survey /venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/york/survey /venv/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".main-section\"}\n  (Session info: chrome=133.0.6943.98); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n#0 0x61aaf7f14bba <unknown>\n#1 0x61aaf79b2790 <unknown>\n#2 0x61aaf7a03c80 <unknown>\n#3 0x61aaf7a03e01 <unknown>\n#4 0x61aaf7a52944 <unknown>\n#5 0x61aaf7a29a7d <unknown>\n#6 0x61aaf7a4fccc <unknown>\n#7 0x61aaf7a29823 <unknown>\n#8 0x61aaf79f5a88 <unknown>\n#9 0x61aaf79f6bf1 <unknown>\n#10 0x61aaf7ede15b <unknown>\n#11 0x61aaf7ee20e2 <unknown>\n#12 0x61aaf7ecb01c <unknown>\n#13 0x61aaf7ee2cd4 <unknown>\n#14 0x61aaf7eaf48f <unknown>\n#15 0x61aaf7f034f8 <unknown>\n#16 0x61aaf7f036c9 <unknown>\n#17 0x61aaf7f13a36 <unknown>\n#18 0x76bea0a9caa4 <unknown>\n#19 0x76bea0b29c3c <unknown>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# driver=webdriver.Chrome()\n",
    "# driver.get(\"https://www.facebook.com/\")\n",
    "from selenium.webdriver.common.by import By\n",
    "# from util import io\n",
    "from urllib.parse import urlencode, urlparse, parse_qs\n",
    "from lxml.html import fromstring\n",
    "from requests import get\n",
    "import urllib.request\n",
    "from xml.etree.ElementTree import XML, fromstring\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver \n",
    "import requests\n",
    "import bs4\n",
    "import codecs\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.facebook.com/\")\n",
    "\n",
    "\n",
    "\n",
    "def parse_selenium_text(whole_text, keyword):\n",
    "  new_list = []\n",
    "  lo = whole_text.splitlines()\n",
    "  ss = keyword.split('+')\n",
    "  ss = '|'.join(ss)\n",
    "  for item in lo:\n",
    "    if re.search(r'('+ss+')', item):\n",
    "        new_list.append([item, 'sciencedirect'])\n",
    "  return new_list\n",
    "\n",
    "def write_to_csv(paper_list, filename):\n",
    "  with open(filename+\".csv\", \"a\", newline=\"\") as f:\n",
    "      writer = csv.writer(f, dialect='excel', delimiter='\\n')\n",
    "      writer.writerow(paper_list)\n",
    "\n",
    "def parse_title(title_list):\n",
    "  string_list = []\n",
    "  for item in title_list:\n",
    "    if isinstance(item, bs4.element.Tag):\n",
    "      string_list.append(item.contents[0])\n",
    "    if isinstance(item, bs4.element.NavigableString):\n",
    "      string_list.append(item)\n",
    "  string_list = ' '.join(string_list)\n",
    "  return string_list\n",
    "\n",
    "\n",
    "\n",
    "def newWriter(paper_list, filename):\n",
    "  result_file = open(filename+\".csv\",'a', newline='', encoding=\"utf-8\")\n",
    "  wr = csv.writer(result_file, dialect='excel')\n",
    "  #wr.writerows([[item] for item in paper_list])\n",
    "  wr.writerow([paper_list[0], paper_list[1]])\n",
    "\n",
    "\n",
    "def parse_acm(pager_number, myurl):\n",
    "  paper_list = []\n",
    "  content = requests.get(myurl)\n",
    "\n",
    "  page_soup = soup(content.text, \"html.parser\")\n",
    "\n",
    "  current_page = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[3].contents\n",
    "  if len(current_page) == 2:\n",
    "    return None\n",
    "  for item in current_page:\n",
    "    if isinstance(item, bs4.element.Tag):\n",
    "      if bool(item.attrs) == False:\n",
    "        continue \n",
    "      if item.attrs['class'][0] == 'search__item':\n",
    "        try:\n",
    "          current_paper = item.contents[3].contents[3].contents[1].contents\n",
    "          raw_title_info = current_paper[1].contents[0].contents[0].contents\n",
    "          doi = current_paper[5].contents[0].attrs['href']\n",
    "          pub_place = current_paper[5].contents[0].attrs['title']\n",
    "          title = parse_title(raw_title_info)\n",
    "          print(title)\n",
    "          paper_list.append([title, pub_place])\n",
    "        except:\n",
    "          print('Parse Error!')\n",
    "\n",
    "  write_to_csv(paper_list, 'ACMPaperList')\n",
    "\n",
    "\n",
    "\n",
    "def parse_scienceDirect(init_pgsize, pager_number, myurl, keyword):\n",
    "  headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:63.0) Gecko/20100101 Firefox/63.0'}\n",
    " \n",
    "  content = requests.get(myurl, headers=headers)\n",
    "  driver.get(myurl)\n",
    "  \n",
    "  time.sleep(2)\n",
    "  bidy = driver.find_element(By.CLASS_NAME, 'col-xs-24')\n",
    "  a = bidy.find_element(By.ID, 'srp-results-list')\n",
    "  b = a.find_element(By.CLASS_NAME, 'search-result-wrapper')\n",
    "  print(b)\n",
    "  \n",
    "  list = parse_selenium_text(b.text, keyword)\n",
    "\n",
    "  for item in list:\n",
    "    newWriter(item, 'scienceDirectPaperList')\n",
    "\n",
    "  myurl = 'https://www.sciencedirect.com/search?qs='+ keyword +'&date=2010-2021&offset='+ str(init_pgsize)\n",
    "  print('Analysis of page {} finished'.format(pager_number))\n",
    "  print('Total number of papers extracted so far:', len(list))\n",
    "  pager_number += 1\n",
    "  init_pgsize += 100\n",
    "  parse_scienceDirect(init_pgsize, pager_number, myurl, keyword)\n",
    "\n",
    "\n",
    "def parseIEEE(pager_number, pgsize, init_url, keyword):\n",
    "  print('I am analyzing this page:', pgsize)\n",
    "\n",
    "  llist = []\n",
    "\n",
    "  driver.get(init_url)\n",
    "\n",
    "  time.sleep(2)\n",
    "  bidy = driver.find_element(By.CLASS_NAME,'main-section')\n",
    "  a = bidy.find_element(By.TAG_NAME,'xpl-results-list')\n",
    "  time.sleep(5)\n",
    "  b = a.find_element(By.CLASS_NAME,'List-results-items')\n",
    "\n",
    "  for item in b:\n",
    "    splited = item.text.split('\\n')\n",
    "    llist.append([splited[0], splited[2]])\n",
    "\n",
    "  for item in llist:\n",
    "    newWriter(item, 'IEEEpaperslist')\n",
    "\n",
    "  myurl = 'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText='+keyword+'&highlight=true&returnType=SEARCH&matchPubs=true&ranges=2010_2021_Year&returnFacets=ALL&rowsPerPage='+str(pgsize)+'&pageNumber='+str(pager_number)\n",
    "  print('Analysis of page {} finished'.format(pager_number))\n",
    "  print('Total number of papers extracted so far:', len(llist))\n",
    "  pager_number += 1\n",
    "  pgsize += 100\n",
    "  parseIEEE(pager_number, pgsize, myurl, keyword)\n",
    "\n",
    "\n",
    "def main():\n",
    "  pager_number = 1\n",
    "  init_pgsize = 100\n",
    "\n",
    "  queries = ['benchmark dataset code generation']\n",
    "  for title in queries:\n",
    "      # acm_url = 'https://dl.acm.org/action/doSearch?AllField='+title+'&pageSize='+str(init_pgsize)+'&startPage=1'\n",
    "      # acm_url = f\"https://dl.acm.org/action/doSearch?AllField={title}&pageSize={init_pgsize}&startPage={pager_number}\"\n",
    "      # parse_acm(pager_number, acm_url)\n",
    "\n",
    "      # sd_url = 'https://www.sciencedirect.com/search?qs='+title+'&date=2022-2024'\n",
    "      # parse_scienceDirect(init_pgsize, pager_number, sd_url, title)\n",
    "\n",
    "      ieee_link = f'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={title}&highlight=true&returnType=SEARCH&matchPubs=true&ranges=2022_2024_Year&returnFacets=ALL&rowsPerPage=100&pageNumber=1'\n",
    "      parseIEEE(pager_number, init_pgsize, ieee_link, title)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep+Transfer+Learning+Vulnerability+Detection\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n",
      "'NavigableString' object has no attribute 'contents'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 277\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[38;5;28mprint\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 262\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m   \u001b[38;5;28mprint\u001b[39m(title)\n\u001b[1;32m    261\u001b[0m   init_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://scholar.google.com/scholar?q=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mtitle\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&hl=en&as_sdt=0\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C5&as_ylo=2011&as_yhi=2024\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 262\u001b[0m   \u001b[43mgoogleScholarScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpager_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscholar_pgsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;66;03m# acm_url = 'https://dl.acm.org/action/doSearch?AllField='+title+'&pageSize=100&startPage=1'\u001b[39;00m\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;66;03m# parse_acm(pager_number, acm_url)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m   \u001b[38;5;66;03m# parseIEEE(pager_number, init_pgsize, ieee_link, title)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m   \u001b[38;5;66;03m#parseIEEEBs4(pager_number, ieee_link)\u001b[39;00m\n\u001b[1;32m    273\u001b[0m end \u001b[38;5;241m=\u001b[39m timer()\n",
      "Cell \u001b[0;32mIn[5], line 151\u001b[0m, in \u001b[0;36mgoogleScholarScraper\u001b[0;34m(pager_number, scholar_pgsize, init_url)\u001b[0m\n\u001b[1;32m    148\u001b[0m next_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://scholar.google.com/scholar?start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(scholar_pgsize)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&q=vulnerability+detection+on+source+code+using+deep+learning&hl=en&as_sdt=0,5&as_ylo=2010&as_yhi=2021\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#time.sleep((130-5)*np.random.random()+5)\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[43mgoogleScholarScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpager_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscholar_pgsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 151\u001b[0m, in \u001b[0;36mgoogleScholarScraper\u001b[0;34m(pager_number, scholar_pgsize, init_url)\u001b[0m\n\u001b[1;32m    148\u001b[0m next_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://scholar.google.com/scholar?start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(scholar_pgsize)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&q=vulnerability+detection+on+source+code+using+deep+learning&hl=en&as_sdt=0,5&as_ylo=2010&as_yhi=2021\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#time.sleep((130-5)*np.random.random()+5)\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[43mgoogleScholarScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpager_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscholar_pgsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: googleScholarScraper at line 151 (18 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 151\u001b[0m, in \u001b[0;36mgoogleScholarScraper\u001b[0;34m(pager_number, scholar_pgsize, init_url)\u001b[0m\n\u001b[1;32m    148\u001b[0m next_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://scholar.google.com/scholar?start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(scholar_pgsize)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&q=vulnerability+detection+on+source+code+using+deep+learning&hl=en&as_sdt=0,5&as_ylo=2010&as_yhi=2021\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#time.sleep((130-5)*np.random.random()+5)\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[43mgoogleScholarScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpager_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscholar_pgsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 106\u001b[0m, in \u001b[0;36mgoogleScholarScraper\u001b[0;34m(pager_number, scholar_pgsize, init_url)\u001b[0m\n\u001b[1;32m    104\u001b[0m current_header \u001b[38;5;241m=\u001b[39m randomize_user_agent()\n\u001b[1;32m    105\u001b[0m llist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 106\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m content \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(init_url, headers\u001b[38;5;241m=\u001b[39mcurrent_header)\n\u001b[1;32m    109\u001b[0m page_soup \u001b[38;5;241m=\u001b[39m soup(content\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver \n",
    "import random\n",
    "driver=webdriver.Chrome()\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def loadtxt():\n",
    "  q = []\n",
    "  with open(\"query.txt\", \"r\") as f:\n",
    "    q = [x.strip() for x in f.readlines()]\n",
    "  return q\n",
    "\n",
    "def jsonWriter(file, filename):\n",
    "  with open(filename+'.json', 'a') as f:\n",
    "      json.dump(file, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(paper_list, filename):\n",
    "  result_file = open(filename+\".csv\",'a', newline='', encoding=\"utf-8\")\n",
    "  wr = csv.writer(result_file, dialect='excel')\n",
    "  wr.writerow([paper_list[0], paper_list[1]])\n",
    "\n",
    "def write_to_csv(paper_list, filename):\n",
    "  with open(filename+\".csv\", \"a\", newline=\"\") as f:\n",
    "      writer = csv.writer(f, delimiter='\\n')\n",
    "      writer.writerow(paper_list)\n",
    "\n",
    "def parse_title(title_list):\n",
    "  string_list = []\n",
    "  for item in title_list:\n",
    "    if isinstance(item, bs4.element.Tag):\n",
    "      string_list.append(item.contents[0])\n",
    "    if isinstance(item, bs4.element.NavigableString):\n",
    "      string_list.append(item)\n",
    "  string_list = ' '.join(string_list)\n",
    "  return string_list\n",
    "\n",
    "def parse_selenium_text(whole_text):\n",
    "  new_list = []\n",
    "  lo = whole_text.splitlines()\n",
    "  for item in lo:\n",
    "    if re.search(r'(vulnerability)', item):\n",
    "      new_list.append([item, 'sciencedirect'])\n",
    "  return new_list\n",
    "\n",
    "def randomize_user_agent():\n",
    "  user_agent_list = [\n",
    "  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "  'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "  'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "  ]\n",
    "\n",
    "  for i in range(4):\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "  \n",
    "  headers = {'User-Agent': user_agent}\n",
    "  return headers\n",
    "\n",
    "def parseIEEE(pager_number, pgsize, init_url, keyword):\n",
    "  print('I am analyzing this page:', pgsize)\n",
    "\n",
    "  llist = []\n",
    "\n",
    "  driver.get(init_url)\n",
    "\n",
    "  time.sleep(2)\n",
    "  # bidy = driver.find_element_by_class_name('main-section')\n",
    "  # a = bidy.find_element_by_tag_name('xpl-results-list')\n",
    "  # time.sleep(5)\n",
    "  # b = a.find_elements_by_class_name('List-results-items')\n",
    "  \n",
    "  # bidy = driver.find_element(By.CLASS_NAME,'col')\n",
    "  a = driver.find_element(By.ID,'xplMainContent')\n",
    "  b = a.find_element(By.TAG_NAME,'xpl-results-list')\n",
    "  #llist = parse_selenium_text(a.text)\n",
    "  b = re.split(r'[\\n\\r]+', a.text)\n",
    "  for item in b:\n",
    "    if re.findall(r\"(vulnerability|Vulnerability|bug|defect|detection|Detection)\", item):\n",
    "    #splited = item.text.split('\\n')\n",
    "      llist.append([item, 'IEEE'])\n",
    "\n",
    "  for item in llist:\n",
    "    newWriter(item, 'IEEEpaperslist')\n",
    "\n",
    "  myurl = 'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText='+keyword+'&highlight=true&returnType=SEARCH&matchPubs=true&ranges=2022_2024_Year&returnFacets=ALL&rowsPerPage='+str(pgsize)+'&pageNumber='+str(pager_number)\n",
    "  print('Analysis of page {} finished'.format(pager_number))\n",
    "  print('Total number of papers extracted so far:', len(llist))\n",
    "  pager_number += 1\n",
    "  # pgsize += 100\n",
    "  parseIEEE(pager_number, pgsize, myurl, keyword)\n",
    "\n",
    "\n",
    "def googleScholarScraper(pager_number, scholar_pgsize, init_url):\n",
    "#   print('I am analyzing this page:', scholar_pgsize)\n",
    "  current_header = randomize_user_agent()\n",
    "  llist = []\n",
    "  time.sleep(2)\n",
    "  content = requests.get(init_url, headers=current_header)\n",
    "\n",
    "  page_soup = soup(content.text, \"html.parser\")\n",
    "\n",
    "  try:\n",
    "    paper_list = page_soup.contents[1].contents[1].contents[0].contents[13].contents[1].contents[2].contents[1]\n",
    "    for item in paper_list.contents:\n",
    "      if isinstance(item, bs4.element.Tag):\n",
    "        if len(item.contents) > 1:\n",
    "          if len(item.contents[1].contents[0].contents) == 3:\n",
    "            for i, sub_item in enumerate(item.contents[1].contents[0].contents[2].contents):\n",
    "              if isinstance(sub_item, bs4.element.Tag):\n",
    "                item.contents[1].contents[0].contents[2].contents[i] = sub_item.contents[0]\n",
    "            _ttl = ' '.join(item.contents[1].contents[0].contents[2].contents)\n",
    "            # print(_ttl)\n",
    "            llist.append([_ttl, item.contents[1].contents[1].contents[-1]])\n",
    "          else:\n",
    "            if len(item.contents[1].contents[0].contents[0].contents) == 1:\n",
    "              if isinstance(item.contents[1].contents[0].contents[0].contents[0], bs4.element.Tag):\n",
    "                llist.append(item.contents[1].contents[0].contents[0].contents[0].contents[0])\n",
    "                # print(item.contents[1].contents[0].contents[0].contents[0].contents[0])\n",
    "              else:\n",
    "                llist.append(item.contents[1].contents[0].contents[0].contents[0])\n",
    "                # print(item.contents[1].contents[0].contents[0].contents[0])\n",
    "            if len(item.contents[1].contents[0].contents[0].contents) > 1:\n",
    "              for i, sub_item in enumerate(item.contents[1].contents[0].contents[0].contents):\n",
    "                if isinstance(sub_item, bs4.element.Tag):\n",
    "                  item.contents[1].contents[0].contents[0].contents[i] = sub_item.contents[0]\n",
    "              _ttl = ' '.join(item.contents[1].contents[0].contents[0].contents)\n",
    "              # print(_ttl)\n",
    "              llist.append([_ttl, item.contents[1].contents[1].contents[- 1]])\n",
    "              \n",
    "    write_to_csv(llist, 'scholar3')\n",
    "\n",
    "    # print('Analysis of page {} finished'.format(pager_number))\n",
    "    # print('Total number of papers extracted so far:', len(paper_list))\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "  pager_number += 1\n",
    "  scholar_pgsize += 10\n",
    "\n",
    "  next_page = 'https://scholar.google.com/scholar?start='+str(scholar_pgsize)+'&q=vulnerability+detection+on+source+code+using+deep+learning&hl=en&as_sdt=0,5&as_ylo=2010&as_yhi=2021'\n",
    "  \n",
    "  #time.sleep((130-5)*np.random.random()+5)\n",
    "  googleScholarScraper(pager_number, scholar_pgsize, next_page)\n",
    "      \n",
    "\n",
    "def parse_scienceDirect(init_pgsize, pager_number, myurl, keyword):\n",
    "  \n",
    "  paper_list = []\n",
    "  \n",
    "  headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:63.0) Gecko/20100101 Firefox/63.0'}\n",
    " \n",
    "  content = requests.get(myurl, headers=headers)\n",
    "  driver.get(myurl)\n",
    "  \n",
    "  time.sleep(2)\n",
    "  bidy = driver.find_element(By.CLASS_NAME, 'col-xs-24')\n",
    "  # bidy = driver.find_elements_by_class_name('col-xs-24')\n",
    "  a = bidy.find_element(By.ID, 'srp-results-list')\n",
    "  b = a.find_element(By.CLASS_NAME, 'search-result-wrapper')\n",
    "  #a = bidy.find_elements_by_id('srp-results-list')\n",
    "  #b = a[0].find_element_by_class_name('search-result-wrapper')\n",
    "  \n",
    "  list = parse_selenium_text(b.text)\n",
    "\n",
    "  for item in list:\n",
    "    newWriter(item, 'scienceDirectPaperList')\n",
    "\n",
    "  myurl = 'https://www.sciencedirect.com/search?qs='+ keyword +'&date=2010-2021&offset='+ str(init_pgsize)\n",
    "  print('Analysis of page {} finished'.format(pager_number))\n",
    "  print('Total number of papers extracted so far:', len(list))\n",
    "  pager_number += 1\n",
    "  init_pgsize += 100\n",
    "  parse_scienceDirect(init_pgsize, pager_number, myurl, keyword)\n",
    "\n",
    "\n",
    "def parse_acm(pager_number, myurl):\n",
    "  paper_list = []\n",
    "  content = requests.get(myurl)\n",
    "\n",
    "  page_soup = soup(content.text, \"html.parser\")\n",
    " \n",
    "  current_page = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[3]\n",
    "  # current_page = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[1].contents\n",
    "  if len(current_page) == 2:\n",
    "    return None\n",
    "  for item in current_page:\n",
    "    if isinstance(item, bs4.element.Tag):\n",
    "      if bool(item.attrs) == False:\n",
    "        continue \n",
    "      if item.attrs['class'][0] == 'search__item':\n",
    "        try:\n",
    "          110\n",
    "          # current_paper = item.contents[3].contents[3].contents[1].contents\n",
    "          # raw_title_info = current_paper[1].contents[0].contents[0].contents\n",
    "          # doi = current_paper[5].contents[0].attrs['href']\n",
    "          # pub_place = current_paper[5].contents[0].attrs['title']\n",
    "          title = item.contents[1].contents[1].contents[0].contents[0].text\n",
    "          # title = parse_title(title)\n",
    "          detail = item.contents[1].contents[1].contents[0].contents[2].text\n",
    "          print(title)\n",
    "          paper_list.append([title, detail])\n",
    "        except:\n",
    "          print('Parse Error!')\n",
    "\n",
    "  write_to_csv(paper_list, 'ACMPaperList')\n",
    "\n",
    "  if pager_number == 1:\n",
    "    myurl = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[4].contents[2].contents[0].attrs['href']\n",
    "  else:\n",
    "    myurl = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[4].contents[2].contents[0].attrs['href']\n",
    "  \n",
    "  print('Analysis of page {} finished'.format(pager_number))\n",
    "  print('Total number of papers extracted so far:', len(paper_list))\n",
    "  pager_number += 1\n",
    "  parse_acm(pager_number, myurl)\n",
    "\n",
    "def parseIEEErecursive(pager_number, myurl):\n",
    "  paper_list = []\n",
    "  content = requests.get(myurl)\n",
    "\n",
    "  page_soup = soup(content.text, \"html.parser\")\n",
    "  current_page = page_soup.contents[2].contents[2].contents[9].contents[1].contents[3].contents[1].contents[0].contents[1].contents[3].contents[3]\n",
    "  parseIEEErecursive()\n",
    "\n",
    "\n",
    "def parseIEEEBs4(pageNumber, myurl):\n",
    "  content = requests.get(myurl)\n",
    "\n",
    "  page_soup = soup(content.text, \"html.parser\")\n",
    "  print('')\n",
    "\n",
    "def main():\n",
    "  start = timer()\n",
    "  pager_number = 1\n",
    "  init_pgsize = 100\n",
    "  scholar_pgsize = 450\n",
    "\n",
    "  # queries = loadtxt()\n",
    "  queries = [\n",
    "            # 'Vulnerability+detection',\n",
    "            'Deep+Transfer+Learning+Vulnerability+Detection',\n",
    "            'Transfer+Learning+Software+Vulnerability+Detection',\n",
    "            'Transfer+Learning+Software+Bug+Detection',\n",
    "            # 'Software+vulnerability+detection',\n",
    "            # 'Vulnerability+detection+using+deep+learning',\n",
    "            # 'Source+code+security+bug+prediction',\n",
    "            # 'Source+code+vulnerability+detection',\n",
    "            # 'Source+code+bug+detection',\n",
    "            # 'Vulnerability+detection+on+source+code+using+deep+learning'\n",
    "    ]\n",
    "  for title in queries:\n",
    "    print(title)\n",
    "    init_url = 'https://scholar.google.com/scholar?q='+title+'&hl=en&as_sdt=0%2C5&as_ylo=2011&as_yhi=2024'\n",
    "    googleScholarScraper(pager_number, scholar_pgsize, init_url)\n",
    "\n",
    "    acm_url = 'https://dl.acm.org/action/doSearch?AllField='+title+'&pageSize=100&startPage=1'\n",
    "    parse_acm(pager_number, acm_url)\n",
    "\n",
    "    sd_url = 'https://www.sciencedirect.com/search?qs='+title+'&date=2010-2022'\n",
    "    parse_scienceDirect(init_pgsize, pager_number, sd_url, title)\n",
    "\n",
    "    ieee_link = 'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText='+title+'&highlight=true&returnType=SEARCH&matchPubs=true&ranges=2022_2024_Year&returnFacets=ALL&rowsPerPage=100&pageNumber=1'\n",
    "    parseIEEE(pager_number, init_pgsize, ieee_link, title)\n",
    "    parseIEEEBs4(pager_number, ieee_link)\n",
    "  end = timer()\n",
    "  print(end-start)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Benchmark+Dataset+Code+Generation+LLM\n",
      "No IEEE results found\n",
      "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "No IEEE results found\n",
      "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
      "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
      "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "No IEEE results found\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "No IEEE results found\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def loadtxt():\n",
    "    return [line.strip() for line in open(\"query.txt\", \"r\")]\n",
    "\n",
    "def jsonWriter(data, filename):\n",
    "    with open(f'{filename}.json', 'a') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(row, filename):\n",
    "    with open(f'{filename}.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def randomize_user_agent():\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    ]\n",
    "    return {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        cookie_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept') or contains(., 'Agree')]\"))\n",
    "        )\n",
    "        cookie_btn.click()\n",
    "        time.sleep(1)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def google_scholar_scraper(query, start=0):\n",
    "    base_url = f\"https://scholar.google.com/scholar?start={start}&q={query}&hl=en&as_sdt=0,5\"\n",
    "    driver.get(base_url)\n",
    "    time.sleep(20)\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    \n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"gs_ri\"))\n",
    "        )\n",
    "        \n",
    "        papers = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find_element(By.TAG_NAME, 'h3').text\n",
    "                link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                papers.append([title, link])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'GoogleScholarPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No results found or page didn't load\")\n",
    "        return 0\n",
    "\n",
    "def parse_ieee(keyword, page=1):\n",
    "    url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword}&pageNumber={page}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".List-results-items\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h3 a\").text\n",
    "                year = item.find_element(By.XPATH, \".//*[contains(text(), 'Year:')]\").text.split()[-1]\n",
    "                papers.append([title, f\"IEEE {year}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'IEEEPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No IEEE results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_science_direct(keyword, offset=0):\n",
    "    url = f\"https://www.sciencedirect.com/search?qs={keyword}&offset={offset}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    handle_cookie_consent()\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".result-list-content\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \".result-item-title\").text\n",
    "                details = item.find_element(By.CSS_SELECTOR, \".result-item-subtype\").text\n",
    "                papers.append([title, f\"ScienceDirect: {details}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'ScienceDirectPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No ScienceDirect results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_acm(query, page=1):\n",
    "    url = f\"https://dl.acm.org/action/doSearch?AllField={query}&startPage={page-1}&pageSize=50\"\n",
    "    response = requests.get(url, headers=randomize_user_agent())\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    for item in soup.select('.issue-item__title'):\n",
    "        try:\n",
    "            title = item.text.strip()\n",
    "            link = \"https://dl.acm.org\" + item.find('a')['href']\n",
    "            papers.append([title, link])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for paper in papers:\n",
    "        newWriter(paper, 'ACMPapers')\n",
    "    \n",
    "    return len(papers)\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        'Benchmark+Dataset+Code+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Summarization+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        'Benchmark+Dataset+Patch+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Optimization+LLM',\n",
    "        'Benchmark+Dataset+Code+Translation+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"Processing: {query}\")\n",
    "        \n",
    "        # Google Scholar (needs careful handling)\n",
    "        for page in range(0, 15):  # First 5 pages\n",
    "            count = google_scholar_scraper(query, start=page*10)\n",
    "            if count == 0: break\n",
    "        \n",
    "        # IEEE\n",
    "        for page in range(1, 15):  # First 5 pages\n",
    "            count = parse_ieee(query, page)\n",
    "            if count < 10: break\n",
    "        \n",
    "        # ScienceDirect\n",
    "        #for offset in range(0, 500, 100):  # First 5 pages\n",
    "            #count = parse_science_direct(query, offset)\n",
    "            #if count < 20: break\n",
    "        \n",
    "        # ACM\n",
    "        for page in range(1, 15):  # First 5 pages\n",
    "            count = parse_acm(query, page)\n",
    "            if count < 10: break\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
      "No ScienceDirect results found\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
      "No ScienceDirect results found\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def loadtxt():\n",
    "    return [line.strip() for line in open(\"query.txt\", \"r\")]\n",
    "\n",
    "def jsonWriter(data, filename):\n",
    "    with open(f'{filename}.json', 'a') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(row, filename):\n",
    "    with open(f'{filename}.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def randomize_user_agent():\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    ]\n",
    "    return {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        cookie_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept') or contains(., 'Agree')]\"))\n",
    "        )\n",
    "        cookie_btn.click()\n",
    "        time.sleep(1)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def is_recent_publication(year_text):\n",
    "    try:\n",
    "        year = int(re.search(r'\\d{4}', year_text).group())\n",
    "        return year >= 2020\n",
    "    except (AttributeError, ValueError):\n",
    "        return False\n",
    "\n",
    "def google_scholar_scraper(query, start=0):\n",
    "    base_url = f\"https://scholar.google.com/scholar?start={start}&q={query}&hl=en&as_sdt=0,5&as_ylo=2020\"\n",
    "    driver.get(base_url)\n",
    "    time.sleep(20)\n",
    "\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    \n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"gs_ri\"))\n",
    "        )\n",
    "        \n",
    "        papers = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find_element(By.TAG_NAME, 'h3').text\n",
    "                link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                year_text = result.find_element(By.CLASS_NAME, 'gs_a').text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, link, year_text])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'GoogleScholarPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No results found or page didn't load\")\n",
    "        return 0\n",
    "\n",
    "def parse_ieee(keyword, page=1):\n",
    "    url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword}&pageNumber={page}&ranges=2020_{datetime.now().year}_Year\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".List-results-items\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h3 a\").text\n",
    "                year_text = item.find_element(By.XPATH, \".//*[contains(text(), 'Year:')]\").text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, f\"IEEE {year_text}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'IEEEPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No IEEE results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_science_direct(keyword, offset=0):\n",
    "    url = f\"https://www.sciencedirect.com/search?qs={keyword}&offset={offset}&date=2020-{datetime.now().year}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    handle_cookie_consent()\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".result-list-content\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \".result-item-title\").text\n",
    "                year_text = item.find_element(By.CSS_SELECTOR, \".subType\").text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, f\"ScienceDirect: {year_text}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'ScienceDirectPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No ScienceDirect results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_acm(query, page=1):\n",
    "    url = f\"https://dl.acm.org/action/doSearch?AllField={query}&startPage={page-1}&pageSize=50&AfterYear=2020\"\n",
    "    response = requests.get(url, headers=randomize_user_agent())\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    for item in soup.select('.issue-item__title'):\n",
    "        try:\n",
    "            title = item.text.strip()\n",
    "            link = \"https://dl.acm.org\" + item.find('a')['href']\n",
    "            year_text = item.find_next(class_='bookPubDate').text\n",
    "            \n",
    "            if is_recent_publication(year_text):\n",
    "                papers.append([title, link, year_text])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for paper in papers:\n",
    "        newWriter(paper, 'ACMPapers')\n",
    "    \n",
    "    return len(papers)\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        'Benchmark+Dataset+Program+Repair+LLM',\n",
    "        'Benchmark+Dataset+Requirement+Generation+LLM',\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"Processing: {query}\")\n",
    "        \n",
    "        # Google Scholar\n",
    "        #for page in range(0, 15):  # First 5 pages\n",
    "            #count = google_scholar_scraper(query, start=page*10)\n",
    "            #if count == 0: break\n",
    "        \n",
    "        # IEEE\n",
    "        #for page in range(1, 16):  # First 5 pages\n",
    "            #count = parse_ieee(query, page)\n",
    "            #if count < 10: break\n",
    "        \n",
    "        # ScienceDirect\n",
    "        for offset in range(0, 500, 100):  # First 5 pages\n",
    "            count = parse_science_direct(query, offset)\n",
    "            if count < 20: break\n",
    "        \n",
    "        # ACM\n",
    "        #for page in range(1, 16):  # First 5 pages\n",
    "            #count = parse_acm(query, page)\n",
    "            #if count < 10: break\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Benchmark+Dataset+Code+Generation+LLM+Large+Language+Model',\n",
    "'Benchmark+Dataset+Code+Summarization+LLM',\n",
    "'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "'Benchmark+Dataset+Patch+Generation+LLM',\n",
    "'Benchmark+Dataset+Code+Optimization+LLM',\n",
    "'Benchmark+Dataset+Code+Translation+LLM',\n",
    "'Benchmark+Dataset+Program+Repair+LLM',\n",
    "'Benchmark+Dataset+Requirement+Generation+LLM',\n",
    "'Benchmark+Dataset+Software+Development+LLM',\n",
    "'Benchmark+Dataset+Software+Engineering+LLM',\n",
    "'Benchmark+Dataset+Code+Review+LLM',\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Benchmark+Code+Generation',\n",
    "'Benchmark+Code+Summarization',\n",
    "'Benchmark+Code+Test+Cases+Generation',\n",
    "'Benchmark+Patch+Generation',\n",
    "'Benchmark+Code+Optimization',\n",
    "'Benchmark+Code+Translation',\n",
    "'Benchmark+Code+Test+Cases+Generation',\n",
    "'Benchmark+Code+Test+Cases+Generation',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Benchmark+Dataset+Code+Generation+LLM\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 69\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 10\n",
      "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 6\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 1\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 24\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
      "number of papers for google scholar: 199\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 2\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
      "No results found or page didn't load\n",
      "179\n",
      "number of papers for google scholar: 179\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 8\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 4\n",
      "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 18\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 4\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 8\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 3\n",
      "Processing: Benchmark+Dataset+Software+Development+LLM\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 40\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 2\n",
      "Processing: Benchmark+Dataset+Software+Engineering+LLM\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 56\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 1\n",
      "Processing: Benchmark+Dataset+Code+Review+LLM\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 8\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 2\n",
      "Processing: Benchmark+Dataset+Code+Generation+Large+Language+Model\n",
      "number of papers for google scholar: 198\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 141\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 17\n",
      "Processing: Benchmark+Dataset+Code+Summarization+Large+Language+Model\n",
      "number of papers for google scholar: 197\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 28\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 2\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model\n",
      "number of papers for google scholar: 200\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 38\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 1\n",
      "Processing: Benchmark+Dataset+Patch+Generation+Large+Language+Model\n",
      "number of papers for google scholar: 197\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 14\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Code+Optimization+Large+Language+Model\n",
      "number of papers for google scholar: 198\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 34\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 8\n",
      "Processing: Benchmark+Dataset+Code+Translation+Large+Language+Model\n",
      "number of papers for google scholar: 199\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 44\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 1\n",
      "Processing: Benchmark+Dataset+Program+Repair+Large+Language+Model\n",
      "number of papers for google scholar: 199\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 18\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 0\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+Large+Language+Model\n",
      "number of papers for google scholar: 199\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 24\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 4\n",
      "Processing: Benchmark+Dataset+Software+Development+Large+Language+Model\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 83\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 3\n",
      "Processing: Benchmark+Dataset+Software+Engineering+Large+Language+Model\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 145\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 2\n",
      "Processing: Benchmark+Dataset+Code+Review+Large+Language+Model\n",
      "No results found or page didn't load\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "No IEEE results found\n",
      "number of papers for IEEE: 36\n",
      "No ScienceDirect results found\n",
      "number of papers for science direct: 3\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def loadtxt():\n",
    "    return [line.strip() for line in open(\"query.txt\", \"r\")]\n",
    "\n",
    "def jsonWriter(data, filename):\n",
    "    with open(f'{filename}.json', 'a') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(row, filename):\n",
    "    with open(f'{filename}.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def randomize_user_agent():\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    ]\n",
    "    return {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        cookie_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept') or contains(., 'Agree') or contains(., 'OK')]\"))\n",
    "        )\n",
    "        cookie_btn.click()\n",
    "        time.sleep(2)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def is_recent_publication(year_text):\n",
    "    try:\n",
    "        year = int(re.search(r'\\d{4}', year_text).group())\n",
    "        return year >= 2020\n",
    "    except (AttributeError, ValueError):\n",
    "        return False\n",
    "        \n",
    "def google_scholar_scraper(query, start=0):\n",
    "    base_url = f\"https://scholar.google.com/scholar?start={start}&q={query}&hl=en&as_sdt=0,5&as_ylo=2020\"\n",
    "    driver.get(base_url)\n",
    "    if start == 0:\n",
    "        time.sleep(20)\n",
    "    else:\n",
    "        time.sleep(random.uniform(2,4))\n",
    "    \n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"gs_ri\"))\n",
    "        )\n",
    "        \n",
    "        papers = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find_element(By.TAG_NAME, 'h3').text\n",
    "                link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                year_text = result.find_element(By.CLASS_NAME, 'gs_a').text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, link, year_text])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'GoogleScholarPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No results found or page didn't load\")\n",
    "        return 0\n",
    "\n",
    "def parse_ieee(keyword, page=0):\n",
    "    url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword}&pageNumber={page}&ranges=2020_{datetime.now().year}_Year\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".List-results-items\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h3 a\").text\n",
    "                year_text = item.find_element(By.XPATH, \".//*[contains(text(), 'Year:')]\").text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, f\"IEEE {year_text}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'IEEEPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No IEEE results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_science_direct(keyword, offset=0):\n",
    "    \"\"\"Scrapes ScienceDirect search results for paper titles and links.\"\"\"\n",
    "    \n",
    "    url = f'https://www.sciencedirect.com/search?date=2020-2025&tak={keyword}&offset={offset}'\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    handle_cookie_consent()\n",
    "\n",
    "    papers = []\n",
    "    \n",
    "    try:\n",
    "        # Wait until search results load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"result-item-container\"))\n",
    "        )\n",
    "        \n",
    "        results = driver.find_elements(By.CLASS_NAME, \"result-item-container\")\n",
    "\n",
    "        for item in results:\n",
    "            try:\n",
    "                title_element = item.find_element(By.TAG_NAME, 'h2').find_element(By.TAG_NAME, 'a')\n",
    "                title = title_element.text\n",
    "                link = title_element.get_attribute('href')\n",
    "                papers.append([title, link])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping item due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'ScienceDirectPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No ScienceDirect results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_acm(query, page):\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?field1=TitleAbstract&text1={query}&AfterYear=2020&startPage={page-1}&pageSize=50\"\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField={query}&pageSize=20&startPage={page-1}\"\n",
    "    url = f'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&field1=Title&text1={query}&field2=Abstract&text2={query}&AfterYear=2020&pageSize=20&startPage={page-1}'\n",
    "    #'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField={query}&pageSize=20&startPage={page-1}'\n",
    "    #https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField=+AND+AllField%3A%28benchmark+dataset+code+generation+llm%29&pageSize=20&startPage=1\n",
    "    response = requests.get(url, headers=randomize_user_agent())\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    for item in soup.select('.issue-item__title'):\n",
    "        try:\n",
    "            title = item.text.strip()\n",
    "            link = \"https://dl.acm.org\" + item.find('a')['href']\n",
    "            year_text = item.find_next(class_='bookPubDate').text\n",
    "            \n",
    "            if is_recent_publication(year_text):\n",
    "                papers.append([title, link, year_text])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for paper in papers:\n",
    "        newWriter(paper, 'ACMPapers')\n",
    "    \n",
    "    print(f'ACM: {len(papers)}')\n",
    "    return len(papers)\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        'Benchmark+Dataset+Code+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Summarization+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        'Benchmark+Dataset+Patch+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Optimization+LLM',\n",
    "        'Benchmark+Dataset+Code+Translation+LLM',\n",
    "        'Benchmark+Dataset+Program+Repair+LLM',\n",
    "        'Benchmark+Dataset+Requirement+Generation+LLM',\n",
    "        'Benchmark+Dataset+Software+Development+LLM',\n",
    "        'Benchmark+Dataset+Software+Engineering+LLM',\n",
    "        'Benchmark+Dataset+Code+Review+LLM',\n",
    "        'Benchmark+Dataset+Code+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Summarization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Patch+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Optimization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Translation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Program+Repair+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Requirement+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Development+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Engineering+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Review+Large+Language+Model'\n",
    "        ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"Processing: {query}\")\n",
    "        \n",
    "        # Google Scholar\n",
    "        count_total = 0\n",
    "        for page in range(0, 20):  # First 5 pages\n",
    "            count = google_scholar_scraper(query, start=page*10)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 19:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "        \n",
    "        # IEEE\n",
    "        #count_total = 0\n",
    "        #for page in range(0, 20):  # First 5 pages\n",
    "            #count = parse_ieee(query, page)\n",
    "            #count_total+=count\n",
    "            #if count == 0: \n",
    "                #print(f'number of papers for IEEE: {count_total}')\n",
    "                #break\n",
    "\n",
    "        # ScienceDirect\n",
    "        #count_total = 0\n",
    "        #for offset in range(0, 250, 25):  # First 5 pages\n",
    "            #count = parse_science_direct(query, offset)\n",
    "            #count_total+=count\n",
    "            #if count == 0:  \n",
    "                #print(f'number of papers for science direct: {count_total}') \n",
    "                #break\n",
    "        \n",
    "        # ACM\n",
    "        count_total = 0\n",
    "        for page in range(1, 6):  # First 5 pages\n",
    "            count = parse_acm(query, page)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 11:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Benchmark+Dataset+Code+Generation+LLM\n",
      "ACM: 19\n",
      "ACM: 11\n",
      "ACM: 0\n",
      "30\n",
      "number of papers for google scholar: 30\n",
      "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "ACM: 2\n",
      "ACM: 0\n",
      "2\n",
      "number of papers for google scholar: 2\n",
      "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
      "ACM: 5\n",
      "ACM: 0\n",
      "5\n",
      "number of papers for google scholar: 5\n",
      "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
      "ACM: 4\n",
      "ACM: 0\n",
      "4\n",
      "number of papers for google scholar: 4\n",
      "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
      "ACM: 7\n",
      "ACM: 0\n",
      "7\n",
      "number of papers for google scholar: 7\n",
      "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
      "ACM: 8\n",
      "ACM: 0\n",
      "8\n",
      "number of papers for google scholar: 8\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
      "ACM: 19\n",
      "ACM: 4\n",
      "ACM: 0\n",
      "23\n",
      "number of papers for google scholar: 23\n",
      "Processing: Benchmark+Dataset+Software+Development+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Engineering+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Review+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Summarization+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Patch+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Optimization+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Translation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Program+Repair+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Development+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Engineering+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Review+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def loadtxt():\n",
    "    return [line.strip() for line in open(\"query.txt\", \"r\")]\n",
    "\n",
    "def jsonWriter(data, filename):\n",
    "    with open(f'{filename}.json', 'a') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(row, filename):\n",
    "    with open(f'{filename}.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def randomize_user_agent():\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    ]\n",
    "    return {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        cookie_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept') or contains(., 'Agree') or contains(., 'OK')]\"))\n",
    "        )\n",
    "        cookie_btn.click()\n",
    "        time.sleep(2)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def is_recent_publication(year_text):\n",
    "    try:\n",
    "        year = int(re.search(r'\\d{4}', year_text).group())\n",
    "        return year >= 2020\n",
    "    except (AttributeError, ValueError):\n",
    "        return False\n",
    "        \n",
    "def google_scholar_scraper(query, start=0):\n",
    "    base_url = f\"https://scholar.google.com/scholar?start={start}&q={query}&hl=en&as_sdt=0,5&as_ylo=2020\"\n",
    "    driver.get(base_url)\n",
    "    if start == 0:\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        time.sleep(random.uniform(2,4))\n",
    "    \n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"gs_ri\"))\n",
    "        )\n",
    "        \n",
    "        papers = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find_element(By.TAG_NAME, 'h3').text\n",
    "                link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                year_text = result.find_element(By.CLASS_NAME, 'gs_a').text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, link, year_text])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'GoogleScholarPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No results found or page didn't load\")\n",
    "        return 0\n",
    "\n",
    "def parse_ieee(keyword, page=0):\n",
    "    url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword}&pageNumber={page}&ranges=2020_{datetime.now().year}_Year\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".List-results-items\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h3 a\").text\n",
    "                year_text = item.find_element(By.XPATH, \".//*[contains(text(), 'Year:')]\").text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, f\"IEEE {year_text}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'IEEEPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No IEEE results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_science_direct(keyword, offset=0):\n",
    "    \"\"\"Scrapes ScienceDirect search results for paper titles and links.\"\"\"\n",
    "    \n",
    "    url = f'https://www.sciencedirect.com/search?date=2020-2025&tak={keyword}&offset={offset}'\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    handle_cookie_consent()\n",
    "\n",
    "    papers = []\n",
    "    \n",
    "    try:\n",
    "        # Wait until search results load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"result-item-container\"))\n",
    "        )\n",
    "        \n",
    "        results = driver.find_elements(By.CLASS_NAME, \"result-item-container\")\n",
    "\n",
    "        for item in results:\n",
    "            try:\n",
    "                title_element = item.find_element(By.TAG_NAME, 'h2').find_element(By.TAG_NAME, 'a')\n",
    "                title = title_element.text\n",
    "                link = title_element.get_attribute('href')\n",
    "                papers.append([title, link])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping item due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'ScienceDirectPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No ScienceDirect results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_acm(query, page):\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?field1=TitleAbstract&text1={query}&AfterYear=2020&startPage={page-1}&pageSize=50\"\n",
    "    url = f\"https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&ABSTRACT={query}&pageSize=20&startPage={page-1}\"\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?field1=TitleAbstract&text1={query}&AfterYear=2020&startPage={page-1}&pageSize=20\"#f'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&field1=Title&text1={query}&field2=Abstract&text2={query}&AfterYear=2020&pageSize=20&startPage={page-1}'\n",
    "    #'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField={query}&pageSize=20&startPage={page-1}'\n",
    "    #https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField=+AND+AllField%3A%28benchmark+dataset+code+generation+llm%29&pageSize=20&startPage=1\n",
    "    response = requests.get(url, headers=randomize_user_agent())\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    for item in soup.select('.issue-item__title'):\n",
    "        try:\n",
    "            title = item.text.strip()\n",
    "            link = \"https://dl.acm.org\" + item.find('a')['href']\n",
    "            year_text = item.find_next(class_='bookPubDate').text\n",
    "            \n",
    "            if is_recent_publication(year_text):\n",
    "                papers.append([title, link, year_text])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for paper in papers:\n",
    "        newWriter(paper, 'ACMPapers')\n",
    "    \n",
    "    print(f'ACM: {len(papers)}')\n",
    "    return len(papers)\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        'Benchmark+Dataset+Code+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Summarization+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        'Benchmark+Dataset+Patch+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Optimization+LLM',\n",
    "        'Benchmark+Dataset+Code+Translation+LLM',\n",
    "        'Benchmark+Dataset+Program+Repair+LLM',\n",
    "        'Benchmark+Dataset+Requirement+Generation+LLM',\n",
    "        'Benchmark+Dataset+Software+Development+LLM',\n",
    "        'Benchmark+Dataset+Software+Engineering+LLM',\n",
    "        'Benchmark+Dataset+Code+Review+LLM',\n",
    "        'Benchmark+Dataset+Code+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Summarization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Patch+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Optimization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Translation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Program+Repair+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Requirement+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Development+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Engineering+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Review+Large+Language+Model'\n",
    "        ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"Processing: {query}\")\n",
    "        \n",
    "        # Google Scholar\n",
    "        count_total = 0\n",
    "        for page in range(0, 6):  # First 5 pages\n",
    "            count = google_scholar_scraper(query, start=page*10)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 5:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "        \n",
    "        # IEEE\n",
    "        count_total = 0\n",
    "        for page in range(0, 20):  # First 5 pages\n",
    "            count = parse_ieee(query, page)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(f'number of papers for IEEE: {count_total}')\n",
    "                break\n",
    "\n",
    "        # ScienceDirect\n",
    "        count_total = 0\n",
    "        for offset in range(0, 250, 25):  # First 5 pages\n",
    "            count = parse_science_direct(query, offset)\n",
    "            count_total+=count\n",
    "            if count == 0:  \n",
    "                print(f'number of papers for science direct: {count_total}') \n",
    "                break\n",
    "        \n",
    "        # ACM\n",
    "        count_total = 0\n",
    "        for page in range(1, 6):  # First 5 pages\n",
    "            count = parse_acm(query, page)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 5:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Benchmark+Dataset+Code+Generation+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Development+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Engineering+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Review+LLM\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Summarization+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Patch+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Optimization+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Translation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Program+Repair+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Requirement+Generation+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Development+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Software+Engineering+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n",
      "Processing: Benchmark+Dataset+Code+Review+Large+Language+Model\n",
      "ACM: 0\n",
      "0\n",
      "number of papers for google scholar: 0\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def loadtxt():\n",
    "    return [line.strip() for line in open(\"query.txt\", \"r\")]\n",
    "\n",
    "def jsonWriter(data, filename):\n",
    "    with open(f'{filename}.json', 'a') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "def newWriter(row, filename):\n",
    "    with open(f'{filename}.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "def randomize_user_agent():\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',\n",
    "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    ]\n",
    "    return {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "def handle_cookie_consent():\n",
    "    try:\n",
    "        cookie_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept') or contains(., 'Agree') or contains(., 'OK')]\"))\n",
    "        )\n",
    "        cookie_btn.click()\n",
    "        time.sleep(2)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def is_recent_publication(year_text):\n",
    "    try:\n",
    "        year = int(re.search(r'\\d{4}', year_text).group())\n",
    "        return year >= 2020\n",
    "    except (AttributeError, ValueError):\n",
    "        return False\n",
    "        \n",
    "def google_scholar_scraper(query, start=0):\n",
    "    base_url = f\"https://scholar.google.com/scholar?start={start}&q={query}&hl=en&as_sdt=0,5&as_ylo=2020\"\n",
    "    driver.get(base_url)\n",
    "    if start == 0:\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        time.sleep(random.uniform(2,4))\n",
    "    \n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"gs_ri\"))\n",
    "        )\n",
    "        \n",
    "        papers = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find_element(By.TAG_NAME, 'h3').text\n",
    "                link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                year_text = result.find_element(By.CLASS_NAME, 'gs_a').text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, link, year_text])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'GoogleScholarPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No results found or page didn't load\")\n",
    "        return 0\n",
    "\n",
    "def parse_ieee(keyword, page=0):\n",
    "    url = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?queryText={keyword}&pageNumber={page}&ranges=2020_{datetime.now().year}_Year\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    papers = []\n",
    "    try:\n",
    "        results = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".List-results-items\"))\n",
    "        )\n",
    "        \n",
    "        for item in results:\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h3 a\").text\n",
    "                year_text = item.find_element(By.XPATH, \".//*[contains(text(), 'Year:')]\").text\n",
    "                \n",
    "                if is_recent_publication(year_text):\n",
    "                    papers.append([title, f\"IEEE {year_text}\"])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'IEEEPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No IEEE results found\")\n",
    "        return 0\n",
    "\n",
    "def parse_science_direct(keyword, offset=0):\n",
    "    \"\"\"Scrapes ScienceDirect search results for paper titles and links.\"\"\"\n",
    "    \n",
    "    url = f'https://www.sciencedirect.com/search?date=2020-2025&tak={keyword}&offset={offset}'\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    handle_cookie_consent()\n",
    "\n",
    "    papers = []\n",
    "    \n",
    "    try:\n",
    "        # Wait until search results load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"result-item-container\"))\n",
    "        )\n",
    "        \n",
    "        results = driver.find_elements(By.CLASS_NAME, \"result-item-container\")\n",
    "\n",
    "        for item in results:\n",
    "            try:\n",
    "                title_element = item.find_element(By.TAG_NAME, 'h2').find_element(By.TAG_NAME, 'a')\n",
    "                title = title_element.text\n",
    "                link = title_element.get_attribute('href')\n",
    "                papers.append([title, link])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping item due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        for paper in papers:\n",
    "            newWriter(paper, 'ScienceDirectPapers')\n",
    "        \n",
    "        return len(papers)\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"No ScienceDirect results found\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def parse_acm(query, page):\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?field1=TitleAbstract&text1={query}&AfterYear=2020&startPage={page-1}&pageSize=50\"\n",
    "    url = f\"https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&TITLE={query}&pageSize=20&startPage={page-1}\"\n",
    "    #url = f\"https://dl.acm.org/action/doSearch?field1=TitleAbstract&text1={query}&AfterYear=2020&startPage={page-1}&pageSize=20\"#f'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&field1=Title&text1={query}&field2=Abstract&text2={query}&AfterYear=2020&pageSize=20&startPage={page-1}'\n",
    "    #'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField={query}&pageSize=20&startPage={page-1}'\n",
    "    #https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&expand=dl&AfterYear=2020&AllField=+AND+AllField%3A%28benchmark+dataset+code+generation+llm%29&pageSize=20&startPage=1\n",
    "    response = requests.get(url, headers=randomize_user_agent())\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    for item in soup.select('.issue-item__title'):\n",
    "        try:\n",
    "            title = item.text.strip()\n",
    "            link = \"https://dl.acm.org\" + item.find('a')['href']\n",
    "            year_text = item.find_next(class_='bookPubDate').text\n",
    "            \n",
    "            if is_recent_publication(year_text):\n",
    "                papers.append([title, link, year_text])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for paper in papers:\n",
    "        newWriter(paper, 'ACMPapers')\n",
    "    \n",
    "    print(f'ACM: {len(papers)}')\n",
    "    return len(papers)\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        'Benchmark+Dataset+Code+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Summarization+LLM',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+LLM',\n",
    "        'Benchmark+Dataset+Patch+Generation+LLM',\n",
    "        'Benchmark+Dataset+Code+Optimization+LLM',\n",
    "        'Benchmark+Dataset+Code+Translation+LLM',\n",
    "        'Benchmark+Dataset+Program+Repair+LLM',\n",
    "        'Benchmark+Dataset+Requirement+Generation+LLM',\n",
    "        'Benchmark+Dataset+Software+Development+LLM',\n",
    "        'Benchmark+Dataset+Software+Engineering+LLM',\n",
    "        'Benchmark+Dataset+Code+Review+LLM',\n",
    "        'Benchmark+Dataset+Code+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Summarization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Patch+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Optimization+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Translation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Program+Repair+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Requirement+Generation+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Development+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Software+Engineering+Large+Language+Model',\n",
    "        'Benchmark+Dataset+Code+Review+Large+Language+Model'\n",
    "        ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"Processing: {query}\")\n",
    "        \n",
    "        # Google Scholar\n",
    "        count_total = 0\n",
    "        for page in range(0, 6):  # First 5 pages\n",
    "            count = google_scholar_scraper(query, start=page*10)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 5:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "        \n",
    "        # IEEE\n",
    "        count_total = 0\n",
    "        for page in range(0, 20):  # First 5 pages\n",
    "            count = parse_ieee(query, page)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(f'number of papers for IEEE: {count_total}')\n",
    "                break\n",
    "\n",
    "        # ScienceDirect\n",
    "        count_total = 0\n",
    "        for offset in range(0, 250, 25):  # First 5 pages\n",
    "            count = parse_science_direct(query, offset)\n",
    "            count_total+=count\n",
    "            if count == 0:  \n",
    "                print(f'number of papers for science direct: {count_total}') \n",
    "                break\n",
    "        \n",
    "        # ACM\n",
    "        count_total = 0\n",
    "        for page in range(1, 6):  # First 5 pages\n",
    "            count = parse_acm(query, page)\n",
    "            count_total+=count\n",
    "            if count == 0: \n",
    "                print(count_total)\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "                break\n",
    "            if page == 5:\n",
    "                print(f'number of papers for google scholar: {count_total}')\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"\"\"Processing: Benchmark+Dataset+Code+Generation+LLM\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 69\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 10\n",
    "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 6\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 1\n",
    "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 24\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
    "number of papers for google scholar: 199\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 2\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
    "No results found or page didn't load\n",
    "179\n",
    "number of papers for google scholar: 179\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 8\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 4\n",
    "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 18\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 4\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 8\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 3\n",
    "Processing: Benchmark+Dataset+Software+Development+LLM\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 40\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 2\n",
    "Processing: Benchmark+Dataset+Software+Engineering+LLM\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 56\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 1\n",
    "Processing: Benchmark+Dataset+Code+Review+LLM\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 8\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 2\n",
    "Processing: Benchmark+Dataset+Code+Generation+Large+Language+Model\n",
    "number of papers for google scholar: 198\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 141\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 17\n",
    "Processing: Benchmark+Dataset+Code+Summarization+Large+Language+Model\n",
    "number of papers for google scholar: 197\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 28\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 2\n",
    "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model\n",
    "number of papers for google scholar: 200\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 38\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 1\n",
    "Processing: Benchmark+Dataset+Patch+Generation+Large+Language+Model\n",
    "number of papers for google scholar: 197\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 14\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Code+Optimization+Large+Language+Model\n",
    "number of papers for google scholar: 198\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 34\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 8\n",
    "Processing: Benchmark+Dataset+Code+Translation+Large+Language+Model\n",
    "number of papers for google scholar: 199\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 44\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 1\n",
    "Processing: Benchmark+Dataset+Program+Repair+Large+Language+Model\n",
    "number of papers for google scholar: 199\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 18\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 0\n",
    "Processing: Benchmark+Dataset+Requirement+Generation+Large+Language+Model\n",
    "number of papers for google scholar: 199\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 24\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 4\n",
    "Processing: Benchmark+Dataset+Software+Development+Large+Language+Model\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 83\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 3\n",
    "Processing: Benchmark+Dataset+Software+Engineering+Large+Language+Model\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 145\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 2\n",
    "Processing: Benchmark+Dataset+Code+Review+Large+Language+Model\n",
    "No results found or page didn't load\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "No IEEE results found\n",
    "number of papers for IEEE: 36\n",
    "No ScienceDirect results found\n",
    "number of papers for science direct: 3\n",
    "\n",
    "Processing: Benchmark+Dataset+Code+Generation+LLM\n",
    "ACM: 19\n",
    "ACM: 11\n",
    "ACM: 0\n",
    "30\n",
    "number of papers for google scholar: 30\n",
    "Processing: Benchmark+Dataset+Code+Summarization+LLM\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+LLM\n",
    "ACM: 2\n",
    "ACM: 0\n",
    "2\n",
    "number of papers for google scholar: 2\n",
    "Processing: Benchmark+Dataset+Patch+Generation+LLM\n",
    "ACM: 5\n",
    "ACM: 0\n",
    "5\n",
    "number of papers for google scholar: 5\n",
    "Processing: Benchmark+Dataset+Code+Optimization+LLM\n",
    "ACM: 4\n",
    "ACM: 0\n",
    "4\n",
    "number of papers for google scholar: 4\n",
    "Processing: Benchmark+Dataset+Code+Translation+LLM\n",
    "ACM: 7\n",
    "ACM: 0\n",
    "7\n",
    "number of papers for google scholar: 7\n",
    "Processing: Benchmark+Dataset+Program+Repair+LLM\n",
    "ACM: 8\n",
    "ACM: 0\n",
    "8\n",
    "number of papers for google scholar: 8\n",
    "Processing: Benchmark+Dataset+Requirement+Generation+LLM\n",
    "ACM: 19\n",
    "ACM: 4\n",
    "ACM: 0\n",
    "23\n",
    "number of papers for google scholar: 23\n",
    "Processing: Benchmark+Dataset+Software+Development+LLM\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Software+Engineering+LLM\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Review+LLM\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Generation+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Summarization+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Patch+Generation+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Optimization+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Translation+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Program+Repair+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Requirement+Generation+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Software+Development+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Software+Engineering+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "Processing: Benchmark+Dataset+Code+Review+Large+Language+Model\n",
    "ACM: 0\n",
    "0\n",
    "number of papers for google scholar: 0\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query                                                       Google Scholar IEEE      ACM       ScienceDirect  \n",
      "==============================================================================================================\n",
      "Benchmark+Dataset+Code+Generation+LLM                       60             69        30        10             \n",
      "Benchmark+Dataset+Code+Summarization+LLM                    60             6         0         1              \n",
      "Benchmark+Dataset+Code+Test+Cases+Generation+LLM            60             24        2         0              \n",
      "Benchmark+Dataset+Patch+Generation+LLM                      60             2         5         0              \n",
      "Benchmark+Dataset+Code+Optimization+LLM                     60             8         4         4              \n",
      "Benchmark+Dataset+Code+Translation+LLM                      60             18        7         0              \n",
      "Benchmark+Dataset+Program+Repair+LLM                        60             4         8         0              \n",
      "Benchmark+Dataset+Requirement+Generation+LLM                60             8         23        3              \n",
      "Benchmark+Dataset+Software+Development+LLM                  60             40        0         2              \n",
      "Benchmark+Dataset+Software+Engineering+LLM                  60             56        0         1              \n",
      "Benchmark+Dataset+Code+Review+LLM                           60             8         0         2              \n",
      "Benchmark+Dataset+Code+Generation+Large+Language+Model      60             141       0         17             \n",
      "Benchmark+Dataset+Code+Summarization+Large+Language+Model   60             28        0         2              \n",
      "Benchmark+Dataset+Code+Test+Cases+Generation+Large+Language+Model60             38        0         1              \n",
      "Benchmark+Dataset+Patch+Generation+Large+Language+Model     60             14        0         0              \n",
      "Benchmark+Dataset+Code+Optimization+Large+Language+Model    60             34        0         8              \n",
      "Benchmark+Dataset+Code+Translation+Large+Language+Model     60             44        0         1              \n",
      "Benchmark+Dataset+Program+Repair+Large+Language+Model       60             18        0         0              \n",
      "Benchmark+Dataset+Requirement+Generation+Large+Language+Model60             24        0         4              \n",
      "Benchmark+Dataset+Software+Development+Large+Language+Model 60             83        0         3              \n",
      "Benchmark+Dataset+Software+Engineering+Large+Language+Model 60             145       0         2              \n",
      "Benchmark+Dataset+Code+Review+Large+Language+Model          60             36        0         3              \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_logs(logs):\n",
    "    query_stats = defaultdict(lambda: {\"Google Scholar\": 0, \"IEEE\": 0, \"ACM\": 0, \"ScienceDirect\": 0})\n",
    "    current_query = None\n",
    "    \n",
    "    for line in logs.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Detect new query\n",
    "        if line.startswith(\"Processing:\"):\n",
    "            current_query = line.replace(\"Processing: \", \"\")\n",
    "        \n",
    "        elif \"number of papers for google scholar:\" in line:\n",
    "            query_stats[current_query][\"Google Scholar\"] = 60        \n",
    "        elif \"number of papers for IEEE:\" in line:\n",
    "            query_stats[current_query][\"IEEE\"] = int(re.search(r'\\d+', line).group())\n",
    "        \n",
    "        elif \"number of papers for science direct:\" in line:\n",
    "            query_stats[current_query][\"ScienceDirect\"] = int(re.search(r'\\d+', line).group())\n",
    "        \n",
    "        elif line.startswith(\"ACM:\"):\n",
    "            count = int(re.search(r'\\d+', line).group())\n",
    "            query_stats[current_query][\"ACM\"] += count\n",
    "    \n",
    "    return query_stats\n",
    "\n",
    "def display_stats(query_stats):\n",
    "    print(f\"{'Query':<60}{'Google Scholar':<15}{'IEEE':<10}{'ACM':<10}{'ScienceDirect':<15}\")\n",
    "    print(\"=\" * 110)\n",
    "    for query, counts in query_stats.items():\n",
    "        print(f\"{query:<60}{counts['Google Scholar']:<15}{counts['IEEE']:<10}{counts['ACM']:<10}{counts['ScienceDirect']:<15}\")\n",
    "\n",
    "# Example usage\n",
    "query_stats = parse_logs(logs)\n",
    "display_stats(query_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Google Scholar</th>\n",
       "      <th>IEEE</th>\n",
       "      <th>ACM</th>\n",
       "      <th>ScienceDirect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark+Dataset+Code+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark+Dataset+Code+Summarization+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark+Dataset+Code+Test+Cases+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark+Dataset+Patch+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark+Dataset+Code+Optimization+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark+Dataset+Code+Translation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark+Dataset+Program+Repair+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark+Dataset+Requirement+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark+Dataset+Software+Development+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark+Dataset+Software+Engineering+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Benchmark+Dataset+Code+Review+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Benchmark+Dataset+Code+Generation+Large+Langua...</td>\n",
       "      <td>60</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Benchmark+Dataset+Code+Summarization+Large+Lan...</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Benchmark+Dataset+Code+Test+Cases+Generation+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Benchmark+Dataset+Patch+Generation+Large+Langu...</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Benchmark+Dataset+Code+Optimization+Large+Lang...</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Benchmark+Dataset+Code+Translation+Large+Langu...</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benchmark+Dataset+Program+Repair+Large+Languag...</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Benchmark+Dataset+Requirement+Generation+Large...</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Benchmark+Dataset+Software+Development+Large+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Benchmark+Dataset+Software+Engineering+Large+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Benchmark+Dataset+Code+Review+Large+Language+M...</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  Google Scholar  IEEE  \\\n",
       "0               Benchmark+Dataset+Code+Generation+LLM              60    69   \n",
       "1            Benchmark+Dataset+Code+Summarization+LLM              60     6   \n",
       "2    Benchmark+Dataset+Code+Test+Cases+Generation+LLM              60    24   \n",
       "3              Benchmark+Dataset+Patch+Generation+LLM              60     2   \n",
       "4             Benchmark+Dataset+Code+Optimization+LLM              60     8   \n",
       "5              Benchmark+Dataset+Code+Translation+LLM              60    18   \n",
       "6                Benchmark+Dataset+Program+Repair+LLM              60     4   \n",
       "7        Benchmark+Dataset+Requirement+Generation+LLM              60     8   \n",
       "8          Benchmark+Dataset+Software+Development+LLM              60    40   \n",
       "9          Benchmark+Dataset+Software+Engineering+LLM              60    56   \n",
       "10                  Benchmark+Dataset+Code+Review+LLM              60     8   \n",
       "11  Benchmark+Dataset+Code+Generation+Large+Langua...              60   141   \n",
       "12  Benchmark+Dataset+Code+Summarization+Large+Lan...              60    28   \n",
       "13  Benchmark+Dataset+Code+Test+Cases+Generation+L...              60    38   \n",
       "14  Benchmark+Dataset+Patch+Generation+Large+Langu...              60    14   \n",
       "15  Benchmark+Dataset+Code+Optimization+Large+Lang...              60    34   \n",
       "16  Benchmark+Dataset+Code+Translation+Large+Langu...              60    44   \n",
       "17  Benchmark+Dataset+Program+Repair+Large+Languag...              60    18   \n",
       "18  Benchmark+Dataset+Requirement+Generation+Large...              60    24   \n",
       "19  Benchmark+Dataset+Software+Development+Large+L...              60    83   \n",
       "20  Benchmark+Dataset+Software+Engineering+Large+L...              60   145   \n",
       "21  Benchmark+Dataset+Code+Review+Large+Language+M...              60    36   \n",
       "\n",
       "    ACM  ScienceDirect  \n",
       "0    30             10  \n",
       "1     0              1  \n",
       "2     2              0  \n",
       "3     5              0  \n",
       "4     4              4  \n",
       "5     7              0  \n",
       "6     8              0  \n",
       "7    23              3  \n",
       "8     0              2  \n",
       "9     0              1  \n",
       "10    0              2  \n",
       "11    0             17  \n",
       "12    0              2  \n",
       "13    0              1  \n",
       "14    0              0  \n",
       "15    0              8  \n",
       "16    0              1  \n",
       "17    0              0  \n",
       "18    0              4  \n",
       "19    0              3  \n",
       "20    0              2  \n",
       "21    0              3  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(query_stats, orient='index').reset_index()\n",
    "df.rename(columns={'index': 'Query'}, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a final row with sums of all columns except 'Query'\n",
    "sum_row = df.drop(columns=['Query']).sum().to_dict()\n",
    "sum_row['Query'] = 'Total'\n",
    "df = pd.concat([df, pd.DataFrame([sum_row])], ignore_index=True)\n",
    "df.to_csv(\"overall_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Google Scholar</th>\n",
       "      <th>IEEE</th>\n",
       "      <th>ACM</th>\n",
       "      <th>ScienceDirect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark+Dataset+Code+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark+Dataset+Code+Summarization+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark+Dataset+Code+Test+Cases+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark+Dataset+Patch+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark+Dataset+Code+Optimization+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark+Dataset+Code+Translation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark+Dataset+Program+Repair+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark+Dataset+Requirement+Generation+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark+Dataset+Software+Development+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark+Dataset+Software+Engineering+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Benchmark+Dataset+Code+Review+LLM</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Benchmark+Dataset+Code+Generation+Large+Langua...</td>\n",
       "      <td>60</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Benchmark+Dataset+Code+Summarization+Large+Lan...</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Benchmark+Dataset+Code+Test+Cases+Generation+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Benchmark+Dataset+Patch+Generation+Large+Langu...</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Benchmark+Dataset+Code+Optimization+Large+Lang...</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Benchmark+Dataset+Code+Translation+Large+Langu...</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benchmark+Dataset+Program+Repair+Large+Languag...</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Benchmark+Dataset+Requirement+Generation+Large...</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Benchmark+Dataset+Software+Development+Large+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Benchmark+Dataset+Software+Engineering+Large+L...</td>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Benchmark+Dataset+Code+Review+Large+Language+M...</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Total</td>\n",
       "      <td>1320</td>\n",
       "      <td>848</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  Google Scholar  IEEE  \\\n",
       "0               Benchmark+Dataset+Code+Generation+LLM              60    69   \n",
       "1            Benchmark+Dataset+Code+Summarization+LLM              60     6   \n",
       "2    Benchmark+Dataset+Code+Test+Cases+Generation+LLM              60    24   \n",
       "3              Benchmark+Dataset+Patch+Generation+LLM              60     2   \n",
       "4             Benchmark+Dataset+Code+Optimization+LLM              60     8   \n",
       "5              Benchmark+Dataset+Code+Translation+LLM              60    18   \n",
       "6                Benchmark+Dataset+Program+Repair+LLM              60     4   \n",
       "7        Benchmark+Dataset+Requirement+Generation+LLM              60     8   \n",
       "8          Benchmark+Dataset+Software+Development+LLM              60    40   \n",
       "9          Benchmark+Dataset+Software+Engineering+LLM              60    56   \n",
       "10                  Benchmark+Dataset+Code+Review+LLM              60     8   \n",
       "11  Benchmark+Dataset+Code+Generation+Large+Langua...              60   141   \n",
       "12  Benchmark+Dataset+Code+Summarization+Large+Lan...              60    28   \n",
       "13  Benchmark+Dataset+Code+Test+Cases+Generation+L...              60    38   \n",
       "14  Benchmark+Dataset+Patch+Generation+Large+Langu...              60    14   \n",
       "15  Benchmark+Dataset+Code+Optimization+Large+Lang...              60    34   \n",
       "16  Benchmark+Dataset+Code+Translation+Large+Langu...              60    44   \n",
       "17  Benchmark+Dataset+Program+Repair+Large+Languag...              60    18   \n",
       "18  Benchmark+Dataset+Requirement+Generation+Large...              60    24   \n",
       "19  Benchmark+Dataset+Software+Development+Large+L...              60    83   \n",
       "20  Benchmark+Dataset+Software+Engineering+Large+L...              60   145   \n",
       "21  Benchmark+Dataset+Code+Review+Large+Language+M...              60    36   \n",
       "22                                              Total            1320   848   \n",
       "\n",
       "    ACM  ScienceDirect  \n",
       "0    30             10  \n",
       "1     0              1  \n",
       "2     2              0  \n",
       "3     5              0  \n",
       "4     4              4  \n",
       "5     7              0  \n",
       "6     8              0  \n",
       "7    23              3  \n",
       "8     0              2  \n",
       "9     0              1  \n",
       "10    0              2  \n",
       "11    0             17  \n",
       "12    0              2  \n",
       "13    0              1  \n",
       "14    0              0  \n",
       "15    0              8  \n",
       "16    0              1  \n",
       "17    0              0  \n",
       "18    0              4  \n",
       "19    0              3  \n",
       "20    0              2  \n",
       "21    0              3  \n",
       "22   79             64  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-Driven Development and LLM-based Code Gen...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3691620.369...</td>\n",
       "      <td>NS Mathews, M Nagappan - Proceedings of the 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PDF] Beyond synthetic benchmarks: Assessing r...</td>\n",
       "      <td>https://www.researchgate.net/profile/Amirkia-R...</td>\n",
       "      <td>AR Oskooei, MS Babacan, E YaÄŸcÄ±â€¦ - The 14th In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classeval: A manually-crafted benchmark for ev...</td>\n",
       "      <td>https://arxiv.org/abs/2308.01861</td>\n",
       "      <td>X Du, M Liu, K Wang, H Wang, J Liu, Y Chenâ€¦ - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Survey on Large Language Models for Code Gen...</td>\n",
       "      <td>https://arxiv.org/abs/2406.00515</td>\n",
       "      <td>J Jiang, F Wang, J Shen, S Kim, S Kim - arXiv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When llm-based code generation meets the softw...</td>\n",
       "      <td>https://arxiv.org/abs/2403.15852</td>\n",
       "      <td>F Lin, DJ Kim - arXiv preprint arXiv:2403.1585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>Gpt4graph: Can large language models understan...</td>\n",
       "      <td>https://arxiv.org/abs/2305.15066</td>\n",
       "      <td>J Guo, L Du, H Liu, M Zhou, X He, S Han - arXi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>Benchmarking and defending against indirect pr...</td>\n",
       "      <td>https://arxiv.org/abs/2312.14197</td>\n",
       "      <td>J Yi, Y Xie, B Zhu, E Kiciman, G Sun, X Xieâ€¦ -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>mplug-paperowl: Scientific diagram analysis wi...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3664647.368...</td>\n",
       "      <td>A Hu, Y Shi, H Xu, J Ye, Q Ye, M Yan, C Liâ€¦ - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>Genegpt: Augmenting large language models with...</td>\n",
       "      <td>https://academic.oup.com/bioinformatics/articl...</td>\n",
       "      <td>Q Jin, Y Yang, Q Chen, Z Lu - Bioinformatics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Huatuogpt, towards taming language model to be...</td>\n",
       "      <td>https://arxiv.org/abs/2305.15075</td>\n",
       "      <td>H Zhang, J Chen, F Jiang, F Yu, Z Chen, J Liâ€¦ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Test-Driven Development and LLM-based Code Gen...   \n",
       "1     [PDF] Beyond synthetic benchmarks: Assessing r...   \n",
       "2     Classeval: A manually-crafted benchmark for ev...   \n",
       "3     A Survey on Large Language Models for Code Gen...   \n",
       "4     When llm-based code generation meets the softw...   \n",
       "...                                                 ...   \n",
       "1333  Gpt4graph: Can large language models understan...   \n",
       "1334  Benchmarking and defending against indirect pr...   \n",
       "1335  mplug-paperowl: Scientific diagram analysis wi...   \n",
       "1336  Genegpt: Augmenting large language models with...   \n",
       "1337  Huatuogpt, towards taming language model to be...   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://dl.acm.org/doi/abs/10.1145/3691620.369...   \n",
       "1     https://www.researchgate.net/profile/Amirkia-R...   \n",
       "2                      https://arxiv.org/abs/2308.01861   \n",
       "3                      https://arxiv.org/abs/2406.00515   \n",
       "4                      https://arxiv.org/abs/2403.15852   \n",
       "...                                                 ...   \n",
       "1333                   https://arxiv.org/abs/2305.15066   \n",
       "1334                   https://arxiv.org/abs/2312.14197   \n",
       "1335  https://dl.acm.org/doi/abs/10.1145/3664647.368...   \n",
       "1336  https://academic.oup.com/bioinformatics/articl...   \n",
       "1337                   https://arxiv.org/abs/2305.15075   \n",
       "\n",
       "                                                   Year  \n",
       "0     NS Mathews, M Nagappan - Proceedings of the 39...  \n",
       "1     AR Oskooei, MS Babacan, E YaÄŸcÄ±â€¦ - The 14th In...  \n",
       "2     X Du, M Liu, K Wang, H Wang, J Liu, Y Chenâ€¦ - ...  \n",
       "3     J Jiang, F Wang, J Shen, S Kim, S Kim - arXiv ...  \n",
       "4     F Lin, DJ Kim - arXiv preprint arXiv:2403.1585...  \n",
       "...                                                 ...  \n",
       "1333  J Guo, L Du, H Liu, M Zhou, X He, S Han - arXi...  \n",
       "1334  J Yi, Y Xie, B Zhu, E Kiciman, G Sun, X Xieâ€¦ -...  \n",
       "1335  A Hu, Y Shi, H Xu, J Ye, Q Ye, M Yan, C Liâ€¦ - ...  \n",
       "1336  Q Jin, Y Yang, Q Chen, Z Lu - Bioinformatics, ...  \n",
       "1337  H Zhang, J Chen, F Jiang, F Yu, Z Chen, J Liâ€¦ ...  \n",
       "\n",
       "[1338 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "t = pd.read_csv('GoogleScholarPapers.csv', names=['Title', 'Link', 'Year'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-Driven Development and LLM-based Code Gen...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3691620.369...</td>\n",
       "      <td>NS Mathews, M Nagappan - Proceedings of the 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PDF] Beyond synthetic benchmarks: Assessing r...</td>\n",
       "      <td>https://www.researchgate.net/profile/Amirkia-R...</td>\n",
       "      <td>AR Oskooei, MS Babacan, E YaÄŸcÄ±â€¦ - The 14th In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classeval: A manually-crafted benchmark for ev...</td>\n",
       "      <td>https://arxiv.org/abs/2308.01861</td>\n",
       "      <td>X Du, M Liu, K Wang, H Wang, J Liu, Y Chenâ€¦ - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Survey on Large Language Models for Code Gen...</td>\n",
       "      <td>https://arxiv.org/abs/2406.00515</td>\n",
       "      <td>J Jiang, F Wang, J Shen, S Kim, S Kim - arXiv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When llm-based code generation meets the softw...</td>\n",
       "      <td>https://arxiv.org/abs/2403.15852</td>\n",
       "      <td>F Lin, DJ Kim - arXiv preprint arXiv:2403.1585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Benchmark evaluations, applications, and chall...</td>\n",
       "      <td>https://arxiv.org/abs/2501.02189</td>\n",
       "      <td>Z Li, X Wu, H Du, H Nghiem, G Shi - arXiv prep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>Large language models for code analysis: Do {L...</td>\n",
       "      <td>https://www.usenix.org/conference/usenixsecuri...</td>\n",
       "      <td>C Fang, N Miao, S Srivastav, J Liu, R Zhangâ€¦ -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>ROBBIE: Robust bias evaluation of large genera...</td>\n",
       "      <td>https://arxiv.org/abs/2311.18140</td>\n",
       "      <td>D Esiobu, X Tan, S Hosseini, M Ung, Y Zhangâ€¦ -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>mplug-paperowl: Scientific diagram analysis wi...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3664647.368...</td>\n",
       "      <td>A Hu, Y Shi, H Xu, J Ye, Q Ye, M Yan, C Liâ€¦ - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Huatuogpt, towards taming language model to be...</td>\n",
       "      <td>https://arxiv.org/abs/2305.15075</td>\n",
       "      <td>H Zhang, J Chen, F Jiang, F Yu, Z Chen, J Liâ€¦ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Test-Driven Development and LLM-based Code Gen...   \n",
       "1     [PDF] Beyond synthetic benchmarks: Assessing r...   \n",
       "2     Classeval: A manually-crafted benchmark for ev...   \n",
       "3     A Survey on Large Language Models for Code Gen...   \n",
       "4     When llm-based code generation meets the softw...   \n",
       "...                                                 ...   \n",
       "1303  Benchmark evaluations, applications, and chall...   \n",
       "1324  Large language models for code analysis: Do {L...   \n",
       "1331  ROBBIE: Robust bias evaluation of large genera...   \n",
       "1335  mplug-paperowl: Scientific diagram analysis wi...   \n",
       "1337  Huatuogpt, towards taming language model to be...   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://dl.acm.org/doi/abs/10.1145/3691620.369...   \n",
       "1     https://www.researchgate.net/profile/Amirkia-R...   \n",
       "2                      https://arxiv.org/abs/2308.01861   \n",
       "3                      https://arxiv.org/abs/2406.00515   \n",
       "4                      https://arxiv.org/abs/2403.15852   \n",
       "...                                                 ...   \n",
       "1303                   https://arxiv.org/abs/2501.02189   \n",
       "1324  https://www.usenix.org/conference/usenixsecuri...   \n",
       "1331                   https://arxiv.org/abs/2311.18140   \n",
       "1335  https://dl.acm.org/doi/abs/10.1145/3664647.368...   \n",
       "1337                   https://arxiv.org/abs/2305.15075   \n",
       "\n",
       "                                                   Year  \n",
       "0     NS Mathews, M Nagappan - Proceedings of the 39...  \n",
       "1     AR Oskooei, MS Babacan, E YaÄŸcÄ±â€¦ - The 14th In...  \n",
       "2     X Du, M Liu, K Wang, H Wang, J Liu, Y Chenâ€¦ - ...  \n",
       "3     J Jiang, F Wang, J Shen, S Kim, S Kim - arXiv ...  \n",
       "4     F Lin, DJ Kim - arXiv preprint arXiv:2403.1585...  \n",
       "...                                                 ...  \n",
       "1303  Z Li, X Wu, H Du, H Nghiem, G Shi - arXiv prep...  \n",
       "1324  C Fang, N Miao, S Srivastav, J Liu, R Zhangâ€¦ -...  \n",
       "1331  D Esiobu, X Tan, S Hosseini, M Ung, Y Zhangâ€¦ -...  \n",
       "1335  A Hu, Y Shi, H Xu, J Ye, Q Ye, M Yan, C Liâ€¦ - ...  \n",
       "1337  H Zhang, J Chen, F Jiang, F Yu, Z Chen, J Liâ€¦ ...  \n",
       "\n",
       "[498 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.drop_duplicates(subset=['Title'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('~/Downloads/survey inclusion exclusion criteria - include_exclude.csv')\n",
    "t.drop_duplicates(subset=['title'], keep='first', inplace=True)\n",
    "t.to_csv('survey inclusion exclusion criteria - include_exclude.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>venue</th>\n",
       "      <th>include/exclude</th>\n",
       "      <th>questions</th>\n",
       "      <th>future use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-Driven Development and LLM-based Code Gen...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3691620.369...</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exclude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PDF] Beyond synthetic benchmarks: Assessing r...</td>\n",
       "      <td>https://www.researchgate.net/profile/Amirkia-R...</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>wcse</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classeval: A manually-crafted benchmark for ev...</td>\n",
       "      <td>https://arxiv.org/abs/2308.01861</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>arvix</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Survey on Large Language Models for Code Gen...</td>\n",
       "      <td>https://arxiv.org/abs/2406.00515</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exclude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When llm-based code generation meets the softw...</td>\n",
       "      <td>https://arxiv.org/abs/2403.15852</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exclude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Benchmark evaluations, applications, and chall...</td>\n",
       "      <td>https://arxiv.org/abs/2501.02189</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Large language models for code analysis: Do {L...</td>\n",
       "      <td>https://www.usenix.org/conference/usenixsecuri...</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ROBBIE: Robust bias evaluation of large genera...</td>\n",
       "      <td>https://arxiv.org/abs/2311.18140</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>mplug-paperowl: Scientific diagram analysis wi...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3664647.368...</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Huatuogpt, towards taming language model to be...</td>\n",
       "      <td>https://arxiv.org/abs/2305.15075</td>\n",
       "      <td>Google Scholar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Test-Driven Development and LLM-based Code Gen...   \n",
       "1    [PDF] Beyond synthetic benchmarks: Assessing r...   \n",
       "2    Classeval: A manually-crafted benchmark for ev...   \n",
       "3    A Survey on Large Language Models for Code Gen...   \n",
       "4    When llm-based code generation meets the softw...   \n",
       "..                                                 ...   \n",
       "494  Benchmark evaluations, applications, and chall...   \n",
       "495  Large language models for code analysis: Do {L...   \n",
       "496  ROBBIE: Robust bias evaluation of large genera...   \n",
       "497  mplug-paperowl: Scientific diagram analysis wi...   \n",
       "498  Huatuogpt, towards taming language model to be...   \n",
       "\n",
       "                                                  link          source  venue  \\\n",
       "0    https://dl.acm.org/doi/abs/10.1145/3691620.369...  Google Scholar    NaN   \n",
       "1    https://www.researchgate.net/profile/Amirkia-R...  Google Scholar   wcse   \n",
       "2                     https://arxiv.org/abs/2308.01861  Google Scholar  arvix   \n",
       "3                     https://arxiv.org/abs/2406.00515  Google Scholar    NaN   \n",
       "4                     https://arxiv.org/abs/2403.15852  Google Scholar    NaN   \n",
       "..                                                 ...             ...    ...   \n",
       "494                   https://arxiv.org/abs/2501.02189  Google Scholar    NaN   \n",
       "495  https://www.usenix.org/conference/usenixsecuri...  Google Scholar    NaN   \n",
       "496                   https://arxiv.org/abs/2311.18140  Google Scholar    NaN   \n",
       "497  https://dl.acm.org/doi/abs/10.1145/3664647.368...  Google Scholar    NaN   \n",
       "498                   https://arxiv.org/abs/2305.15075  Google Scholar    NaN   \n",
       "\n",
       "    include/exclude questions future use  \n",
       "0           exclude       NaN        NaN  \n",
       "1                 ?       NaN        NaN  \n",
       "2           include       NaN        NaN  \n",
       "3           exclude       NaN        NaN  \n",
       "4           exclude       NaN        NaN  \n",
       "..              ...       ...        ...  \n",
       "494             NaN       NaN        NaN  \n",
       "495             NaN       NaN        NaN  \n",
       "496             NaN       NaN        NaN  \n",
       "497             NaN       NaN        NaN  \n",
       "498             NaN       NaN        NaN  \n",
       "\n",
       "[499 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "t = pd.read_csv('survey inclusion exclusion - include_exclude no duplicates.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTL-Repo: A Benchmark for Evaluating LLMs on L...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FormalEval: A Method for Automatic Evaluation ...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test-Driven Development and LLM-based Code Gen...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLM - Based Code Generation for Querying Tempo...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RTLCoder: Outperforming GPT-3.5 in Design RTL ...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Tell Me How to Survey: Literature Review Made ...</td>\n",
       "      <td>IEEE Year: 2022</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Discriminative Probing and Tuning for Text-to-...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Persistence of RDF Data into NoSQL: A Survey a...</td>\n",
       "      <td>IEEE Year: 2022</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>Streaming Technologies and Serialization Proto...</td>\n",
       "      <td>IEEE Year: 2024</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Understand Me, if You Refer to Aspect Knowledg...</td>\n",
       "      <td>IEEE Year: 2022</td>\n",
       "      <td>IEEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title             year source\n",
       "0    RTL-Repo: A Benchmark for Evaluating LLMs on L...  IEEE Year: 2024   IEEE\n",
       "1    FormalEval: A Method for Automatic Evaluation ...  IEEE Year: 2024   IEEE\n",
       "2    Test-Driven Development and LLM-based Code Gen...  IEEE Year: 2024   IEEE\n",
       "3    LLM - Based Code Generation for Querying Tempo...  IEEE Year: 2024   IEEE\n",
       "4    RTLCoder: Outperforming GPT-3.5 in Design RTL ...  IEEE Year: 2024   IEEE\n",
       "..                                                 ...              ...    ...\n",
       "843  Tell Me How to Survey: Literature Review Made ...  IEEE Year: 2022   IEEE\n",
       "844  Discriminative Probing and Tuning for Text-to-...  IEEE Year: 2024   IEEE\n",
       "845  Persistence of RDF Data into NoSQL: A Survey a...  IEEE Year: 2022   IEEE\n",
       "846  Streaming Technologies and Serialization Proto...  IEEE Year: 2024   IEEE\n",
       "847  Understand Me, if You Refer to Aspect Knowledg...  IEEE Year: 2022   IEEE\n",
       "\n",
       "[848 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieee = pd.read_csv('IEEEPapers.csv', names=['title', 'year'])\n",
    "ieee['source'] = 'IEEE'\n",
    "ieee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evaluation of Code LLMs on Geospatial Code Gen...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3687123.3698286</td>\n",
       "      <td>January 2025</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teaching Code LLMs to Use Autocompletion Tools...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3714462</td>\n",
       "      <td>May 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CodeFuse-13B: A Pretrained Multi-lingual Code ...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3639477.3639719</td>\n",
       "      <td>June 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generating Software Tests for Mobile Applicati...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3644032.3644454</td>\n",
       "      <td>November 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RTLFixer: Automatically Fixing RTL Syntax Erro...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3649329.3657353</td>\n",
       "      <td>November 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PromptRobust: Towards Evaluating the Robustnes...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3689217.3690621</td>\n",
       "      <td>November 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Towards Better Chinese Spelling Check for Sear...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3616855.3635847</td>\n",
       "      <td>January 2025</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Enhancing Graph Representation Learning with W...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3704522.3704537</td>\n",
       "      <td>October 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Multi-Modality Co-Learning for Efficient Skele...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3664647.3681015</td>\n",
       "      <td>March 2024</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>MAPLE: Mobile App Prediction Leveraging Large ...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3643514</td>\n",
       "      <td>November 2023</td>\n",
       "      <td>ACM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Evaluation of Code LLMs on Geospatial Code Gen...   \n",
       "1   Teaching Code LLMs to Use Autocompletion Tools...   \n",
       "2   CodeFuse-13B: A Pretrained Multi-lingual Code ...   \n",
       "3   Generating Software Tests for Mobile Applicati...   \n",
       "4   RTLFixer: Automatically Fixing RTL Syntax Erro...   \n",
       "..                                                ...   \n",
       "74  PromptRobust: Towards Evaluating the Robustnes...   \n",
       "75  Towards Better Chinese Spelling Check for Sear...   \n",
       "76  Enhancing Graph Representation Learning with W...   \n",
       "77  Multi-Modality Co-Learning for Efficient Skele...   \n",
       "78  MAPLE: Mobile App Prediction Leveraging Large ...   \n",
       "\n",
       "                                              link           year source  \n",
       "0   https://dl.acm.org/doi/10.1145/3687123.3698286   January 2025    ACM  \n",
       "1           https://dl.acm.org/doi/10.1145/3714462       May 2024    ACM  \n",
       "2   https://dl.acm.org/doi/10.1145/3639477.3639719      June 2024    ACM  \n",
       "3   https://dl.acm.org/doi/10.1145/3644032.3644454  November 2024    ACM  \n",
       "4   https://dl.acm.org/doi/10.1145/3649329.3657353  November 2024    ACM  \n",
       "..                                             ...            ...    ...  \n",
       "74  https://dl.acm.org/doi/10.1145/3689217.3690621  November 2024    ACM  \n",
       "75  https://dl.acm.org/doi/10.1145/3616855.3635847   January 2025    ACM  \n",
       "76  https://dl.acm.org/doi/10.1145/3704522.3704537   October 2024    ACM  \n",
       "77  https://dl.acm.org/doi/10.1145/3664647.3681015     March 2024    ACM  \n",
       "78          https://dl.acm.org/doi/10.1145/3643514  November 2023    ACM  \n",
       "\n",
       "[79 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acm = pd.read_csv('ACMPapers.csv', names=['title', 'link', 'year'])\n",
    "acm['source'] = 'ACM'\n",
    "acm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SmartGuard: An LLM-enhanced framework for smar...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low-cost language models: Survey and performan...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-stage guided code generation for Large L...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The more quality information the better: Hiera...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MedExpQA: Multilingual benchmarking of Large L...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Enhancing source code retrieval with joint Bi-...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SEOSS-Queries - a software engineering dataset...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Transformers in source code generation: A comp...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Re-examining lexical and semantic attention: D...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Oslcfit (organic simultaneous LSTM and CNN Fit...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   SmartGuard: An LLM-enhanced framework for smar...   \n",
       "1   Low-cost language models: Survey and performan...   \n",
       "2   Multi-stage guided code generation for Large L...   \n",
       "3   The more quality information the better: Hiera...   \n",
       "4   MedExpQA: Multilingual benchmarking of Large L...   \n",
       "..                                                ...   \n",
       "59  Enhancing source code retrieval with joint Bi-...   \n",
       "60  SEOSS-Queries - a software engineering dataset...   \n",
       "61  Transformers in source code generation: A comp...   \n",
       "62  Re-examining lexical and semantic attention: D...   \n",
       "63  Oslcfit (organic simultaneous LSTM and CNN Fit...   \n",
       "\n",
       "                                                 link         source  \n",
       "0   https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "1   https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "2   https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "3   https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "4   https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "..                                                ...            ...  \n",
       "59  https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "60  https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "61  https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "62  https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "63  https://www.sciencedirect.com/science/article/...  ScienceDirect  \n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = pd.read_csv('ScienceDirectPapers.csv', names=['title', 'link'])\n",
    "sd['source'] = 'ScienceDirect'\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([ieee, acm, sd], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([t, merged_df], ignore_index=True).drop_duplicates(subset=['title'], keep='first').to_csv('merged_all_sources_no_duplicated_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-Driven Development and LLM-based Code Gen...</td>\n",
       "      <td>Google Scholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PDF] Beyond synthetic benchmarks: Assessing r...</td>\n",
       "      <td>Google Scholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classeval: A manually-crafted benchmark for ev...</td>\n",
       "      <td>Google Scholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Survey on Large Language Models for Code Gen...</td>\n",
       "      <td>Google Scholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When llm-based code generation meets the softw...</td>\n",
       "      <td>Google Scholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>Oslcfit (organic simultaneous LSTM and CNN Fit...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>GTFS-Madrid-Bench: A benchmark for virtual kno...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>EDS-MEMBED: Multi-sense embeddings based on en...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>SEOSS-Queries - a software engineering dataset...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>Re-examining lexical and semantic attention: D...</td>\n",
       "      <td>ScienceDirect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2268 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title          source\n",
       "0     Test-Driven Development and LLM-based Code Gen...  Google Scholar\n",
       "1     [PDF] Beyond synthetic benchmarks: Assessing r...  Google Scholar\n",
       "2     Classeval: A manually-crafted benchmark for ev...  Google Scholar\n",
       "3     A Survey on Large Language Models for Code Gen...  Google Scholar\n",
       "4     When llm-based code generation meets the softw...  Google Scholar\n",
       "...                                                 ...             ...\n",
       "2263  Oslcfit (organic simultaneous LSTM and CNN Fit...   ScienceDirect\n",
       "2264  GTFS-Madrid-Bench: A benchmark for virtual kno...   ScienceDirect\n",
       "2265  EDS-MEMBED: Multi-sense embeddings based on en...   ScienceDirect\n",
       "2266  SEOSS-Queries - a software engineering dataset...   ScienceDirect\n",
       "2267  Re-examining lexical and semantic attention: D...   ScienceDirect\n",
       "\n",
       "[2268 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "g = pd.read_csv('GoogleScholarPapers.csv', names=['title', 'link', 'year'])\n",
    "g['source'] = 'Google Scholar'\n",
    "ieee = pd.read_csv('IEEEPapers.csv', names=['title', 'year']) #.drop_duplicates(subset=['title'], keep='first')\n",
    "ieee['source'] = 'IEEE'\n",
    "acm = pd.read_csv('ACMPapers.csv', names=['title', 'link', 'year']).drop_duplicates(subset=['title'], keep='first')\n",
    "acm['source'] = 'ACM'\n",
    "sd = pd.read_csv('ScienceDirectPapers.csv', names=['title', 'link']).drop_duplicates(subset=['title'], keep='first')\n",
    "sd['source'] = 'ScienceDirect'\n",
    "merged_df = pd.concat([g, ieee, acm, sd], ignore_index=True)\n",
    "merged_df.drop('year', axis=1, inplace=True)\n",
    "\n",
    "a = pd.read_csv('survey personal - include_exclude_nodup.csv')\n",
    "a[['title', 'link', 'venue', 'include/exclude', 'questions', 'future use']]\n",
    "merged_df[['title', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dict = {'Google Scholar': 0, 'IEEE': 1, 'ACM': 2, 'ScienceDirect': 3} \n",
    "\n",
    "pd.merge(merged_df[['title', 'source']], a[['title', 'link', 'venue', 'include/exclude', 'questions', 'future use']], on='title', how='inner').reindex(columns=['title', 'link', 'source', 'venue', 'include/exclude', 'questions', 'future use']).sort_values(by='source', key=lambda x: x.map(custom_dict)).to_csv('include-exclude_sheet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "include/exclude\n",
       "exclude      1825\n",
       "include       286\n",
       "?             120\n",
       "include ?      27\n",
       "?               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(a[['title', 'link', 'venue', 'include/exclude', 'questions', 'future use']], merged_df[['title', 'source']], on='title', how='inner').reindex(columns=['title', 'link', 'source', 'venue', 'include/exclude', 'questions', 'future use']).sort_values(by='source', key=lambda x: x.map(custom_dict))['include/exclude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
